{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------- utf-8 encoding -----------------------------------------\n",
    "# this file contains kinds of layers test cases that are implemented here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensor import Tensor\n",
    "from initializer_w import Initializer\n",
    "from layers.models import Linear\n",
    "from optimizer.optim import GradientOptimiser, AdamOptimizer\n",
    "from layers.module import Module\n",
    "from autograd.autodiff import mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int = 5,\n",
    "        out_features: int = 1,\n",
    "        init_type=\"uniform\",\n",
    "        meta: dict = {\"low\": 0.0, \"high\": 1.0},\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_feature = in_features\n",
    "        self.out_feature = out_features\n",
    "        self.init_type = init_type\n",
    "        self.meta =  meta\n",
    "        self.linear = Linear(in_feature= self.in_feature , out_feature=self.out_feature , init_type=self.init_type  , meta=self.meta)\n",
    "        self.add_module(\"linear\", self.linear)\n",
    "    def forward(self, x: Tensor):\n",
    "\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.LinearModel object at 0x7c94641e6a40>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining input data for this\n",
    "init_w  = Initializer()\n",
    "# x = init_w.forward(shape=(50 , 5) , init_type=\"random\"  , retain_grad=True , meta=None)\n",
    "# y = init_w.forward(shape=(50, 1), init_type=\"random\", retain_grad=True, meta=None)\n",
    "\n",
    "\n",
    "x = np.linspace(-10, 10, 50).reshape(-1, 1)\n",
    "# noise = np.random.normal(0, 2, size=x.shape)\n",
    "y = (3 * x + 2).reshape(-1, 1)\n",
    "x = Tensor(data=x, retain_grad=True)\n",
    "y = Tensor(data=y, retain_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at Epoch 0 is : netwok_nn.tensor(292.2281806850554 , grad = 1.0)\n",
      "Loss at Epoch 1 is : netwok_nn.tensor(292.02518071206674 , grad = 1.0)\n",
      "Loss at Epoch 2 is : netwok_nn.tensor(291.82931268520355 , grad = 1.0)\n",
      "Loss at Epoch 3 is : netwok_nn.tensor(291.6349653132289 , grad = 1.0)\n",
      "Loss at Epoch 4 is : netwok_nn.tensor(291.44019334729364 , grad = 1.0)\n",
      "Loss at Epoch 5 is : netwok_nn.tensor(291.244102217681 , grad = 1.0)\n",
      "Loss at Epoch 6 is : netwok_nn.tensor(291.04621396874234 , grad = 1.0)\n",
      "Loss at Epoch 7 is : netwok_nn.tensor(290.8462499484083 , grad = 1.0)\n",
      "Loss at Epoch 8 is : netwok_nn.tensor(290.6440396323486 , grad = 1.0)\n",
      "Loss at Epoch 9 is : netwok_nn.tensor(290.4394768065188 , grad = 1.0)\n",
      "Loss at Epoch 10 is : netwok_nn.tensor(290.2324963215939 , grad = 1.0)\n",
      "Loss at Epoch 11 is : netwok_nn.tensor(290.02306078492677 , grad = 1.0)\n",
      "Loss at Epoch 12 is : netwok_nn.tensor(289.81115245922024 , grad = 1.0)\n",
      "Loss at Epoch 13 is : netwok_nn.tensor(289.59676807059736 , grad = 1.0)\n",
      "Loss at Epoch 14 is : netwok_nn.tensor(289.37991532991725 , grad = 1.0)\n",
      "Loss at Epoch 15 is : netwok_nn.tensor(289.1606105081008 , grad = 1.0)\n",
      "Loss at Epoch 16 is : netwok_nn.tensor(288.93887668460457 , grad = 1.0)\n",
      "Loss at Epoch 17 is : netwok_nn.tensor(288.7147424400901 , grad = 1.0)\n",
      "Loss at Epoch 18 is : netwok_nn.tensor(288.4882408509356 , grad = 1.0)\n",
      "Loss at Epoch 19 is : netwok_nn.tensor(288.2594086944735 , grad = 1.0)\n",
      "Loss at Epoch 20 is : netwok_nn.tensor(288.028285805153 , grad = 1.0)\n",
      "Loss at Epoch 21 is : netwok_nn.tensor(287.794914541506 , grad = 1.0)\n",
      "Loss at Epoch 22 is : netwok_nn.tensor(287.559339336469 , grad = 1.0)\n",
      "Loss at Epoch 23 is : netwok_nn.tensor(287.3216063119534 , grad = 1.0)\n",
      "Loss at Epoch 24 is : netwok_nn.tensor(287.0817629441389 , grad = 1.0)\n",
      "Loss at Epoch 25 is : netwok_nn.tensor(286.8398577697716 , grad = 1.0)\n",
      "Loss at Epoch 26 is : netwok_nn.tensor(286.5959401263688 , grad = 1.0)\n",
      "Loss at Epoch 27 is : netwok_nn.tensor(286.35005992106636 , grad = 1.0)\n",
      "Loss at Epoch 28 is : netwok_nn.tensor(286.10226742413244 , grad = 1.0)\n",
      "Loss at Epoch 29 is : netwok_nn.tensor(285.85261308409133 , grad = 1.0)\n",
      "Loss at Epoch 30 is : netwok_nn.tensor(285.60114736205423 , grad = 1.0)\n",
      "Loss at Epoch 31 is : netwok_nn.tensor(285.3479205833282 , grad = 1.0)\n",
      "Loss at Epoch 32 is : netwok_nn.tensor(285.0929828047149 , grad = 1.0)\n",
      "Loss at Epoch 33 is : netwok_nn.tensor(284.8363836961611 , grad = 1.0)\n",
      "Loss at Epoch 34 is : netwok_nn.tensor(284.57817243560464 , grad = 1.0)\n",
      "Loss at Epoch 35 is : netwok_nn.tensor(284.3183976159971 , grad = 1.0)\n",
      "Loss at Epoch 36 is : netwok_nn.tensor(284.0571071635836 , grad = 1.0)\n",
      "Loss at Epoch 37 is : netwok_nn.tensor(283.7943482666029 , grad = 1.0)\n",
      "Loss at Epoch 38 is : netwok_nn.tensor(283.53016731362874 , grad = 1.0)\n",
      "Loss at Epoch 39 is : netwok_nn.tensor(283.2646098408258 , grad = 1.0)\n",
      "Loss at Epoch 40 is : netwok_nn.tensor(282.9977204874349 , grad = 1.0)\n",
      "Loss at Epoch 41 is : netwok_nn.tensor(282.72954295884006 , grad = 1.0)\n",
      "Loss at Epoch 42 is : netwok_nn.tensor(282.46011999660186 , grad = 1.0)\n",
      "Loss at Epoch 43 is : netwok_nn.tensor(282.1894933548745 , grad = 1.0)\n",
      "Loss at Epoch 44 is : netwok_nn.tensor(281.9177037826522 , grad = 1.0)\n",
      "Loss at Epoch 45 is : netwok_nn.tensor(281.6447910113187 , grad = 1.0)\n",
      "Loss at Epoch 46 is : netwok_nn.tensor(281.3707937470063 , grad = 1.0)\n",
      "Loss at Epoch 47 is : netwok_nn.tensor(281.09574966729116 , grad = 1.0)\n",
      "Loss at Epoch 48 is : netwok_nn.tensor(280.81969542178626 , grad = 1.0)\n",
      "Loss at Epoch 49 is : netwok_nn.tensor(280.5426666362162 , grad = 1.0)\n",
      "Loss at Epoch 50 is : netwok_nn.tensor(280.2646979195859 , grad = 1.0)\n",
      "Loss at Epoch 51 is : netwok_nn.tensor(279.9858228740804 , grad = 1.0)\n",
      "Loss at Epoch 52 is : netwok_nn.tensor(279.70607410736125 , grad = 1.0)\n",
      "Loss at Epoch 53 is : netwok_nn.tensor(279.42548324694496 , grad = 1.0)\n",
      "Loss at Epoch 54 is : netwok_nn.tensor(279.14408095637754 , grad = 1.0)\n",
      "Loss at Epoch 55 is : netwok_nn.tensor(278.86189695293945 , grad = 1.0)\n",
      "Loss at Epoch 56 is : netwok_nn.tensor(278.5789600266372 , grad = 1.0)\n",
      "Loss at Epoch 57 is : netwok_nn.tensor(278.29529806026125 , grad = 1.0)\n",
      "Loss at Epoch 58 is : netwok_nn.tensor(278.0109380503072 , grad = 1.0)\n",
      "Loss at Epoch 59 is : netwok_nn.tensor(277.725906128577 , grad = 1.0)\n",
      "Loss at Epoch 60 is : netwok_nn.tensor(277.4402275842958 , grad = 1.0)\n",
      "Loss at Epoch 61 is : netwok_nn.tensor(277.15392688659506 , grad = 1.0)\n",
      "Loss at Epoch 62 is : netwok_nn.tensor(276.86702770722883 , grad = 1.0)\n",
      "Loss at Epoch 63 is : netwok_nn.tensor(276.57955294340525 , grad = 1.0)\n",
      "Loss at Epoch 64 is : netwok_nn.tensor(276.29152474062795 , grad = 1.0)\n",
      "Loss at Epoch 65 is : netwok_nn.tensor(276.0029645154541 , grad = 1.0)\n",
      "Loss at Epoch 66 is : netwok_nn.tensor(275.71389297808855 , grad = 1.0)\n",
      "Loss at Epoch 67 is : netwok_nn.tensor(275.42433015474364 , grad = 1.0)\n",
      "Loss at Epoch 68 is : netwok_nn.tensor(275.1342954097026 , grad = 1.0)\n",
      "Loss at Epoch 69 is : netwok_nn.tensor(274.8438074670355 , grad = 1.0)\n",
      "Loss at Epoch 70 is : netwok_nn.tensor(274.55288443192234 , grad = 1.0)\n",
      "Loss at Epoch 71 is : netwok_nn.tensor(274.26154381154714 , grad = 1.0)\n",
      "Loss at Epoch 72 is : netwok_nn.tensor(273.96980253553176 , grad = 1.0)\n",
      "Loss at Epoch 73 is : netwok_nn.tensor(273.67767697588516 , grad = 1.0)\n",
      "Loss at Epoch 74 is : netwok_nn.tensor(273.3851829664489 , grad = 1.0)\n",
      "Loss at Epoch 75 is : netwok_nn.tensor(273.0923358218233 , grad = 1.0)\n",
      "Loss at Epoch 76 is : netwok_nn.tensor(272.79915035576516 , grad = 1.0)\n",
      "Loss at Epoch 77 is : netwok_nn.tensor(272.5056408990481 , grad = 1.0)\n",
      "Loss at Epoch 78 is : netwok_nn.tensor(272.2118213167849 , grad = 1.0)\n",
      "Loss at Epoch 79 is : netwok_nn.tensor(271.91770502520774 , grad = 1.0)\n",
      "Loss at Epoch 80 is : netwok_nn.tensor(271.6233050079106 , grad = 1.0)\n",
      "Loss at Epoch 81 is : netwok_nn.tensor(271.3286338315572 , grad = 1.0)\n",
      "Loss at Epoch 82 is : netwok_nn.tensor(271.0337036610596 , grad = 1.0)\n",
      "Loss at Epoch 83 is : netwok_nn.tensor(270.7385262742353 , grad = 1.0)\n",
      "Loss at Epoch 84 is : netwok_nn.tensor(270.4431130759523 , grad = 1.0)\n",
      "Loss at Epoch 85 is : netwok_nn.tensor(270.14747511177023 , grad = 1.0)\n",
      "Loss at Epoch 86 is : netwok_nn.tensor(269.8516230810907 , grad = 1.0)\n",
      "Loss at Epoch 87 is : netwok_nn.tensor(269.5555673498259 , grad = 1.0)\n",
      "Loss at Epoch 88 is : netwok_nn.tensor(269.25931796260033 , grad = 1.0)\n",
      "Loss at Epoch 89 is : netwok_nn.tensor(268.9628846544955 , grad = 1.0)\n",
      "Loss at Epoch 90 is : netwok_nn.tensor(268.6662768623531 , grad = 1.0)\n",
      "Loss at Epoch 91 is : netwok_nn.tensor(268.36950373564764 , grad = 1.0)\n",
      "Loss at Epoch 92 is : netwok_nn.tensor(268.0725741469443 , grad = 1.0)\n",
      "Loss at Epoch 93 is : netwok_nn.tensor(267.7754967019523 , grad = 1.0)\n",
      "Loss at Epoch 94 is : netwok_nn.tensor(267.4782797491904 , grad = 1.0)\n",
      "Loss at Epoch 95 is : netwok_nn.tensor(267.1809313892752 , grad = 1.0)\n",
      "Loss at Epoch 96 is : netwok_nn.tensor(266.8834594838477 , grad = 1.0)\n",
      "Loss at Epoch 97 is : netwok_nn.tensor(266.58587166414827 , grad = 1.0)\n",
      "Loss at Epoch 98 is : netwok_nn.tensor(266.2881753392562 , grad = 1.0)\n",
      "Loss at Epoch 99 is : netwok_nn.tensor(265.9903777040028 , grad = 1.0)\n",
      "Loss at Epoch 100 is : netwok_nn.tensor(265.6924857465737 , grad = 1.0)\n",
      "Loss at Epoch 101 is : netwok_nn.tensor(265.3945062558095 , grad = 1.0)\n",
      "Loss at Epoch 102 is : netwok_nn.tensor(265.0964458282179 , grad = 1.0)\n",
      "Loss at Epoch 103 is : netwok_nn.tensor(264.79831087470865 , grad = 1.0)\n",
      "Loss at Epoch 104 is : netwok_nn.tensor(264.5001076270614 , grad = 1.0)\n",
      "Loss at Epoch 105 is : netwok_nn.tensor(264.2018421441379 , grad = 1.0)\n",
      "Loss at Epoch 106 is : netwok_nn.tensor(263.9035203178489 , grad = 1.0)\n",
      "Loss at Epoch 107 is : netwok_nn.tensor(263.6051478788844 , grad = 1.0)\n",
      "Loss at Epoch 108 is : netwok_nn.tensor(263.30673040221956 , grad = 1.0)\n",
      "Loss at Epoch 109 is : netwok_nn.tensor(263.00827331240185 , grad = 1.0)\n",
      "Loss at Epoch 110 is : netwok_nn.tensor(262.70978188863205 , grad = 1.0)\n",
      "Loss at Epoch 111 is : netwok_nn.tensor(262.41126126964514 , grad = 1.0)\n",
      "Loss at Epoch 112 is : netwok_nn.tensor(262.1127164584005 , grad = 1.0)\n",
      "Loss at Epoch 113 is : netwok_nn.tensor(261.8141523265893 , grad = 1.0)\n",
      "Loss at Epoch 114 is : netwok_nn.tensor(261.5155736189663 , grad = 1.0)\n",
      "Loss at Epoch 115 is : netwok_nn.tensor(261.2169849575137 , grad = 1.0)\n",
      "Loss at Epoch 116 is : netwok_nn.tensor(260.9183908454446 , grad = 1.0)\n",
      "Loss at Epoch 117 is : netwok_nn.tensor(260.6197956710511 , grad = 1.0)\n",
      "Loss at Epoch 118 is : netwok_nn.tensor(260.3212037114063 , grad = 1.0)\n",
      "Loss at Epoch 119 is : netwok_nn.tensor(260.0226191359233 , grad = 1.0)\n",
      "Loss at Epoch 120 is : netwok_nn.tensor(259.72404600977967 , grad = 1.0)\n",
      "Loss at Epoch 121 is : netwok_nn.tensor(259.42548829721176 , grad = 1.0)\n",
      "Loss at Epoch 122 is : netwok_nn.tensor(259.1269498646845 , grad = 1.0)\n",
      "Loss at Epoch 123 is : netwok_nn.tensor(258.82843448394215 , grad = 1.0)\n",
      "Loss at Epoch 124 is : netwok_nn.tensor(258.5299458349452 , grad = 1.0)\n",
      "Loss at Epoch 125 is : netwok_nn.tensor(258.2314875086972 , grad = 1.0)\n",
      "Loss at Epoch 126 is : netwok_nn.tensor(257.93306300996755 , grad = 1.0)\n",
      "Loss at Epoch 127 is : netwok_nn.tensor(257.6346757599131 , grad = 1.0)\n",
      "Loss at Epoch 128 is : netwok_nn.tensor(257.3363290986041 , grad = 1.0)\n",
      "Loss at Epoch 129 is : netwok_nn.tensor(257.03802628745746 , grad = 1.0)\n",
      "Loss at Epoch 130 is : netwok_nn.tensor(256.73977051158215 , grad = 1.0)\n",
      "Loss at Epoch 131 is : netwok_nn.tensor(256.441564882039 , grad = 1.0)\n",
      "Loss at Epoch 132 is : netwok_nn.tensor(256.1434124380197 , grad = 1.0)\n",
      "Loss at Epoch 133 is : netwok_nn.tensor(255.84531614894811 , grad = 1.0)\n",
      "Loss at Epoch 134 is : netwok_nn.tensor(255.54727891650592 , grad = 1.0)\n",
      "Loss at Epoch 135 is : netwok_nn.tensor(255.24930357658758 , grad = 1.0)\n",
      "Loss at Epoch 136 is : netwok_nn.tensor(254.9513929011859 , grad = 1.0)\n",
      "Loss at Epoch 137 is : netwok_nn.tensor(254.65354960021162 , grad = 1.0)\n",
      "Loss at Epoch 138 is : netwok_nn.tensor(254.3557763232498 , grad = 1.0)\n",
      "Loss at Epoch 139 is : netwok_nn.tensor(254.05807566125543 , grad = 1.0)\n",
      "Loss at Epoch 140 is : netwok_nn.tensor(253.76045014819044 , grad = 1.0)\n",
      "Loss at Epoch 141 is : netwok_nn.tensor(253.4629022626051 , grad = 1.0)\n",
      "Loss at Epoch 142 is : netwok_nn.tensor(253.1654344291648 , grad = 1.0)\n",
      "Loss at Epoch 143 is : netwok_nn.tensor(252.86804902012642 , grad = 1.0)\n",
      "Loss at Epoch 144 is : netwok_nn.tensor(252.57074835676366 , grad = 1.0)\n",
      "Loss at Epoch 145 is : netwok_nn.tensor(252.27353471074574 , grad = 1.0)\n",
      "Loss at Epoch 146 is : netwok_nn.tensor(251.97641030546956 , grad = 1.0)\n",
      "Loss at Epoch 147 is : netwok_nn.tensor(251.67937731734807 , grad = 1.0)\n",
      "Loss at Epoch 148 is : netwok_nn.tensor(251.3824378770568 , grad = 1.0)\n",
      "Loss at Epoch 149 is : netwok_nn.tensor(251.08559407073813 , grad = 1.0)\n",
      "Loss at Epoch 150 is : netwok_nn.tensor(250.7888479411684 , grad = 1.0)\n",
      "Loss at Epoch 151 is : netwok_nn.tensor(250.49220148888574 , grad = 1.0)\n",
      "Loss at Epoch 152 is : netwok_nn.tensor(250.19565667328266 , grad = 1.0)\n",
      "Loss at Epoch 153 is : netwok_nn.tensor(249.89921541366286 , grad = 1.0)\n",
      "Loss at Epoch 154 is : netwok_nn.tensor(249.6028795902655 , grad = 1.0)\n",
      "Loss at Epoch 155 is : netwok_nn.tensor(249.30665104525633 , grad = 1.0)\n",
      "Loss at Epoch 156 is : netwok_nn.tensor(249.010531583688 , grad = 1.0)\n",
      "Loss at Epoch 157 is : netwok_nn.tensor(248.71452297443045 , grad = 1.0)\n",
      "Loss at Epoch 158 is : netwok_nn.tensor(248.41862695107255 , grad = 1.0)\n",
      "Loss at Epoch 159 is : netwok_nn.tensor(248.12284521279568 , grad = 1.0)\n",
      "Loss at Epoch 160 is : netwok_nn.tensor(247.8271794252205 , grad = 1.0)\n",
      "Loss at Epoch 161 is : netwok_nn.tensor(247.5316312212282 , grad = 1.0)\n",
      "Loss at Epoch 162 is : netwok_nn.tensor(247.23620220175673 , grad = 1.0)\n",
      "Loss at Epoch 163 is : netwok_nn.tensor(246.9408939365729 , grad = 1.0)\n",
      "Loss at Epoch 164 is : netwok_nn.tensor(246.6457079650215 , grad = 1.0)\n",
      "Loss at Epoch 165 is : netwok_nn.tensor(246.35064579675208 , grad = 1.0)\n",
      "Loss at Epoch 166 is : netwok_nn.tensor(246.05570891242397 , grad = 1.0)\n",
      "Loss at Epoch 167 is : netwok_nn.tensor(245.7608987643911 , grad = 1.0)\n",
      "Loss at Epoch 168 is : netwok_nn.tensor(245.46621677736607 , grad = 1.0)\n",
      "Loss at Epoch 169 is : netwok_nn.tensor(245.17166434906542 , grad = 1.0)\n",
      "Loss at Epoch 170 is : netwok_nn.tensor(244.87724285083598 , grad = 1.0)\n",
      "Loss at Epoch 171 is : netwok_nn.tensor(244.582953628263 , grad = 1.0)\n",
      "Loss at Epoch 172 is : netwok_nn.tensor(244.2887980017612 , grad = 1.0)\n",
      "Loss at Epoch 173 is : netwok_nn.tensor(243.99477726714923 , grad = 1.0)\n",
      "Loss at Epoch 174 is : netwok_nn.tensor(243.70089269620695 , grad = 1.0)\n",
      "Loss at Epoch 175 is : netwok_nn.tensor(243.40714553721776 , grad = 1.0)\n",
      "Loss at Epoch 176 is : netwok_nn.tensor(243.11353701549564 , grad = 1.0)\n",
      "Loss at Epoch 177 is : netwok_nn.tensor(242.8200683338974 , grad = 1.0)\n",
      "Loss at Epoch 178 is : netwok_nn.tensor(242.52674067332066 , grad = 1.0)\n",
      "Loss at Epoch 179 is : netwok_nn.tensor(242.23355519318838 , grad = 1.0)\n",
      "Loss at Epoch 180 is : netwok_nn.tensor(241.9405130319197 , grad = 1.0)\n",
      "Loss at Epoch 181 is : netwok_nn.tensor(241.64761530738832 , grad = 1.0)\n",
      "Loss at Epoch 182 is : netwok_nn.tensor(241.35486311736855 , grad = 1.0)\n",
      "Loss at Epoch 183 is : netwok_nn.tensor(241.06225753996875 , grad = 1.0)\n",
      "Loss at Epoch 184 is : netwok_nn.tensor(240.76979963405375 , grad = 1.0)\n",
      "Loss at Epoch 185 is : netwok_nn.tensor(240.47749043965555 , grad = 1.0)\n",
      "Loss at Epoch 186 is : netwok_nn.tensor(240.1853309783737 , grad = 1.0)\n",
      "Loss at Epoch 187 is : netwok_nn.tensor(239.89332225376435 , grad = 1.0)\n",
      "Loss at Epoch 188 is : netwok_nn.tensor(239.60146525171984 , grad = 1.0)\n",
      "Loss at Epoch 189 is : netwok_nn.tensor(239.3097609408377 , grad = 1.0)\n",
      "Loss at Epoch 190 is : netwok_nn.tensor(239.01821027278064 , grad = 1.0)\n",
      "Loss at Epoch 191 is : netwok_nn.tensor(238.72681418262673 , grad = 1.0)\n",
      "Loss at Epoch 192 is : netwok_nn.tensor(238.4355735892112 , grad = 1.0)\n",
      "Loss at Epoch 193 is : netwok_nn.tensor(238.14448939545878 , grad = 1.0)\n",
      "Loss at Epoch 194 is : netwok_nn.tensor(237.85356248870798 , grad = 1.0)\n",
      "Loss at Epoch 195 is : netwok_nn.tensor(237.56279374102735 , grad = 1.0)\n",
      "Loss at Epoch 196 is : netwok_nn.tensor(237.2721840095232 , grad = 1.0)\n",
      "Loss at Epoch 197 is : netwok_nn.tensor(236.98173413664009 , grad = 1.0)\n",
      "Loss at Epoch 198 is : netwok_nn.tensor(236.6914449504537 , grad = 1.0)\n",
      "Loss at Epoch 199 is : netwok_nn.tensor(236.4013172649564 , grad = 1.0)\n",
      "Loss at Epoch 200 is : netwok_nn.tensor(236.1113518803355 , grad = 1.0)\n",
      "Loss at Epoch 201 is : netwok_nn.tensor(235.82154958324546 , grad = 1.0)\n",
      "Loss at Epoch 202 is : netwok_nn.tensor(235.53191114707226 , grad = 1.0)\n",
      "Loss at Epoch 203 is : netwok_nn.tensor(235.24243733219268 , grad = 1.0)\n",
      "Loss at Epoch 204 is : netwok_nn.tensor(234.95312888622593 , grad = 1.0)\n",
      "Loss at Epoch 205 is : netwok_nn.tensor(234.66398654428042 , grad = 1.0)\n",
      "Loss at Epoch 206 is : netwok_nn.tensor(234.37501102919393 , grad = 1.0)\n",
      "Loss at Epoch 207 is : netwok_nn.tensor(234.08620305176802 , grad = 1.0)\n",
      "Loss at Epoch 208 is : netwok_nn.tensor(233.79756331099736 , grad = 1.0)\n",
      "Loss at Epoch 209 is : netwok_nn.tensor(233.5090924942932 , grad = 1.0)\n",
      "Loss at Epoch 210 is : netwok_nn.tensor(233.22079127770178 , grad = 1.0)\n",
      "Loss at Epoch 211 is : netwok_nn.tensor(232.93266032611737 , grad = 1.0)\n",
      "Loss at Epoch 212 is : netwok_nn.tensor(232.6447002934908 , grad = 1.0)\n",
      "Loss at Epoch 213 is : netwok_nn.tensor(232.35691182303293 , grad = 1.0)\n",
      "Loss at Epoch 214 is : netwok_nn.tensor(232.06929554741313 , grad = 1.0)\n",
      "Loss at Epoch 215 is : netwok_nn.tensor(231.7818520889536 , grad = 1.0)\n",
      "Loss at Epoch 216 is : netwok_nn.tensor(231.49458205981938 , grad = 1.0)\n",
      "Loss at Epoch 217 is : netwok_nn.tensor(231.20748606220306 , grad = 1.0)\n",
      "Loss at Epoch 218 is : netwok_nn.tensor(230.92056468850697 , grad = 1.0)\n",
      "Loss at Epoch 219 is : netwok_nn.tensor(230.63381852151934 , grad = 1.0)\n",
      "Loss at Epoch 220 is : netwok_nn.tensor(230.3472481345882 , grad = 1.0)\n",
      "Loss at Epoch 221 is : netwok_nn.tensor(230.06085409179016 , grad = 1.0)\n",
      "Loss at Epoch 222 is : netwok_nn.tensor(229.77463694809646 , grad = 1.0)\n",
      "Loss at Epoch 223 is : netwok_nn.tensor(229.48859724953408 , grad = 1.0)\n",
      "Loss at Epoch 224 is : netwok_nn.tensor(229.20273553334465 , grad = 1.0)\n",
      "Loss at Epoch 225 is : netwok_nn.tensor(228.917052328139 , grad = 1.0)\n",
      "Loss at Epoch 226 is : netwok_nn.tensor(228.6315481540486 , grad = 1.0)\n",
      "Loss at Epoch 227 is : netwok_nn.tensor(228.34622352287366 , grad = 1.0)\n",
      "Loss at Epoch 228 is : netwok_nn.tensor(228.06107893822812 , grad = 1.0)\n",
      "Loss at Epoch 229 is : netwok_nn.tensor(227.7761148956813 , grad = 1.0)\n",
      "Loss at Epoch 230 is : netwok_nn.tensor(227.4913318828968 , grad = 1.0)\n",
      "Loss at Epoch 231 is : netwok_nn.tensor(227.20673037976826 , grad = 1.0)\n",
      "Loss at Epoch 232 is : netwok_nn.tensor(226.922310858552 , grad = 1.0)\n",
      "Loss at Epoch 233 is : netwok_nn.tensor(226.63807378399738 , grad = 1.0)\n",
      "Loss at Epoch 234 is : netwok_nn.tensor(226.354019613474 , grad = 1.0)\n",
      "Loss at Epoch 235 is : netwok_nn.tensor(226.0701487970963 , grad = 1.0)\n",
      "Loss at Epoch 236 is : netwok_nn.tensor(225.7864617778458 , grad = 1.0)\n",
      "Loss at Epoch 237 is : netwok_nn.tensor(225.50295899169006 , grad = 1.0)\n",
      "Loss at Epoch 238 is : netwok_nn.tensor(225.2196408677004 , grad = 1.0)\n",
      "Loss at Epoch 239 is : netwok_nn.tensor(224.93650782816596 , grad = 1.0)\n",
      "Loss at Epoch 240 is : netwok_nn.tensor(224.65356028870627 , grad = 1.0)\n",
      "Loss at Epoch 241 is : netwok_nn.tensor(224.37079865838078 , grad = 1.0)\n",
      "Loss at Epoch 242 is : netwok_nn.tensor(224.08822333979688 , grad = 1.0)\n",
      "Loss at Epoch 243 is : netwok_nn.tensor(223.80583472921535 , grad = 1.0)\n",
      "Loss at Epoch 244 is : netwok_nn.tensor(223.52363321665368 , grad = 1.0)\n",
      "Loss at Epoch 245 is : netwok_nn.tensor(223.2416191859872 , grad = 1.0)\n",
      "Loss at Epoch 246 is : netwok_nn.tensor(222.9597930150484 , grad = 1.0)\n",
      "Loss at Epoch 247 is : netwok_nn.tensor(222.67815507572453 , grad = 1.0)\n",
      "Loss at Epoch 248 is : netwok_nn.tensor(222.3967057340523 , grad = 1.0)\n",
      "Loss at Epoch 249 is : netwok_nn.tensor(222.11544535031183 , grad = 1.0)\n",
      "Loss at Epoch 250 is : netwok_nn.tensor(221.83437427911787 , grad = 1.0)\n",
      "Loss at Epoch 251 is : netwok_nn.tensor(221.55349286950982 , grad = 1.0)\n",
      "Loss at Epoch 252 is : netwok_nn.tensor(221.27280146503966 , grad = 1.0)\n",
      "Loss at Epoch 253 is : netwok_nn.tensor(220.99230040385825 , grad = 1.0)\n",
      "Loss at Epoch 254 is : netwok_nn.tensor(220.71199001879984 , grad = 1.0)\n",
      "Loss at Epoch 255 is : netwok_nn.tensor(220.43187063746527 , grad = 1.0)\n",
      "Loss at Epoch 256 is : netwok_nn.tensor(220.15194258230315 , grad = 1.0)\n",
      "Loss at Epoch 257 is : netwok_nn.tensor(219.87220617068996 , grad = 1.0)\n",
      "Loss at Epoch 258 is : netwok_nn.tensor(219.5926617150079 , grad = 1.0)\n",
      "Loss at Epoch 259 is : netwok_nn.tensor(219.3133095227218 , grad = 1.0)\n",
      "Loss at Epoch 260 is : netwok_nn.tensor(219.034149896455 , grad = 1.0)\n",
      "Loss at Epoch 261 is : netwok_nn.tensor(218.75518313406258 , grad = 1.0)\n",
      "Loss at Epoch 262 is : netwok_nn.tensor(218.47640952870395 , grad = 1.0)\n",
      "Loss at Epoch 263 is : netwok_nn.tensor(218.19782936891446 , grad = 1.0)\n",
      "Loss at Epoch 264 is : netwok_nn.tensor(217.91944293867485 , grad = 1.0)\n",
      "Loss at Epoch 265 is : netwok_nn.tensor(217.64125051747968 , grad = 1.0)\n",
      "Loss at Epoch 266 is : netwok_nn.tensor(217.36325238040487 , grad = 1.0)\n",
      "Loss at Epoch 267 is : netwok_nn.tensor(217.08544879817364 , grad = 1.0)\n",
      "Loss at Epoch 268 is : netwok_nn.tensor(216.80784003722113 , grad = 1.0)\n",
      "Loss at Epoch 269 is : netwok_nn.tensor(216.530426359758 , grad = 1.0)\n",
      "Loss at Epoch 270 is : netwok_nn.tensor(216.25320802383322 , grad = 1.0)\n",
      "Loss at Epoch 271 is : netwok_nn.tensor(215.97618528339478 , grad = 1.0)\n",
      "Loss at Epoch 272 is : netwok_nn.tensor(215.69935838835042 , grad = 1.0)\n",
      "Loss at Epoch 273 is : netwok_nn.tensor(215.42272758462627 , grad = 1.0)\n",
      "Loss at Epoch 274 is : netwok_nn.tensor(215.1462931142253 , grad = 1.0)\n",
      "Loss at Epoch 275 is : netwok_nn.tensor(214.87005521528383 , grad = 1.0)\n",
      "Loss at Epoch 276 is : netwok_nn.tensor(214.5940141221281 , grad = 1.0)\n",
      "Loss at Epoch 277 is : netwok_nn.tensor(214.31817006532853 , grad = 1.0)\n",
      "Loss at Epoch 278 is : netwok_nn.tensor(214.04252327175422 , grad = 1.0)\n",
      "Loss at Epoch 279 is : netwok_nn.tensor(213.7670739646258 , grad = 1.0)\n",
      "Loss at Epoch 280 is : netwok_nn.tensor(213.49182236356756 , grad = 1.0)\n",
      "Loss at Epoch 281 is : netwok_nn.tensor(213.21676868465858 , grad = 1.0)\n",
      "Loss at Epoch 282 is : netwok_nn.tensor(212.94191314048294 , grad = 1.0)\n",
      "Loss at Epoch 283 is : netwok_nn.tensor(212.66725594017942 , grad = 1.0)\n",
      "Loss at Epoch 284 is : netwok_nn.tensor(212.39279728948975 , grad = 1.0)\n",
      "Loss at Epoch 285 is : netwok_nn.tensor(212.11853739080644 , grad = 1.0)\n",
      "Loss at Epoch 286 is : netwok_nn.tensor(211.84447644321958 , grad = 1.0)\n",
      "Loss at Epoch 287 is : netwok_nn.tensor(211.57061464256304 , grad = 1.0)\n",
      "Loss at Epoch 288 is : netwok_nn.tensor(211.29695218145952 , grad = 1.0)\n",
      "Loss at Epoch 289 is : netwok_nn.tensor(211.0234892493655 , grad = 1.0)\n",
      "Loss at Epoch 290 is : netwok_nn.tensor(210.75022603261436 , grad = 1.0)\n",
      "Loss at Epoch 291 is : netwok_nn.tensor(210.47716271446004 , grad = 1.0)\n",
      "Loss at Epoch 292 is : netwok_nn.tensor(210.20429947511875 , grad = 1.0)\n",
      "Loss at Epoch 293 is : netwok_nn.tensor(209.93163649181105 , grad = 1.0)\n",
      "Loss at Epoch 294 is : netwok_nn.tensor(209.65917393880213 , grad = 1.0)\n",
      "Loss at Epoch 295 is : netwok_nn.tensor(209.38691198744263 , grad = 1.0)\n",
      "Loss at Epoch 296 is : netwok_nn.tensor(209.1148508062077 , grad = 1.0)\n",
      "Loss at Epoch 297 is : netwok_nn.tensor(208.84299056073593 , grad = 1.0)\n",
      "Loss at Epoch 298 is : netwok_nn.tensor(208.57133141386785 , grad = 1.0)\n",
      "Loss at Epoch 299 is : netwok_nn.tensor(208.2998735256831 , grad = 1.0)\n",
      "Loss at Epoch 300 is : netwok_nn.tensor(208.02861705353757 , grad = 1.0)\n",
      "Loss at Epoch 301 is : netwok_nn.tensor(207.75756215209987 , grad = 1.0)\n",
      "Loss at Epoch 302 is : netwok_nn.tensor(207.48670897338684 , grad = 1.0)\n",
      "Loss at Epoch 303 is : netwok_nn.tensor(207.21605766679917 , grad = 1.0)\n",
      "Loss at Epoch 304 is : netwok_nn.tensor(206.9456083791552 , grad = 1.0)\n",
      "Loss at Epoch 305 is : netwok_nn.tensor(206.6753612547259 , grad = 1.0)\n",
      "Loss at Epoch 306 is : netwok_nn.tensor(206.4053164352677 , grad = 1.0)\n",
      "Loss at Epoch 307 is : netwok_nn.tensor(206.13547406005569 , grad = 1.0)\n",
      "Loss at Epoch 308 is : netwok_nn.tensor(205.86583426591608 , grad = 1.0)\n",
      "Loss at Epoch 309 is : netwok_nn.tensor(205.59639718725805 , grad = 1.0)\n",
      "Loss at Epoch 310 is : netwok_nn.tensor(205.32716295610498 , grad = 1.0)\n",
      "Loss at Epoch 311 is : netwok_nn.tensor(205.0581317021257 , grad = 1.0)\n",
      "Loss at Epoch 312 is : netwok_nn.tensor(204.78930355266468 , grad = 1.0)\n",
      "Loss at Epoch 313 is : netwok_nn.tensor(204.52067863277196 , grad = 1.0)\n",
      "Loss at Epoch 314 is : netwok_nn.tensor(204.2522570652327 , grad = 1.0)\n",
      "Loss at Epoch 315 is : netwok_nn.tensor(203.98403897059598 , grad = 1.0)\n",
      "Loss at Epoch 316 is : netwok_nn.tensor(203.71602446720354 , grad = 1.0)\n",
      "Loss at Epoch 317 is : netwok_nn.tensor(203.44821367121781 , grad = 1.0)\n",
      "Loss at Epoch 318 is : netwok_nn.tensor(203.18060669664987 , grad = 1.0)\n",
      "Loss at Epoch 319 is : netwok_nn.tensor(202.91320365538596 , grad = 1.0)\n",
      "Loss at Epoch 320 is : netwok_nn.tensor(202.64600465721486 , grad = 1.0)\n",
      "Loss at Epoch 321 is : netwok_nn.tensor(202.37900980985418 , grad = 1.0)\n",
      "Loss at Epoch 322 is : netwok_nn.tensor(202.11221921897646 , grad = 1.0)\n",
      "Loss at Epoch 323 is : netwok_nn.tensor(201.84563298823446 , grad = 1.0)\n",
      "Loss at Epoch 324 is : netwok_nn.tensor(201.57925121928668 , grad = 1.0)\n",
      "Loss at Epoch 325 is : netwok_nn.tensor(201.31307401182184 , grad = 1.0)\n",
      "Loss at Epoch 326 is : netwok_nn.tensor(201.04710146358372 , grad = 1.0)\n",
      "Loss at Epoch 327 is : netwok_nn.tensor(200.78133367039504 , grad = 1.0)\n",
      "Loss at Epoch 328 is : netwok_nn.tensor(200.51577072618105 , grad = 1.0)\n",
      "Loss at Epoch 329 is : netwok_nn.tensor(200.25041272299302 , grad = 1.0)\n",
      "Loss at Epoch 330 is : netwok_nn.tensor(199.98525975103144 , grad = 1.0)\n",
      "Loss at Epoch 331 is : netwok_nn.tensor(199.7203118986684 , grad = 1.0)\n",
      "Loss at Epoch 332 is : netwok_nn.tensor(199.4555692524699 , grad = 1.0)\n",
      "Loss at Epoch 333 is : netwok_nn.tensor(199.19103189721798 , grad = 1.0)\n",
      "Loss at Epoch 334 is : netwok_nn.tensor(198.92669991593257 , grad = 1.0)\n",
      "Loss at Epoch 335 is : netwok_nn.tensor(198.66257338989234 , grad = 1.0)\n",
      "Loss at Epoch 336 is : netwok_nn.tensor(198.3986523986563 , grad = 1.0)\n",
      "Loss at Epoch 337 is : netwok_nn.tensor(198.134937020084 , grad = 1.0)\n",
      "Loss at Epoch 338 is : netwok_nn.tensor(197.87142733035645 , grad = 1.0)\n",
      "Loss at Epoch 339 is : netwok_nn.tensor(197.6081234039958 , grad = 1.0)\n",
      "Loss at Epoch 340 is : netwok_nn.tensor(197.34502531388551 , grad = 1.0)\n",
      "Loss at Epoch 341 is : netwok_nn.tensor(197.0821331312899 , grad = 1.0)\n",
      "Loss at Epoch 342 is : netwok_nn.tensor(196.81944692587288 , grad = 1.0)\n",
      "Loss at Epoch 343 is : netwok_nn.tensor(196.55696676571773 , grad = 1.0)\n",
      "Loss at Epoch 344 is : netwok_nn.tensor(196.29469271734524 , grad = 1.0)\n",
      "Loss at Epoch 345 is : netwok_nn.tensor(196.0326248457324 , grad = 1.0)\n",
      "Loss at Epoch 346 is : netwok_nn.tensor(195.77076321433051 , grad = 1.0)\n",
      "Loss at Epoch 347 is : netwok_nn.tensor(195.50910788508298 , grad = 1.0)\n",
      "Loss at Epoch 348 is : netwok_nn.tensor(195.24765891844342 , grad = 1.0)\n",
      "Loss at Epoch 349 is : netwok_nn.tensor(194.9864163733925 , grad = 1.0)\n",
      "Loss at Epoch 350 is : netwok_nn.tensor(194.72538030745554 , grad = 1.0)\n",
      "Loss at Epoch 351 is : netwok_nn.tensor(194.4645507767191 , grad = 1.0)\n",
      "Loss at Epoch 352 is : netwok_nn.tensor(194.2039278358482 , grad = 1.0)\n",
      "Loss at Epoch 353 is : netwok_nn.tensor(193.94351153810206 , grad = 1.0)\n",
      "Loss at Epoch 354 is : netwok_nn.tensor(193.683301935351 , grad = 1.0)\n",
      "Loss at Epoch 355 is : netwok_nn.tensor(193.4232990780919 , grad = 1.0)\n",
      "Loss at Epoch 356 is : netwok_nn.tensor(193.16350301546456 , grad = 1.0)\n",
      "Loss at Epoch 357 is : netwok_nn.tensor(192.9039137952666 , grad = 1.0)\n",
      "Loss at Epoch 358 is : netwok_nn.tensor(192.64453146396932 , grad = 1.0)\n",
      "Loss at Epoch 359 is : netwok_nn.tensor(192.38535606673253 , grad = 1.0)\n",
      "Loss at Epoch 360 is : netwok_nn.tensor(192.12638764741973 , grad = 1.0)\n",
      "Loss at Epoch 361 is : netwok_nn.tensor(191.86762624861265 , grad = 1.0)\n",
      "Loss at Epoch 362 is : netwok_nn.tensor(191.60907191162576 , grad = 1.0)\n",
      "Loss at Epoch 363 is : netwok_nn.tensor(191.35072467652074 , grad = 1.0)\n",
      "Loss at Epoch 364 is : netwok_nn.tensor(191.0925845821205 , grad = 1.0)\n",
      "Loss at Epoch 365 is : netwok_nn.tensor(190.83465166602312 , grad = 1.0)\n",
      "Loss at Epoch 366 is : netwok_nn.tensor(190.5769259646156 , grad = 1.0)\n",
      "Loss at Epoch 367 is : netwok_nn.tensor(190.3194075130876 , grad = 1.0)\n",
      "Loss at Epoch 368 is : netwok_nn.tensor(190.06209634544442 , grad = 1.0)\n",
      "Loss at Epoch 369 is : netwok_nn.tensor(189.80499249452063 , grad = 1.0)\n",
      "Loss at Epoch 370 is : netwok_nn.tensor(189.54809599199282 , grad = 1.0)\n",
      "Loss at Epoch 371 is : netwok_nn.tensor(189.29140686839256 , grad = 1.0)\n",
      "Loss at Epoch 372 is : netwok_nn.tensor(189.03492515311916 , grad = 1.0)\n",
      "Loss at Epoch 373 is : netwok_nn.tensor(188.77865087445196 , grad = 1.0)\n",
      "Loss at Epoch 374 is : netwok_nn.tensor(188.52258405956286 , grad = 1.0)\n",
      "Loss at Epoch 375 is : netwok_nn.tensor(188.26672473452848 , grad = 1.0)\n",
      "Loss at Epoch 376 is : netwok_nn.tensor(188.01107292434207 , grad = 1.0)\n",
      "Loss at Epoch 377 is : netwok_nn.tensor(187.7556286529255 , grad = 1.0)\n",
      "Loss at Epoch 378 is : netwok_nn.tensor(187.50039194314104 , grad = 1.0)\n",
      "Loss at Epoch 379 is : netwok_nn.tensor(187.24536281680258 , grad = 1.0)\n",
      "Loss at Epoch 380 is : netwok_nn.tensor(186.99054129468743 , grad = 1.0)\n",
      "Loss at Epoch 381 is : netwok_nn.tensor(186.73592739654737 , grad = 1.0)\n",
      "Loss at Epoch 382 is : netwok_nn.tensor(186.4815211411198 , grad = 1.0)\n",
      "Loss at Epoch 383 is : netwok_nn.tensor(186.22732254613874 , grad = 1.0)\n",
      "Loss at Epoch 384 is : netwok_nn.tensor(185.97333162834562 , grad = 1.0)\n",
      "Loss at Epoch 385 is : netwok_nn.tensor(185.71954840349997 , grad = 1.0)\n",
      "Loss at Epoch 386 is : netwok_nn.tensor(185.46597288638995 , grad = 1.0)\n",
      "Loss at Epoch 387 is : netwok_nn.tensor(185.2126050908428 , grad = 1.0)\n",
      "Loss at Epoch 388 is : netwok_nn.tensor(184.95944502973532 , grad = 1.0)\n",
      "Loss at Epoch 389 is : netwok_nn.tensor(184.70649271500366 , grad = 1.0)\n",
      "Loss at Epoch 390 is : netwok_nn.tensor(184.4537481576533 , grad = 1.0)\n",
      "Loss at Epoch 391 is : netwok_nn.tensor(184.20121136776976 , grad = 1.0)\n",
      "Loss at Epoch 392 is : netwok_nn.tensor(183.9488823545271 , grad = 1.0)\n",
      "Loss at Epoch 393 is : netwok_nn.tensor(183.69676112619862 , grad = 1.0)\n",
      "Loss at Epoch 394 is : netwok_nn.tensor(183.444847690166 , grad = 1.0)\n",
      "Loss at Epoch 395 is : netwok_nn.tensor(183.19314205292852 , grad = 1.0)\n",
      "Loss at Epoch 396 is : netwok_nn.tensor(182.94164422011286 , grad = 1.0)\n",
      "Loss at Epoch 397 is : netwok_nn.tensor(182.69035419648168 , grad = 1.0)\n",
      "Loss at Epoch 398 is : netwok_nn.tensor(182.439271985943 , grad = 1.0)\n",
      "Loss at Epoch 399 is : netwok_nn.tensor(182.18839759155927 , grad = 1.0)\n",
      "Loss at Epoch 400 is : netwok_nn.tensor(181.93773101555595 , grad = 1.0)\n",
      "Loss at Epoch 401 is : netwok_nn.tensor(181.68727225933029 , grad = 1.0)\n",
      "Loss at Epoch 402 is : netwok_nn.tensor(181.43702132346007 , grad = 1.0)\n",
      "Loss at Epoch 403 is : netwok_nn.tensor(181.1869782077121 , grad = 1.0)\n",
      "Loss at Epoch 404 is : netwok_nn.tensor(180.9371429110504 , grad = 1.0)\n",
      "Loss at Epoch 405 is : netwok_nn.tensor(180.68751543164475 , grad = 1.0)\n",
      "Loss at Epoch 406 is : netwok_nn.tensor(180.43809576687897 , grad = 1.0)\n",
      "Loss at Epoch 407 is : netwok_nn.tensor(180.18888391335872 , grad = 1.0)\n",
      "Loss at Epoch 408 is : netwok_nn.tensor(179.93987986691974 , grad = 1.0)\n",
      "Loss at Epoch 409 is : netwok_nn.tensor(179.6910836226356 , grad = 1.0)\n",
      "Loss at Epoch 410 is : netwok_nn.tensor(179.44249517482575 , grad = 1.0)\n",
      "Loss at Epoch 411 is : netwok_nn.tensor(179.19411451706296 , grad = 1.0)\n",
      "Loss at Epoch 412 is : netwok_nn.tensor(178.94594164218117 , grad = 1.0)\n",
      "Loss at Epoch 413 is : netwok_nn.tensor(178.69797654228296 , grad = 1.0)\n",
      "Loss at Epoch 414 is : netwok_nn.tensor(178.45021920874686 , grad = 1.0)\n",
      "Loss at Epoch 415 is : netwok_nn.tensor(178.20266963223497 , grad = 1.0)\n",
      "Loss at Epoch 416 is : netwok_nn.tensor(177.95532780269997 , grad = 1.0)\n",
      "Loss at Epoch 417 is : netwok_nn.tensor(177.70819370939248 , grad = 1.0)\n",
      "Loss at Epoch 418 is : netwok_nn.tensor(177.46126734086806 , grad = 1.0)\n",
      "Loss at Epoch 419 is : netwok_nn.tensor(177.21454868499433 , grad = 1.0)\n",
      "Loss at Epoch 420 is : netwok_nn.tensor(176.9680377289577 , grad = 1.0)\n",
      "Loss at Epoch 421 is : netwok_nn.tensor(176.72173445927052 , grad = 1.0)\n",
      "Loss at Epoch 422 is : netwok_nn.tensor(176.47563886177753 , grad = 1.0)\n",
      "Loss at Epoch 423 is : netwok_nn.tensor(176.22975092166268 , grad = 1.0)\n",
      "Loss at Epoch 424 is : netwok_nn.tensor(175.98407062345595 , grad = 1.0)\n",
      "Loss at Epoch 425 is : netwok_nn.tensor(175.73859795103948 , grad = 1.0)\n",
      "Loss at Epoch 426 is : netwok_nn.tensor(175.49333288765445 , grad = 1.0)\n",
      "Loss at Epoch 427 is : netwok_nn.tensor(175.24827541590696 , grad = 1.0)\n",
      "Loss at Epoch 428 is : netwok_nn.tensor(175.00342551777504 , grad = 1.0)\n",
      "Loss at Epoch 429 is : netwok_nn.tensor(174.75878317461402 , grad = 1.0)\n",
      "Loss at Epoch 430 is : netwok_nn.tensor(174.5143483671636 , grad = 1.0)\n",
      "Loss at Epoch 431 is : netwok_nn.tensor(174.2701210755531 , grad = 1.0)\n",
      "Loss at Epoch 432 is : netwok_nn.tensor(174.02610127930816 , grad = 1.0)\n",
      "Loss at Epoch 433 is : netwok_nn.tensor(173.78228895735637 , grad = 1.0)\n",
      "Loss at Epoch 434 is : netwok_nn.tensor(173.538684088033 , grad = 1.0)\n",
      "Loss at Epoch 435 is : netwok_nn.tensor(173.29528664908727 , grad = 1.0)\n",
      "Loss at Epoch 436 is : netwok_nn.tensor(173.0520966176877 , grad = 1.0)\n",
      "Loss at Epoch 437 is : netwok_nn.tensor(172.809113970428 , grad = 1.0)\n",
      "Loss at Epoch 438 is : netwok_nn.tensor(172.56633868333267 , grad = 1.0)\n",
      "Loss at Epoch 439 is : netwok_nn.tensor(172.32377073186245 , grad = 1.0)\n",
      "Loss at Epoch 440 is : netwok_nn.tensor(172.08141009092 , grad = 1.0)\n",
      "Loss at Epoch 441 is : netwok_nn.tensor(171.83925673485513 , grad = 1.0)\n",
      "Loss at Epoch 442 is : netwok_nn.tensor(171.5973106374703 , grad = 1.0)\n",
      "Loss at Epoch 443 is : netwok_nn.tensor(171.35557177202594 , grad = 1.0)\n",
      "Loss at Epoch 444 is : netwok_nn.tensor(171.11404011124566 , grad = 1.0)\n",
      "Loss at Epoch 445 is : netwok_nn.tensor(170.87271562732144 , grad = 1.0)\n",
      "Loss at Epoch 446 is : netwok_nn.tensor(170.6315982919189 , grad = 1.0)\n",
      "Loss at Epoch 447 is : netwok_nn.tensor(170.39068807618202 , grad = 1.0)\n",
      "Loss at Epoch 448 is : netwok_nn.tensor(170.14998495073857 , grad = 1.0)\n",
      "Loss at Epoch 449 is : netwok_nn.tensor(169.909488885705 , grad = 1.0)\n",
      "Loss at Epoch 450 is : netwok_nn.tensor(169.669199850691 , grad = 1.0)\n",
      "Loss at Epoch 451 is : netwok_nn.tensor(169.42911781480493 , grad = 1.0)\n",
      "Loss at Epoch 452 is : netwok_nn.tensor(169.18924274665807 , grad = 1.0)\n",
      "Loss at Epoch 453 is : netwok_nn.tensor(168.94957461436982 , grad = 1.0)\n",
      "Loss at Epoch 454 is : netwok_nn.tensor(168.7101133855721 , grad = 1.0)\n",
      "Loss at Epoch 455 is : netwok_nn.tensor(168.47085902741415 , grad = 1.0)\n",
      "Loss at Epoch 456 is : netwok_nn.tensor(168.23181150656703 , grad = 1.0)\n",
      "Loss at Epoch 457 is : netwok_nn.tensor(167.99297078922825 , grad = 1.0)\n",
      "Loss at Epoch 458 is : netwok_nn.tensor(167.7543368411263 , grad = 1.0)\n",
      "Loss at Epoch 459 is : netwok_nn.tensor(167.51590962752505 , grad = 1.0)\n",
      "Loss at Epoch 460 is : netwok_nn.tensor(167.27768911322798 , grad = 1.0)\n",
      "Loss at Epoch 461 is : netwok_nn.tensor(167.03967526258285 , grad = 1.0)\n",
      "Loss at Epoch 462 is : netwok_nn.tensor(166.8018680394859 , grad = 1.0)\n",
      "Loss at Epoch 463 is : netwok_nn.tensor(166.56426740738593 , grad = 1.0)\n",
      "Loss at Epoch 464 is : netwok_nn.tensor(166.32687332928873 , grad = 1.0)\n",
      "Loss at Epoch 465 is : netwok_nn.tensor(166.08968576776115 , grad = 1.0)\n",
      "Loss at Epoch 466 is : netwok_nn.tensor(165.85270468493533 , grad = 1.0)\n",
      "Loss at Epoch 467 is : netwok_nn.tensor(165.61593004251262 , grad = 1.0)\n",
      "Loss at Epoch 468 is : netwok_nn.tensor(165.3793618017678 , grad = 1.0)\n",
      "Loss at Epoch 469 is : netwok_nn.tensor(165.14299992355285 , grad = 1.0)\n",
      "Loss at Epoch 470 is : netwok_nn.tensor(164.9068443683011 , grad = 1.0)\n",
      "Loss at Epoch 471 is : netwok_nn.tensor(164.67089509603116 , grad = 1.0)\n",
      "Loss at Epoch 472 is : netwok_nn.tensor(164.43515206635053 , grad = 1.0)\n",
      "Loss at Epoch 473 is : netwok_nn.tensor(164.19961523845978 , grad = 1.0)\n",
      "Loss at Epoch 474 is : netwok_nn.tensor(163.96428457115607 , grad = 1.0)\n",
      "Loss at Epoch 475 is : netwok_nn.tensor(163.72916002283696 , grad = 1.0)\n",
      "Loss at Epoch 476 is : netwok_nn.tensor(163.49424155150427 , grad = 1.0)\n",
      "Loss at Epoch 477 is : netwok_nn.tensor(163.25952911476762 , grad = 1.0)\n",
      "Loss at Epoch 478 is : netwok_nn.tensor(163.02502266984803 , grad = 1.0)\n",
      "Loss at Epoch 479 is : netwok_nn.tensor(162.7907221735815 , grad = 1.0)\n",
      "Loss at Epoch 480 is : netwok_nn.tensor(162.55662758242283 , grad = 1.0)\n",
      "Loss at Epoch 481 is : netwok_nn.tensor(162.32273885244874 , grad = 1.0)\n",
      "Loss at Epoch 482 is : netwok_nn.tensor(162.08905593936169 , grad = 1.0)\n",
      "Loss at Epoch 483 is : netwok_nn.tensor(161.85557879849318 , grad = 1.0)\n",
      "Loss at Epoch 484 is : netwok_nn.tensor(161.6223073848072 , grad = 1.0)\n",
      "Loss at Epoch 485 is : netwok_nn.tensor(161.3892416529035 , grad = 1.0)\n",
      "Loss at Epoch 486 is : netwok_nn.tensor(161.15638155702115 , grad = 1.0)\n",
      "Loss at Epoch 487 is : netwok_nn.tensor(160.92372705104168 , grad = 1.0)\n",
      "Loss at Epoch 488 is : netwok_nn.tensor(160.69127808849234 , grad = 1.0)\n",
      "Loss at Epoch 489 is : netwok_nn.tensor(160.45903462254944 , grad = 1.0)\n",
      "Loss at Epoch 490 is : netwok_nn.tensor(160.22699660604158 , grad = 1.0)\n",
      "Loss at Epoch 491 is : netwok_nn.tensor(159.99516399145267 , grad = 1.0)\n",
      "Loss at Epoch 492 is : netwok_nn.tensor(159.76353673092524 , grad = 1.0)\n",
      "Loss at Epoch 493 is : netwok_nn.tensor(159.53211477626348 , grad = 1.0)\n",
      "Loss at Epoch 494 is : netwok_nn.tensor(159.30089807893634 , grad = 1.0)\n",
      "Loss at Epoch 495 is : netwok_nn.tensor(159.0698865900805 , grad = 1.0)\n",
      "Loss at Epoch 496 is : netwok_nn.tensor(158.8390802605035 , grad = 1.0)\n",
      "Loss at Epoch 497 is : netwok_nn.tensor(158.60847904068666 , grad = 1.0)\n",
      "Loss at Epoch 498 is : netwok_nn.tensor(158.37808288078813 , grad = 1.0)\n",
      "Loss at Epoch 499 is : netwok_nn.tensor(158.1478917306456 , grad = 1.0)\n",
      "Loss at Epoch 500 is : netwok_nn.tensor(157.91790553977953 , grad = 1.0)\n",
      "Loss at Epoch 501 is : netwok_nn.tensor(157.68812425739569 , grad = 1.0)\n",
      "Loss at Epoch 502 is : netwok_nn.tensor(157.45854783238826 , grad = 1.0)\n",
      "Loss at Epoch 503 is : netwok_nn.tensor(157.2291762133425 , grad = 1.0)\n",
      "Loss at Epoch 504 is : netwok_nn.tensor(157.00000934853756 , grad = 1.0)\n",
      "Loss at Epoch 505 is : netwok_nn.tensor(156.77104718594924 , grad = 1.0)\n",
      "Loss at Epoch 506 is : netwok_nn.tensor(156.54228967325275 , grad = 1.0)\n",
      "Loss at Epoch 507 is : netwok_nn.tensor(156.31373675782544 , grad = 1.0)\n",
      "Loss at Epoch 508 is : netwok_nn.tensor(156.08538838674932 , grad = 1.0)\n",
      "Loss at Epoch 509 is : netwok_nn.tensor(155.85724450681388 , grad = 1.0)\n",
      "Loss at Epoch 510 is : netwok_nn.tensor(155.62930506451877 , grad = 1.0)\n",
      "Loss at Epoch 511 is : netwok_nn.tensor(155.4015700060761 , grad = 1.0)\n",
      "Loss at Epoch 512 is : netwok_nn.tensor(155.17403927741333 , grad = 1.0)\n",
      "Loss at Epoch 513 is : netwok_nn.tensor(154.94671282417568 , grad = 1.0)\n",
      "Loss at Epoch 514 is : netwok_nn.tensor(154.71959059172855 , grad = 1.0)\n",
      "Loss at Epoch 515 is : netwok_nn.tensor(154.4926725251603 , grad = 1.0)\n",
      "Loss at Epoch 516 is : netwok_nn.tensor(154.2659585692844 , grad = 1.0)\n",
      "Loss at Epoch 517 is : netwok_nn.tensor(154.03944866864222 , grad = 1.0)\n",
      "Loss at Epoch 518 is : netwok_nn.tensor(153.81314276750516 , grad = 1.0)\n",
      "Loss at Epoch 519 is : netwok_nn.tensor(153.58704080987712 , grad = 1.0)\n",
      "Loss at Epoch 520 is : netwok_nn.tensor(153.36114273949707 , grad = 1.0)\n",
      "Loss at Epoch 521 is : netwok_nn.tensor(153.13544849984117 , grad = 1.0)\n",
      "Loss at Epoch 522 is : netwok_nn.tensor(152.90995803412528 , grad = 1.0)\n",
      "Loss at Epoch 523 is : netwok_nn.tensor(152.68467128530708 , grad = 1.0)\n",
      "Loss at Epoch 524 is : netwok_nn.tensor(152.45958819608862 , grad = 1.0)\n",
      "Loss at Epoch 525 is : netwok_nn.tensor(152.2347087089184 , grad = 1.0)\n",
      "Loss at Epoch 526 is : netwok_nn.tensor(152.01003276599351 , grad = 1.0)\n",
      "Loss at Epoch 527 is : netwok_nn.tensor(151.7855603092623 , grad = 1.0)\n",
      "Loss at Epoch 528 is : netwok_nn.tensor(151.56129128042602 , grad = 1.0)\n",
      "Loss at Epoch 529 is : netwok_nn.tensor(151.33722562094152 , grad = 1.0)\n",
      "Loss at Epoch 530 is : netwok_nn.tensor(151.1133632720229 , grad = 1.0)\n",
      "Loss at Epoch 531 is : netwok_nn.tensor(150.88970417464415 , grad = 1.0)\n",
      "Loss at Epoch 532 is : netwok_nn.tensor(150.66624826954097 , grad = 1.0)\n",
      "Loss at Epoch 533 is : netwok_nn.tensor(150.44299549721288 , grad = 1.0)\n",
      "Loss at Epoch 534 is : netwok_nn.tensor(150.21994579792542 , grad = 1.0)\n",
      "Loss at Epoch 535 is : netwok_nn.tensor(149.9970991117122 , grad = 1.0)\n",
      "Loss at Epoch 536 is : netwok_nn.tensor(149.77445537837687 , grad = 1.0)\n",
      "Loss at Epoch 537 is : netwok_nn.tensor(149.55201453749515 , grad = 1.0)\n",
      "Loss at Epoch 538 is : netwok_nn.tensor(149.32977652841686 , grad = 1.0)\n",
      "Loss at Epoch 539 is : netwok_nn.tensor(149.107741290268 , grad = 1.0)\n",
      "Loss at Epoch 540 is : netwok_nn.tensor(148.88590876195246 , grad = 1.0)\n",
      "Loss at Epoch 541 is : netwok_nn.tensor(148.66427888215435 , grad = 1.0)\n",
      "Loss at Epoch 542 is : netwok_nn.tensor(148.44285158933954 , grad = 1.0)\n",
      "Loss at Epoch 543 is : netwok_nn.tensor(148.22162682175787 , grad = 1.0)\n",
      "Loss at Epoch 544 is : netwok_nn.tensor(148.0006045174448 , grad = 1.0)\n",
      "Loss at Epoch 545 is : netwok_nn.tensor(147.7797846142235 , grad = 1.0)\n",
      "Loss at Epoch 546 is : netwok_nn.tensor(147.55916704970664 , grad = 1.0)\n",
      "Loss at Epoch 547 is : netwok_nn.tensor(147.33875176129823 , grad = 1.0)\n",
      "Loss at Epoch 548 is : netwok_nn.tensor(147.11853868619528 , grad = 1.0)\n",
      "Loss at Epoch 549 is : netwok_nn.tensor(146.89852776139006 , grad = 1.0)\n",
      "Loss at Epoch 550 is : netwok_nn.tensor(146.67871892367128 , grad = 1.0)\n",
      "Loss at Epoch 551 is : netwok_nn.tensor(146.4591121096264 , grad = 1.0)\n",
      "Loss at Epoch 552 is : netwok_nn.tensor(146.23970725564308 , grad = 1.0)\n",
      "Loss at Epoch 553 is : netwok_nn.tensor(146.02050429791106 , grad = 1.0)\n",
      "Loss at Epoch 554 is : netwok_nn.tensor(145.80150317242385 , grad = 1.0)\n",
      "Loss at Epoch 555 is : netwok_nn.tensor(145.58270381498048 , grad = 1.0)\n",
      "Loss at Epoch 556 is : netwok_nn.tensor(145.36410616118698 , grad = 1.0)\n",
      "Loss at Epoch 557 is : netwok_nn.tensor(145.1457101464585 , grad = 1.0)\n",
      "Loss at Epoch 558 is : netwok_nn.tensor(144.9275157060205 , grad = 1.0)\n",
      "Loss at Epoch 559 is : netwok_nn.tensor(144.70952277491085 , grad = 1.0)\n",
      "Loss at Epoch 560 is : netwok_nn.tensor(144.49173128798097 , grad = 1.0)\n",
      "Loss at Epoch 561 is : netwok_nn.tensor(144.27414117989792 , grad = 1.0)\n",
      "Loss at Epoch 562 is : netwok_nn.tensor(144.0567523851457 , grad = 1.0)\n",
      "Loss at Epoch 563 is : netwok_nn.tensor(143.83956483802703 , grad = 1.0)\n",
      "Loss at Epoch 564 is : netwok_nn.tensor(143.62257847266477 , grad = 1.0)\n",
      "Loss at Epoch 565 is : netwok_nn.tensor(143.40579322300363 , grad = 1.0)\n",
      "Loss at Epoch 566 is : netwok_nn.tensor(143.18920902281155 , grad = 1.0)\n",
      "Loss at Epoch 567 is : netwok_nn.tensor(142.97282580568145 , grad = 1.0)\n",
      "Loss at Epoch 568 is : netwok_nn.tensor(142.75664350503266 , grad = 1.0)\n",
      "Loss at Epoch 569 is : netwok_nn.tensor(142.5406620541122 , grad = 1.0)\n",
      "Loss at Epoch 570 is : netwok_nn.tensor(142.3248813859968 , grad = 1.0)\n",
      "Loss at Epoch 571 is : netwok_nn.tensor(142.1093014335938 , grad = 1.0)\n",
      "Loss at Epoch 572 is : netwok_nn.tensor(141.893922129643 , grad = 1.0)\n",
      "Loss at Epoch 573 is : netwok_nn.tensor(141.678743406718 , grad = 1.0)\n",
      "Loss at Epoch 574 is : netwok_nn.tensor(141.4637651972277 , grad = 1.0)\n",
      "Loss at Epoch 575 is : netwok_nn.tensor(141.24898743341757 , grad = 1.0)\n",
      "Loss at Epoch 576 is : netwok_nn.tensor(141.0344100473712 , grad = 1.0)\n",
      "Loss at Epoch 577 is : netwok_nn.tensor(140.8200329710118 , grad = 1.0)\n",
      "Loss at Epoch 578 is : netwok_nn.tensor(140.60585613610334 , grad = 1.0)\n",
      "Loss at Epoch 579 is : netwok_nn.tensor(140.39187947425208 , grad = 1.0)\n",
      "Loss at Epoch 580 is : netwok_nn.tensor(140.178102916908 , grad = 1.0)\n",
      "Loss at Epoch 581 is : netwok_nn.tensor(139.964526395366 , grad = 1.0)\n",
      "Loss at Epoch 582 is : netwok_nn.tensor(139.75114984076737 , grad = 1.0)\n",
      "Loss at Epoch 583 is : netwok_nn.tensor(139.5379731841011 , grad = 1.0)\n",
      "Loss at Epoch 584 is : netwok_nn.tensor(139.32499635620516 , grad = 1.0)\n",
      "Loss at Epoch 585 is : netwok_nn.tensor(139.11221928776777 , grad = 1.0)\n",
      "Loss at Epoch 586 is : netwok_nn.tensor(138.89964190932892 , grad = 1.0)\n",
      "Loss at Epoch 587 is : netwok_nn.tensor(138.68726415128123 , grad = 1.0)\n",
      "Loss at Epoch 588 is : netwok_nn.tensor(138.47508594387182 , grad = 1.0)\n",
      "Loss at Epoch 589 is : netwok_nn.tensor(138.26310721720304 , grad = 1.0)\n",
      "Loss at Epoch 590 is : netwok_nn.tensor(138.05132790123392 , grad = 1.0)\n",
      "Loss at Epoch 591 is : netwok_nn.tensor(137.8397479257815 , grad = 1.0)\n",
      "Loss at Epoch 592 is : netwok_nn.tensor(137.62836722052205 , grad = 1.0)\n",
      "Loss at Epoch 593 is : netwok_nn.tensor(137.41718571499206 , grad = 1.0)\n",
      "Loss at Epoch 594 is : netwok_nn.tensor(137.20620333858977 , grad = 1.0)\n",
      "Loss at Epoch 595 is : netwok_nn.tensor(136.99542002057618 , grad = 1.0)\n",
      "Loss at Epoch 596 is : netwok_nn.tensor(136.78483569007622 , grad = 1.0)\n",
      "Loss at Epoch 597 is : netwok_nn.tensor(136.57445027608006 , grad = 1.0)\n",
      "Loss at Epoch 598 is : netwok_nn.tensor(136.36426370744422 , grad = 1.0)\n",
      "Loss at Epoch 599 is : netwok_nn.tensor(136.15427591289273 , grad = 1.0)\n",
      "Loss at Epoch 600 is : netwok_nn.tensor(135.94448682101824 , grad = 1.0)\n",
      "Loss at Epoch 601 is : netwok_nn.tensor(135.7348963602832 , grad = 1.0)\n",
      "Loss at Epoch 602 is : netwok_nn.tensor(135.525504459021 , grad = 1.0)\n",
      "Loss at Epoch 603 is : netwok_nn.tensor(135.3163110454371 , grad = 1.0)\n",
      "Loss at Epoch 604 is : netwok_nn.tensor(135.10731604761003 , grad = 1.0)\n",
      "Loss at Epoch 605 is : netwok_nn.tensor(134.8985193934928 , grad = 1.0)\n",
      "Loss at Epoch 606 is : netwok_nn.tensor(134.68992101091348 , grad = 1.0)\n",
      "Loss at Epoch 607 is : netwok_nn.tensor(134.48152082757684 , grad = 1.0)\n",
      "Loss at Epoch 608 is : netwok_nn.tensor(134.27331877106502 , grad = 1.0)\n",
      "Loss at Epoch 609 is : netwok_nn.tensor(134.0653147688388 , grad = 1.0)\n",
      "Loss at Epoch 610 is : netwok_nn.tensor(133.8575087482385 , grad = 1.0)\n",
      "Loss at Epoch 611 is : netwok_nn.tensor(133.64990063648528 , grad = 1.0)\n",
      "Loss at Epoch 612 is : netwok_nn.tensor(133.44249036068194 , grad = 1.0)\n",
      "Loss at Epoch 613 is : netwok_nn.tensor(133.23527784781402 , grad = 1.0)\n",
      "Loss at Epoch 614 is : netwok_nn.tensor(133.0282630247509 , grad = 1.0)\n",
      "Loss at Epoch 615 is : netwok_nn.tensor(132.82144581824662 , grad = 1.0)\n",
      "Loss at Epoch 616 is : netwok_nn.tensor(132.61482615494126 , grad = 1.0)\n",
      "Loss at Epoch 617 is : netwok_nn.tensor(132.40840396136136 , grad = 1.0)\n",
      "Loss at Epoch 618 is : netwok_nn.tensor(132.20217916392158 , grad = 1.0)\n",
      "Loss at Epoch 619 is : netwok_nn.tensor(131.996151688925 , grad = 1.0)\n",
      "Loss at Epoch 620 is : netwok_nn.tensor(131.79032146256475 , grad = 1.0)\n",
      "Loss at Epoch 621 is : netwok_nn.tensor(131.58468841092446 , grad = 1.0)\n",
      "Loss at Epoch 622 is : netwok_nn.tensor(131.3792524599794 , grad = 1.0)\n",
      "Loss at Epoch 623 is : netwok_nn.tensor(131.17401353559757 , grad = 1.0)\n",
      "Loss at Epoch 624 is : netwok_nn.tensor(130.96897156354035 , grad = 1.0)\n",
      "Loss at Epoch 625 is : netwok_nn.tensor(130.76412646946372 , grad = 1.0)\n",
      "Loss at Epoch 626 is : netwok_nn.tensor(130.559478178919 , grad = 1.0)\n",
      "Loss at Epoch 627 is : netwok_nn.tensor(130.35502661735373 , grad = 1.0)\n",
      "Loss at Epoch 628 is : netwok_nn.tensor(130.15077171011288 , grad = 1.0)\n",
      "Loss at Epoch 629 is : netwok_nn.tensor(129.94671338243927 , grad = 1.0)\n",
      "Loss at Epoch 630 is : netwok_nn.tensor(129.74285155947504 , grad = 1.0)\n",
      "Loss at Epoch 631 is : netwok_nn.tensor(129.53918616626189 , grad = 1.0)\n",
      "Loss at Epoch 632 is : netwok_nn.tensor(129.33571712774256 , grad = 1.0)\n",
      "Loss at Epoch 633 is : netwok_nn.tensor(129.13244436876133 , grad = 1.0)\n",
      "Loss at Epoch 634 is : netwok_nn.tensor(128.92936781406507 , grad = 1.0)\n",
      "Loss at Epoch 635 is : netwok_nn.tensor(128.72648738830395 , grad = 1.0)\n",
      "Loss at Epoch 636 is : netwok_nn.tensor(128.52380301603236 , grad = 1.0)\n",
      "Loss at Epoch 637 is : netwok_nn.tensor(128.32131462170983 , grad = 1.0)\n",
      "Loss at Epoch 638 is : netwok_nn.tensor(128.1190221297017 , grad = 1.0)\n",
      "Loss at Epoch 639 is : netwok_nn.tensor(127.91692546428027 , grad = 1.0)\n",
      "Loss at Epoch 640 is : netwok_nn.tensor(127.71502454962503 , grad = 1.0)\n",
      "Loss at Epoch 641 is : netwok_nn.tensor(127.51331930982418 , grad = 1.0)\n",
      "Loss at Epoch 642 is : netwok_nn.tensor(127.31180966887496 , grad = 1.0)\n",
      "Loss at Epoch 643 is : netwok_nn.tensor(127.11049555068465 , grad = 1.0)\n",
      "Loss at Epoch 644 is : netwok_nn.tensor(126.90937687907126 , grad = 1.0)\n",
      "Loss at Epoch 645 is : netwok_nn.tensor(126.70845357776444 , grad = 1.0)\n",
      "Loss at Epoch 646 is : netwok_nn.tensor(126.50772557040618 , grad = 1.0)\n",
      "Loss at Epoch 647 is : netwok_nn.tensor(126.30719278055163 , grad = 1.0)\n",
      "Loss at Epoch 648 is : netwok_nn.tensor(126.1068551316698 , grad = 1.0)\n",
      "Loss at Epoch 649 is : netwok_nn.tensor(125.90671254714452 , grad = 1.0)\n",
      "Loss at Epoch 650 is : netwok_nn.tensor(125.70676495027489 , grad = 1.0)\n",
      "Loss at Epoch 651 is : netwok_nn.tensor(125.50701226427626 , grad = 1.0)\n",
      "Loss at Epoch 652 is : netwok_nn.tensor(125.307454412281 , grad = 1.0)\n",
      "Loss at Epoch 653 is : netwok_nn.tensor(125.10809131733902 , grad = 1.0)\n",
      "Loss at Epoch 654 is : netwok_nn.tensor(124.90892290241884 , grad = 1.0)\n",
      "Loss at Epoch 655 is : netwok_nn.tensor(124.7099490904079 , grad = 1.0)\n",
      "Loss at Epoch 656 is : netwok_nn.tensor(124.51116980411369 , grad = 1.0)\n",
      "Loss at Epoch 657 is : netwok_nn.tensor(124.31258496626423 , grad = 1.0)\n",
      "Loss at Epoch 658 is : netwok_nn.tensor(124.11419449950876 , grad = 1.0)\n",
      "Loss at Epoch 659 is : netwok_nn.tensor(123.91599832641869 , grad = 1.0)\n",
      "Loss at Epoch 660 is : netwok_nn.tensor(123.717996369488 , grad = 1.0)\n",
      "Loss at Epoch 661 is : netwok_nn.tensor(123.52018855113415 , grad = 1.0)\n",
      "Loss at Epoch 662 is : netwok_nn.tensor(123.32257479369868 , grad = 1.0)\n",
      "Loss at Epoch 663 is : netwok_nn.tensor(123.12515501944785 , grad = 1.0)\n",
      "Loss at Epoch 664 is : netwok_nn.tensor(122.92792915057336 , grad = 1.0)\n",
      "Loss at Epoch 665 is : netwok_nn.tensor(122.73089710919322 , grad = 1.0)\n",
      "Loss at Epoch 666 is : netwok_nn.tensor(122.53405881735209 , grad = 1.0)\n",
      "Loss at Epoch 667 is : netwok_nn.tensor(122.33741419702206 , grad = 1.0)\n",
      "Loss at Epoch 668 is : netwok_nn.tensor(122.14096317010336 , grad = 1.0)\n",
      "Loss at Epoch 669 is : netwok_nn.tensor(121.94470565842514 , grad = 1.0)\n",
      "Loss at Epoch 670 is : netwok_nn.tensor(121.74864158374578 , grad = 1.0)\n",
      "Loss at Epoch 671 is : netwok_nn.tensor(121.55277086775376 , grad = 1.0)\n",
      "Loss at Epoch 672 is : netwok_nn.tensor(121.3570934320684 , grad = 1.0)\n",
      "Loss at Epoch 673 is : netwok_nn.tensor(121.1616091982401 , grad = 1.0)\n",
      "Loss at Epoch 674 is : netwok_nn.tensor(120.96631808775139 , grad = 1.0)\n",
      "Loss at Epoch 675 is : netwok_nn.tensor(120.77122002201742 , grad = 1.0)\n",
      "Loss at Epoch 676 is : netwok_nn.tensor(120.57631492238636 , grad = 1.0)\n",
      "Loss at Epoch 677 is : netwok_nn.tensor(120.3816027101403 , grad = 1.0)\n",
      "Loss at Epoch 678 is : netwok_nn.tensor(120.18708330649577 , grad = 1.0)\n",
      "Loss at Epoch 679 is : netwok_nn.tensor(119.99275663260423 , grad = 1.0)\n",
      "Loss at Epoch 680 is : netwok_nn.tensor(119.79862260955281 , grad = 1.0)\n",
      "Loss at Epoch 681 is : netwok_nn.tensor(119.60468115836487 , grad = 1.0)\n",
      "Loss at Epoch 682 is : netwok_nn.tensor(119.4109322000005 , grad = 1.0)\n",
      "Loss at Epoch 683 is : netwok_nn.tensor(119.21737565535723 , grad = 1.0)\n",
      "Loss at Epoch 684 is : netwok_nn.tensor(119.02401144527057 , grad = 1.0)\n",
      "Loss at Epoch 685 is : netwok_nn.tensor(118.83083949051448 , grad = 1.0)\n",
      "Loss at Epoch 686 is : netwok_nn.tensor(118.63785971180208 , grad = 1.0)\n",
      "Loss at Epoch 687 is : netwok_nn.tensor(118.44507202978622 , grad = 1.0)\n",
      "Loss at Epoch 688 is : netwok_nn.tensor(118.25247636505992 , grad = 1.0)\n",
      "Loss at Epoch 689 is : netwok_nn.tensor(118.06007263815704 , grad = 1.0)\n",
      "Loss at Epoch 690 is : netwok_nn.tensor(117.86786076955266 , grad = 1.0)\n",
      "Loss at Epoch 691 is : netwok_nn.tensor(117.67584067966398 , grad = 1.0)\n",
      "Loss at Epoch 692 is : netwok_nn.tensor(117.48401228885041 , grad = 1.0)\n",
      "Loss at Epoch 693 is : netwok_nn.tensor(117.29237551741447 , grad = 1.0)\n",
      "Loss at Epoch 694 is : netwok_nn.tensor(117.10093028560225 , grad = 1.0)\n",
      "Loss at Epoch 695 is : netwok_nn.tensor(116.9096765136037 , grad = 1.0)\n",
      "Loss at Epoch 696 is : netwok_nn.tensor(116.71861412155354 , grad = 1.0)\n",
      "Loss at Epoch 697 is : netwok_nn.tensor(116.52774302953148 , grad = 1.0)\n",
      "Loss at Epoch 698 is : netwok_nn.tensor(116.33706315756297 , grad = 1.0)\n",
      "Loss at Epoch 699 is : netwok_nn.tensor(116.14657442561943 , grad = 1.0)\n",
      "Loss at Epoch 700 is : netwok_nn.tensor(115.95627675361908 , grad = 1.0)\n",
      "Loss at Epoch 701 is : netwok_nn.tensor(115.76617006142715 , grad = 1.0)\n",
      "Loss at Epoch 702 is : netwok_nn.tensor(115.57625426885664 , grad = 1.0)\n",
      "Loss at Epoch 703 is : netwok_nn.tensor(115.38652929566875 , grad = 1.0)\n",
      "Loss at Epoch 704 is : netwok_nn.tensor(115.19699506157325 , grad = 1.0)\n",
      "Loss at Epoch 705 is : netwok_nn.tensor(115.00765148622908 , grad = 1.0)\n",
      "Loss at Epoch 706 is : netwok_nn.tensor(114.81849848924486 , grad = 1.0)\n",
      "Loss at Epoch 707 is : netwok_nn.tensor(114.6295359901793 , grad = 1.0)\n",
      "Loss at Epoch 708 is : netwok_nn.tensor(114.44076390854167 , grad = 1.0)\n",
      "Loss at Epoch 709 is : netwok_nn.tensor(114.2521821637924 , grad = 1.0)\n",
      "Loss at Epoch 710 is : netwok_nn.tensor(114.0637906753435 , grad = 1.0)\n",
      "Loss at Epoch 711 is : netwok_nn.tensor(113.8755893625589 , grad = 1.0)\n",
      "Loss at Epoch 712 is : netwok_nn.tensor(113.68757814475512 , grad = 1.0)\n",
      "Loss at Epoch 713 is : netwok_nn.tensor(113.4997569412016 , grad = 1.0)\n",
      "Loss at Epoch 714 is : netwok_nn.tensor(113.31212567112127 , grad = 1.0)\n",
      "Loss at Epoch 715 is : netwok_nn.tensor(113.12468425369076 , grad = 1.0)\n",
      "Loss at Epoch 716 is : netwok_nn.tensor(112.93743260804122 , grad = 1.0)\n",
      "Loss at Epoch 717 is : netwok_nn.tensor(112.75037065325849 , grad = 1.0)\n",
      "Loss at Epoch 718 is : netwok_nn.tensor(112.56349830838363 , grad = 1.0)\n",
      "Loss at Epoch 719 is : netwok_nn.tensor(112.37681549241333 , grad = 1.0)\n",
      "Loss at Epoch 720 is : netwok_nn.tensor(112.1903221243005 , grad = 1.0)\n",
      "Loss at Epoch 721 is : netwok_nn.tensor(112.00401812295446 , grad = 1.0)\n",
      "Loss at Epoch 722 is : netwok_nn.tensor(111.81790340724159 , grad = 1.0)\n",
      "Loss at Epoch 723 is : netwok_nn.tensor(111.63197789598567 , grad = 1.0)\n",
      "Loss at Epoch 724 is : netwok_nn.tensor(111.44624150796822 , grad = 1.0)\n",
      "Loss at Epoch 725 is : netwok_nn.tensor(111.26069416192911 , grad = 1.0)\n",
      "Loss at Epoch 726 is : netwok_nn.tensor(111.07533577656685 , grad = 1.0)\n",
      "Loss at Epoch 727 is : netwok_nn.tensor(110.89016627053897 , grad = 1.0)\n",
      "Loss at Epoch 728 is : netwok_nn.tensor(110.70518556246266 , grad = 1.0)\n",
      "Loss at Epoch 729 is : netwok_nn.tensor(110.52039357091483 , grad = 1.0)\n",
      "Loss at Epoch 730 is : netwok_nn.tensor(110.33579021443285 , grad = 1.0)\n",
      "Loss at Epoch 731 is : netwok_nn.tensor(110.15137541151472 , grad = 1.0)\n",
      "Loss at Epoch 732 is : netwok_nn.tensor(109.96714908061966 , grad = 1.0)\n",
      "Loss at Epoch 733 is : netwok_nn.tensor(109.78311114016826 , grad = 1.0)\n",
      "Loss at Epoch 734 is : netwok_nn.tensor(109.59926150854314 , grad = 1.0)\n",
      "Loss at Epoch 735 is : netwok_nn.tensor(109.41560010408922 , grad = 1.0)\n",
      "Loss at Epoch 736 is : netwok_nn.tensor(109.23212684511407 , grad = 1.0)\n",
      "Loss at Epoch 737 is : netwok_nn.tensor(109.0488416498884 , grad = 1.0)\n",
      "Loss at Epoch 738 is : netwok_nn.tensor(108.86574443664632 , grad = 1.0)\n",
      "Loss at Epoch 739 is : netwok_nn.tensor(108.68283512358585 , grad = 1.0)\n",
      "Loss at Epoch 740 is : netwok_nn.tensor(108.50011362886914 , grad = 1.0)\n",
      "Loss at Epoch 741 is : netwok_nn.tensor(108.31757987062304 , grad = 1.0)\n",
      "Loss at Epoch 742 is : netwok_nn.tensor(108.13523376693928 , grad = 1.0)\n",
      "Loss at Epoch 743 is : netwok_nn.tensor(107.95307523587503 , grad = 1.0)\n",
      "Loss at Epoch 744 is : netwok_nn.tensor(107.77110419545305 , grad = 1.0)\n",
      "Loss at Epoch 745 is : netwok_nn.tensor(107.58932056366223 , grad = 1.0)\n",
      "Loss at Epoch 746 is : netwok_nn.tensor(107.40772425845786 , grad = 1.0)\n",
      "Loss at Epoch 747 is : netwok_nn.tensor(107.22631519776205 , grad = 1.0)\n",
      "Loss at Epoch 748 is : netwok_nn.tensor(107.04509329946403 , grad = 1.0)\n",
      "Loss at Epoch 749 is : netwok_nn.tensor(106.86405848142053 , grad = 1.0)\n",
      "Loss at Epoch 750 is : netwok_nn.tensor(106.68321066145613 , grad = 1.0)\n",
      "Loss at Epoch 751 is : netwok_nn.tensor(106.50254975736355 , grad = 1.0)\n",
      "Loss at Epoch 752 is : netwok_nn.tensor(106.32207568690414 , grad = 1.0)\n",
      "Loss at Epoch 753 is : netwok_nn.tensor(106.141788367808 , grad = 1.0)\n",
      "Loss at Epoch 754 is : netwok_nn.tensor(105.96168771777461 , grad = 1.0)\n",
      "Loss at Epoch 755 is : netwok_nn.tensor(105.78177365447286 , grad = 1.0)\n",
      "Loss at Epoch 756 is : netwok_nn.tensor(105.60204609554155 , grad = 1.0)\n",
      "Loss at Epoch 757 is : netwok_nn.tensor(105.4225049585898 , grad = 1.0)\n",
      "Loss at Epoch 758 is : netwok_nn.tensor(105.24315016119722 , grad = 1.0)\n",
      "Loss at Epoch 759 is : netwok_nn.tensor(105.06398162091426 , grad = 1.0)\n",
      "Loss at Epoch 760 is : netwok_nn.tensor(104.88499925526267 , grad = 1.0)\n",
      "Loss at Epoch 761 is : netwok_nn.tensor(104.7062029817356 , grad = 1.0)\n",
      "Loss at Epoch 762 is : netwok_nn.tensor(104.52759271779813 , grad = 1.0)\n",
      "Loss at Epoch 763 is : netwok_nn.tensor(104.34916838088746 , grad = 1.0)\n",
      "Loss at Epoch 764 is : netwok_nn.tensor(104.17092988841333 , grad = 1.0)\n",
      "Loss at Epoch 765 is : netwok_nn.tensor(103.99287715775822 , grad = 1.0)\n",
      "Loss at Epoch 766 is : netwok_nn.tensor(103.81501010627768 , grad = 1.0)\n",
      "Loss at Epoch 767 is : netwok_nn.tensor(103.63732865130079 , grad = 1.0)\n",
      "Loss at Epoch 768 is : netwok_nn.tensor(103.45983271013021 , grad = 1.0)\n",
      "Loss at Epoch 769 is : netwok_nn.tensor(103.28252220004269 , grad = 1.0)\n",
      "Loss at Epoch 770 is : netwok_nn.tensor(103.1053970382893 , grad = 1.0)\n",
      "Loss at Epoch 771 is : netwok_nn.tensor(102.92845714209572 , grad = 1.0)\n",
      "Loss at Epoch 772 is : netwok_nn.tensor(102.75170242866253 , grad = 1.0)\n",
      "Loss at Epoch 773 is : netwok_nn.tensor(102.57513281516553 , grad = 1.0)\n",
      "Loss at Epoch 774 is : netwok_nn.tensor(102.39874821875601 , grad = 1.0)\n",
      "Loss at Epoch 775 is : netwok_nn.tensor(102.22254855656107 , grad = 1.0)\n",
      "Loss at Epoch 776 is : netwok_nn.tensor(102.04653374568393 , grad = 1.0)\n",
      "Loss at Epoch 777 is : netwok_nn.tensor(101.87070370320414 , grad = 1.0)\n",
      "Loss at Epoch 778 is : netwok_nn.tensor(101.69505834617792 , grad = 1.0)\n",
      "Loss at Epoch 779 is : netwok_nn.tensor(101.51959759163836 , grad = 1.0)\n",
      "Loss at Epoch 780 is : netwok_nn.tensor(101.34432135659581 , grad = 1.0)\n",
      "Loss at Epoch 781 is : netwok_nn.tensor(101.16922955803811 , grad = 1.0)\n",
      "Loss at Epoch 782 is : netwok_nn.tensor(100.99432211293093 , grad = 1.0)\n",
      "Loss at Epoch 783 is : netwok_nn.tensor(100.81959893821787 , grad = 1.0)\n",
      "Loss at Epoch 784 is : netwok_nn.tensor(100.64505995082085 , grad = 1.0)\n",
      "Loss at Epoch 785 is : netwok_nn.tensor(100.47070506764052 , grad = 1.0)\n",
      "Loss at Epoch 786 is : netwok_nn.tensor(100.29653420555618 , grad = 1.0)\n",
      "Loss at Epoch 787 is : netwok_nn.tensor(100.12254728142642 , grad = 1.0)\n",
      "Loss at Epoch 788 is : netwok_nn.tensor(99.94874421208901 , grad = 1.0)\n",
      "Loss at Epoch 789 is : netwok_nn.tensor(99.77512491436156 , grad = 1.0)\n",
      "Loss at Epoch 790 is : netwok_nn.tensor(99.60168930504146 , grad = 1.0)\n",
      "Loss at Epoch 791 is : netwok_nn.tensor(99.42843730090627 , grad = 1.0)\n",
      "Loss at Epoch 792 is : netwok_nn.tensor(99.25536881871402 , grad = 1.0)\n",
      "Loss at Epoch 793 is : netwok_nn.tensor(99.08248377520333 , grad = 1.0)\n",
      "Loss at Epoch 794 is : netwok_nn.tensor(98.90978208709384 , grad = 1.0)\n",
      "Loss at Epoch 795 is : netwok_nn.tensor(98.73726367108628 , grad = 1.0)\n",
      "Loss at Epoch 796 is : netwok_nn.tensor(98.56492844386271 , grad = 1.0)\n",
      "Loss at Epoch 797 is : netwok_nn.tensor(98.39277632208704 , grad = 1.0)\n",
      "Loss at Epoch 798 is : netwok_nn.tensor(98.22080722240501 , grad = 1.0)\n",
      "Loss at Epoch 799 is : netwok_nn.tensor(98.0490210614445 , grad = 1.0)\n",
      "Loss at Epoch 800 is : netwok_nn.tensor(97.87741775581578 , grad = 1.0)\n",
      "Loss at Epoch 801 is : netwok_nn.tensor(97.70599722211175 , grad = 1.0)\n",
      "Loss at Epoch 802 is : netwok_nn.tensor(97.53475937690818 , grad = 1.0)\n",
      "Loss at Epoch 803 is : netwok_nn.tensor(97.36370413676397 , grad = 1.0)\n",
      "Loss at Epoch 804 is : netwok_nn.tensor(97.19283141822135 , grad = 1.0)\n",
      "Loss at Epoch 805 is : netwok_nn.tensor(97.02214113780609 , grad = 1.0)\n",
      "Loss at Epoch 806 is : netwok_nn.tensor(96.85163321202775 , grad = 1.0)\n",
      "Loss at Epoch 807 is : netwok_nn.tensor(96.68130755738004 , grad = 1.0)\n",
      "Loss at Epoch 808 is : netwok_nn.tensor(96.51116409034077 , grad = 1.0)\n",
      "Loss at Epoch 809 is : netwok_nn.tensor(96.34120272737236 , grad = 1.0)\n",
      "Loss at Epoch 810 is : netwok_nn.tensor(96.1714233849218 , grad = 1.0)\n",
      "Loss at Epoch 811 is : netwok_nn.tensor(96.00182597942114 , grad = 1.0)\n",
      "Loss at Epoch 812 is : netwok_nn.tensor(95.83241042728753 , grad = 1.0)\n",
      "Loss at Epoch 813 is : netwok_nn.tensor(95.66317664492348 , grad = 1.0)\n",
      "Loss at Epoch 814 is : netwok_nn.tensor(95.49412454871707 , grad = 1.0)\n",
      "Loss at Epoch 815 is : netwok_nn.tensor(95.32525405504221 , grad = 1.0)\n",
      "Loss at Epoch 816 is : netwok_nn.tensor(95.15656508025886 , grad = 1.0)\n",
      "Loss at Epoch 817 is : netwok_nn.tensor(94.98805754071309 , grad = 1.0)\n",
      "Loss at Epoch 818 is : netwok_nn.tensor(94.81973135273749 , grad = 1.0)\n",
      "Loss at Epoch 819 is : netwok_nn.tensor(94.65158643265133 , grad = 1.0)\n",
      "Loss at Epoch 820 is : netwok_nn.tensor(94.48362269676065 , grad = 1.0)\n",
      "Loss at Epoch 821 is : netwok_nn.tensor(94.31584006135867 , grad = 1.0)\n",
      "Loss at Epoch 822 is : netwok_nn.tensor(94.14823844272573 , grad = 1.0)\n",
      "Loss at Epoch 823 is : netwok_nn.tensor(93.98081775712973 , grad = 1.0)\n",
      "Loss at Epoch 824 is : netwok_nn.tensor(93.81357792082625 , grad = 1.0)\n",
      "Loss at Epoch 825 is : netwok_nn.tensor(93.64651885005864 , grad = 1.0)\n",
      "Loss at Epoch 826 is : netwok_nn.tensor(93.47964046105844 , grad = 1.0)\n",
      "Loss at Epoch 827 is : netwok_nn.tensor(93.31294267004537 , grad = 1.0)\n",
      "Loss at Epoch 828 is : netwok_nn.tensor(93.14642539322772 , grad = 1.0)\n",
      "Loss at Epoch 829 is : netwok_nn.tensor(92.98008854680229 , grad = 1.0)\n",
      "Loss at Epoch 830 is : netwok_nn.tensor(92.81393204695483 , grad = 1.0)\n",
      "Loss at Epoch 831 is : netwok_nn.tensor(92.64795580986012 , grad = 1.0)\n",
      "Loss at Epoch 832 is : netwok_nn.tensor(92.48215975168218 , grad = 1.0)\n",
      "Loss at Epoch 833 is : netwok_nn.tensor(92.31654378857436 , grad = 1.0)\n",
      "Loss at Epoch 834 is : netwok_nn.tensor(92.15110783667973 , grad = 1.0)\n",
      "Loss at Epoch 835 is : netwok_nn.tensor(91.9858518121311 , grad = 1.0)\n",
      "Loss at Epoch 836 is : netwok_nn.tensor(91.82077563105122 , grad = 1.0)\n",
      "Loss at Epoch 837 is : netwok_nn.tensor(91.65587920955309 , grad = 1.0)\n",
      "Loss at Epoch 838 is : netwok_nn.tensor(91.49116246373998 , grad = 1.0)\n",
      "Loss at Epoch 839 is : netwok_nn.tensor(91.32662530970569 , grad = 1.0)\n",
      "Loss at Epoch 840 is : netwok_nn.tensor(91.16226766353473 , grad = 1.0)\n",
      "Loss at Epoch 841 is : netwok_nn.tensor(90.99808944130254 , grad = 1.0)\n",
      "Loss at Epoch 842 is : netwok_nn.tensor(90.83409055907552 , grad = 1.0)\n",
      "Loss at Epoch 843 is : netwok_nn.tensor(90.67027093291135 , grad = 1.0)\n",
      "Loss at Epoch 844 is : netwok_nn.tensor(90.50663047885914 , grad = 1.0)\n",
      "Loss at Epoch 845 is : netwok_nn.tensor(90.34316911295944 , grad = 1.0)\n",
      "Loss at Epoch 846 is : netwok_nn.tensor(90.1798867512448 , grad = 1.0)\n",
      "Loss at Epoch 847 is : netwok_nn.tensor(90.01678330973941 , grad = 1.0)\n",
      "Loss at Epoch 848 is : netwok_nn.tensor(89.85385870445971 , grad = 1.0)\n",
      "Loss at Epoch 849 is : netwok_nn.tensor(89.69111285141439 , grad = 1.0)\n",
      "Loss at Epoch 850 is : netwok_nn.tensor(89.52854566660444 , grad = 1.0)\n",
      "Loss at Epoch 851 is : netwok_nn.tensor(89.36615706602358 , grad = 1.0)\n",
      "Loss at Epoch 852 is : netwok_nn.tensor(89.20394696565818 , grad = 1.0)\n",
      "Loss at Epoch 853 is : netwok_nn.tensor(89.04191528148755 , grad = 1.0)\n",
      "Loss at Epoch 854 is : netwok_nn.tensor(88.88006192948407 , grad = 1.0)\n",
      "Loss at Epoch 855 is : netwok_nn.tensor(88.71838682561336 , grad = 1.0)\n",
      "Loss at Epoch 856 is : netwok_nn.tensor(88.5568898858344 , grad = 1.0)\n",
      "Loss at Epoch 857 is : netwok_nn.tensor(88.3955710260997 , grad = 1.0)\n",
      "Loss at Epoch 858 is : netwok_nn.tensor(88.2344301623555 , grad = 1.0)\n",
      "Loss at Epoch 859 is : netwok_nn.tensor(88.07346721054193 , grad = 1.0)\n",
      "Loss at Epoch 860 is : netwok_nn.tensor(87.91268208659311 , grad = 1.0)\n",
      "Loss at Epoch 861 is : netwok_nn.tensor(87.75207470643733 , grad = 1.0)\n",
      "Loss at Epoch 862 is : netwok_nn.tensor(87.59164498599714 , grad = 1.0)\n",
      "Loss at Epoch 863 is : netwok_nn.tensor(87.43139284118959 , grad = 1.0)\n",
      "Loss at Epoch 864 is : netwok_nn.tensor(87.27131818792637 , grad = 1.0)\n",
      "Loss at Epoch 865 is : netwok_nn.tensor(87.11142094211392 , grad = 1.0)\n",
      "Loss at Epoch 866 is : netwok_nn.tensor(86.9517010196536 , grad = 1.0)\n",
      "Loss at Epoch 867 is : netwok_nn.tensor(86.79215833644177 , grad = 1.0)\n",
      "Loss at Epoch 868 is : netwok_nn.tensor(86.63279280837007 , grad = 1.0)\n",
      "Loss at Epoch 869 is : netwok_nn.tensor(86.47360435132549 , grad = 1.0)\n",
      "Loss at Epoch 870 is : netwok_nn.tensor(86.31459288119038 , grad = 1.0)\n",
      "Loss at Epoch 871 is : netwok_nn.tensor(86.1557583138429 , grad = 1.0)\n",
      "Loss at Epoch 872 is : netwok_nn.tensor(85.99710056515683 , grad = 1.0)\n",
      "Loss at Epoch 873 is : netwok_nn.tensor(85.83861955100201 , grad = 1.0)\n",
      "Loss at Epoch 874 is : netwok_nn.tensor(85.68031518724415 , grad = 1.0)\n",
      "Loss at Epoch 875 is : netwok_nn.tensor(85.5221873897453 , grad = 1.0)\n",
      "Loss at Epoch 876 is : netwok_nn.tensor(85.36423607436377 , grad = 1.0)\n",
      "Loss at Epoch 877 is : netwok_nn.tensor(85.20646115695432 , grad = 1.0)\n",
      "Loss at Epoch 878 is : netwok_nn.tensor(85.04886255336831 , grad = 1.0)\n",
      "Loss at Epoch 879 is : netwok_nn.tensor(84.89144017945385 , grad = 1.0)\n",
      "Loss at Epoch 880 is : netwok_nn.tensor(84.73419395105591 , grad = 1.0)\n",
      "Loss at Epoch 881 is : netwok_nn.tensor(84.57712378401641 , grad = 1.0)\n",
      "Loss at Epoch 882 is : netwok_nn.tensor(84.42022959417442 , grad = 1.0)\n",
      "Loss at Epoch 883 is : netwok_nn.tensor(84.26351129736628 , grad = 1.0)\n",
      "Loss at Epoch 884 is : netwok_nn.tensor(84.10696880942565 , grad = 1.0)\n",
      "Loss at Epoch 885 is : netwok_nn.tensor(83.95060204618376 , grad = 1.0)\n",
      "Loss at Epoch 886 is : netwok_nn.tensor(83.79441092346939 , grad = 1.0)\n",
      "Loss at Epoch 887 is : netwok_nn.tensor(83.63839535710916 , grad = 1.0)\n",
      "Loss at Epoch 888 is : netwok_nn.tensor(83.48255526292755 , grad = 1.0)\n",
      "Loss at Epoch 889 is : netwok_nn.tensor(83.32689055674707 , grad = 1.0)\n",
      "Loss at Epoch 890 is : netwok_nn.tensor(83.17140115438826 , grad = 1.0)\n",
      "Loss at Epoch 891 is : netwok_nn.tensor(83.01608697167 , grad = 1.0)\n",
      "Loss at Epoch 892 is : netwok_nn.tensor(82.86094792440954 , grad = 1.0)\n",
      "Loss at Epoch 893 is : netwok_nn.tensor(82.70598392842255 , grad = 1.0)\n",
      "Loss at Epoch 894 is : netwok_nn.tensor(82.55119489952345 , grad = 1.0)\n",
      "Loss at Epoch 895 is : netwok_nn.tensor(82.39658075352521 , grad = 1.0)\n",
      "Loss at Epoch 896 is : netwok_nn.tensor(82.24214140623977 , grad = 1.0)\n",
      "Loss at Epoch 897 is : netwok_nn.tensor(82.08787677347799 , grad = 1.0)\n",
      "Loss at Epoch 898 is : netwok_nn.tensor(81.93378677104977 , grad = 1.0)\n",
      "Loss at Epoch 899 is : netwok_nn.tensor(81.77987131476429 , grad = 1.0)\n",
      "Loss at Epoch 900 is : netwok_nn.tensor(81.62613032042998 , grad = 1.0)\n",
      "Loss at Epoch 901 is : netwok_nn.tensor(81.4725637038547 , grad = 1.0)\n",
      "Loss at Epoch 902 is : netwok_nn.tensor(81.31917138084582 , grad = 1.0)\n",
      "Loss at Epoch 903 is : netwok_nn.tensor(81.16595326721031 , grad = 1.0)\n",
      "Loss at Epoch 904 is : netwok_nn.tensor(81.01290927875502 , grad = 1.0)\n",
      "Loss at Epoch 905 is : netwok_nn.tensor(80.86003933128656 , grad = 1.0)\n",
      "Loss at Epoch 906 is : netwok_nn.tensor(80.70734334061147 , grad = 1.0)\n",
      "Loss at Epoch 907 is : netwok_nn.tensor(80.55482122253655 , grad = 1.0)\n",
      "Loss at Epoch 908 is : netwok_nn.tensor(80.40247289286856 , grad = 1.0)\n",
      "Loss at Epoch 909 is : netwok_nn.tensor(80.25029826741465 , grad = 1.0)\n",
      "Loss at Epoch 910 is : netwok_nn.tensor(80.09829726198238 , grad = 1.0)\n",
      "Loss at Epoch 911 is : netwok_nn.tensor(79.94646979237979 , grad = 1.0)\n",
      "Loss at Epoch 912 is : netwok_nn.tensor(79.79481577441555 , grad = 1.0)\n",
      "Loss at Epoch 913 is : netwok_nn.tensor(79.64333512389894 , grad = 1.0)\n",
      "Loss at Epoch 914 is : netwok_nn.tensor(79.49202775664014 , grad = 1.0)\n",
      "Loss at Epoch 915 is : netwok_nn.tensor(79.34089358845021 , grad = 1.0)\n",
      "Loss at Epoch 916 is : netwok_nn.tensor(79.18993253514121 , grad = 1.0)\n",
      "Loss at Epoch 917 is : netwok_nn.tensor(79.0391445125263 , grad = 1.0)\n",
      "Loss at Epoch 918 is : netwok_nn.tensor(78.88852943641987 , grad = 1.0)\n",
      "Loss at Epoch 919 is : netwok_nn.tensor(78.7380872226376 , grad = 1.0)\n",
      "Loss at Epoch 920 is : netwok_nn.tensor(78.58781778699655 , grad = 1.0)\n",
      "Loss at Epoch 921 is : netwok_nn.tensor(78.43772104531531 , grad = 1.0)\n",
      "Loss at Epoch 922 is : netwok_nn.tensor(78.28779691341407 , grad = 1.0)\n",
      "Loss at Epoch 923 is : netwok_nn.tensor(78.13804530711468 , grad = 1.0)\n",
      "Loss at Epoch 924 is : netwok_nn.tensor(77.98846614224077 , grad = 1.0)\n",
      "Loss at Epoch 925 is : netwok_nn.tensor(77.83905933461784 , grad = 1.0)\n",
      "Loss at Epoch 926 is : netwok_nn.tensor(77.68982480007345 , grad = 1.0)\n",
      "Loss at Epoch 927 is : netwok_nn.tensor(77.54076245443706 , grad = 1.0)\n",
      "Loss at Epoch 928 is : netwok_nn.tensor(77.39187221354045 , grad = 1.0)\n",
      "Loss at Epoch 929 is : netwok_nn.tensor(77.2431539932175 , grad = 1.0)\n",
      "Loss at Epoch 930 is : netwok_nn.tensor(77.09460770930454 , grad = 1.0)\n",
      "Loss at Epoch 931 is : netwok_nn.tensor(76.94623327764025 , grad = 1.0)\n",
      "Loss at Epoch 932 is : netwok_nn.tensor(76.79803061406581 , grad = 1.0)\n",
      "Loss at Epoch 933 is : netwok_nn.tensor(76.6499996344251 , grad = 1.0)\n",
      "Loss at Epoch 934 is : netwok_nn.tensor(76.50214025456455 , grad = 1.0)\n",
      "Loss at Epoch 935 is : netwok_nn.tensor(76.35445239033345 , grad = 1.0)\n",
      "Loss at Epoch 936 is : netwok_nn.tensor(76.20693595758392 , grad = 1.0)\n",
      "Loss at Epoch 937 is : netwok_nn.tensor(76.05959087217107 , grad = 1.0)\n",
      "Loss at Epoch 938 is : netwok_nn.tensor(75.91241704995296 , grad = 1.0)\n",
      "Loss at Epoch 939 is : netwok_nn.tensor(75.76541440679078 , grad = 1.0)\n",
      "Loss at Epoch 940 is : netwok_nn.tensor(75.61858285854898 , grad = 1.0)\n",
      "Loss at Epoch 941 is : netwok_nn.tensor(75.47192232109522 , grad = 1.0)\n",
      "Loss at Epoch 942 is : netwok_nn.tensor(75.3254327103005 , grad = 1.0)\n",
      "Loss at Epoch 943 is : netwok_nn.tensor(75.17911394203938 , grad = 1.0)\n",
      "Loss at Epoch 944 is : netwok_nn.tensor(75.0329659321898 , grad = 1.0)\n",
      "Loss at Epoch 945 is : netwok_nn.tensor(74.88698859663339 , grad = 1.0)\n",
      "Loss at Epoch 946 is : netwok_nn.tensor(74.74118185125542 , grad = 1.0)\n",
      "Loss at Epoch 947 is : netwok_nn.tensor(74.59554561194493 , grad = 1.0)\n",
      "Loss at Epoch 948 is : netwok_nn.tensor(74.4500797945948 , grad = 1.0)\n",
      "Loss at Epoch 949 is : netwok_nn.tensor(74.30478431510183 , grad = 1.0)\n",
      "Loss at Epoch 950 is : netwok_nn.tensor(74.15965908936677 , grad = 1.0)\n",
      "Loss at Epoch 951 is : netwok_nn.tensor(74.01470403329449 , grad = 1.0)\n",
      "Loss at Epoch 952 is : netwok_nn.tensor(73.86991906279398 , grad = 1.0)\n",
      "Loss at Epoch 953 is : netwok_nn.tensor(73.72530409377845 , grad = 1.0)\n",
      "Loss at Epoch 954 is : netwok_nn.tensor(73.5808590421654 , grad = 1.0)\n",
      "Loss at Epoch 955 is : netwok_nn.tensor(73.43658382387673 , grad = 1.0)\n",
      "Loss at Epoch 956 is : netwok_nn.tensor(73.29247835483868 , grad = 1.0)\n",
      "Loss at Epoch 957 is : netwok_nn.tensor(73.14854255098211 , grad = 1.0)\n",
      "Loss at Epoch 958 is : netwok_nn.tensor(73.00477632824243 , grad = 1.0)\n",
      "Loss at Epoch 959 is : netwok_nn.tensor(72.86117960255964 , grad = 1.0)\n",
      "Loss at Epoch 960 is : netwok_nn.tensor(72.71775228987859 , grad = 1.0)\n",
      "Loss at Epoch 961 is : netwok_nn.tensor(72.57449430614884 , grad = 1.0)\n",
      "Loss at Epoch 962 is : netwok_nn.tensor(72.43140556732483 , grad = 1.0)\n",
      "Loss at Epoch 963 is : netwok_nn.tensor(72.28848598936594 , grad = 1.0)\n",
      "Loss at Epoch 964 is : netwok_nn.tensor(72.14573548823655 , grad = 1.0)\n",
      "Loss at Epoch 965 is : netwok_nn.tensor(72.00315397990616 , grad = 1.0)\n",
      "Loss at Epoch 966 is : netwok_nn.tensor(71.8607413803493 , grad = 1.0)\n",
      "Loss at Epoch 967 is : netwok_nn.tensor(71.71849760554585 , grad = 1.0)\n",
      "Loss at Epoch 968 is : netwok_nn.tensor(71.57642257148082 , grad = 1.0)\n",
      "Loss at Epoch 969 is : netwok_nn.tensor(71.43451619414472 , grad = 1.0)\n",
      "Loss at Epoch 970 is : netwok_nn.tensor(71.29277838953331 , grad = 1.0)\n",
      "Loss at Epoch 971 is : netwok_nn.tensor(71.15120907364792 , grad = 1.0)\n",
      "Loss at Epoch 972 is : netwok_nn.tensor(71.00980816249536 , grad = 1.0)\n",
      "Loss at Epoch 973 is : netwok_nn.tensor(70.86857557208805 , grad = 1.0)\n",
      "Loss at Epoch 974 is : netwok_nn.tensor(70.72751121844412 , grad = 1.0)\n",
      "Loss at Epoch 975 is : netwok_nn.tensor(70.58661501758738 , grad = 1.0)\n",
      "Loss at Epoch 976 is : netwok_nn.tensor(70.44588688554741 , grad = 1.0)\n",
      "Loss at Epoch 977 is : netwok_nn.tensor(70.30532673835968 , grad = 1.0)\n",
      "Loss at Epoch 978 is : netwok_nn.tensor(70.16493449206558 , grad = 1.0)\n",
      "Loss at Epoch 979 is : netwok_nn.tensor(70.02471006271244 , grad = 1.0)\n",
      "Loss at Epoch 980 is : netwok_nn.tensor(69.8846533663536 , grad = 1.0)\n",
      "Loss at Epoch 981 is : netwok_nn.tensor(69.74476431904856 , grad = 1.0)\n",
      "Loss at Epoch 982 is : netwok_nn.tensor(69.6050428368629 , grad = 1.0)\n",
      "Loss at Epoch 983 is : netwok_nn.tensor(69.46548883586853 , grad = 1.0)\n",
      "Loss at Epoch 984 is : netwok_nn.tensor(69.32610223214346 , grad = 1.0)\n",
      "Loss at Epoch 985 is : netwok_nn.tensor(69.18688294177214 , grad = 1.0)\n",
      "Loss at Epoch 986 is : netwok_nn.tensor(69.04783088084538 , grad = 1.0)\n",
      "Loss at Epoch 987 is : netwok_nn.tensor(68.90894596546045 , grad = 1.0)\n",
      "Loss at Epoch 988 is : netwok_nn.tensor(68.7702281117211 , grad = 1.0)\n",
      "Loss at Epoch 989 is : netwok_nn.tensor(68.63167723573761 , grad = 1.0)\n",
      "Loss at Epoch 990 is : netwok_nn.tensor(68.49329325362693 , grad = 1.0)\n",
      "Loss at Epoch 991 is : netwok_nn.tensor(68.35507608151264 , grad = 1.0)\n",
      "Loss at Epoch 992 is : netwok_nn.tensor(68.21702563552505 , grad = 1.0)\n",
      "Loss at Epoch 993 is : netwok_nn.tensor(68.07914183180124 , grad = 1.0)\n",
      "Loss at Epoch 994 is : netwok_nn.tensor(67.94142458648511 , grad = 1.0)\n",
      "Loss at Epoch 995 is : netwok_nn.tensor(67.80387381572747 , grad = 1.0)\n",
      "Loss at Epoch 996 is : netwok_nn.tensor(67.66648943568609 , grad = 1.0)\n",
      "Loss at Epoch 997 is : netwok_nn.tensor(67.52927136252566 , grad = 1.0)\n",
      "Loss at Epoch 998 is : netwok_nn.tensor(67.39221951241798 , grad = 1.0)\n",
      "Loss at Epoch 999 is : netwok_nn.tensor(67.2553338015419 , grad = 1.0)\n",
      "Loss at Epoch 1000 is : netwok_nn.tensor(67.1186141460834 , grad = 1.0)\n",
      "Loss at Epoch 1001 is : netwok_nn.tensor(66.98206046223576 , grad = 1.0)\n",
      "Loss at Epoch 1002 is : netwok_nn.tensor(66.84567266619938 , grad = 1.0)\n",
      "Loss at Epoch 1003 is : netwok_nn.tensor(66.70945067418202 , grad = 1.0)\n",
      "Loss at Epoch 1004 is : netwok_nn.tensor(66.57339440239882 , grad = 1.0)\n",
      "Loss at Epoch 1005 is : netwok_nn.tensor(66.43750376707227 , grad = 1.0)\n",
      "Loss at Epoch 1006 is : netwok_nn.tensor(66.3017786844323 , grad = 1.0)\n",
      "Loss at Epoch 1007 is : netwok_nn.tensor(66.16621907071641 , grad = 1.0)\n",
      "Loss at Epoch 1008 is : netwok_nn.tensor(66.03082484216952 , grad = 1.0)\n",
      "Loss at Epoch 1009 is : netwok_nn.tensor(65.89559591504428 , grad = 1.0)\n",
      "Loss at Epoch 1010 is : netwok_nn.tensor(65.7605322056009 , grad = 1.0)\n",
      "Loss at Epoch 1011 is : netwok_nn.tensor(65.62563363010732 , grad = 1.0)\n",
      "Loss at Epoch 1012 is : netwok_nn.tensor(65.49090010483913 , grad = 1.0)\n",
      "Loss at Epoch 1013 is : netwok_nn.tensor(65.35633154607977 , grad = 1.0)\n",
      "Loss at Epoch 1014 is : netwok_nn.tensor(65.22192787012057 , grad = 1.0)\n",
      "Loss at Epoch 1015 is : netwok_nn.tensor(65.0876889932606 , grad = 1.0)\n",
      "Loss at Epoch 1016 is : netwok_nn.tensor(64.95361483180692 , grad = 1.0)\n",
      "Loss at Epoch 1017 is : netwok_nn.tensor(64.81970530207457 , grad = 1.0)\n",
      "Loss at Epoch 1018 is : netwok_nn.tensor(64.68596032038657 , grad = 1.0)\n",
      "Loss at Epoch 1019 is : netwok_nn.tensor(64.552379803074 , grad = 1.0)\n",
      "Loss at Epoch 1020 is : netwok_nn.tensor(64.41896366647606 , grad = 1.0)\n",
      "Loss at Epoch 1021 is : netwok_nn.tensor(64.28571182694004 , grad = 1.0)\n",
      "Loss at Epoch 1022 is : netwok_nn.tensor(64.15262420082146 , grad = 1.0)\n",
      "Loss at Epoch 1023 is : netwok_nn.tensor(64.01970070448408 , grad = 1.0)\n",
      "Loss at Epoch 1024 is : netwok_nn.tensor(63.8869412542999 , grad = 1.0)\n",
      "Loss at Epoch 1025 is : netwok_nn.tensor(63.75434576664924 , grad = 1.0)\n",
      "Loss at Epoch 1026 is : netwok_nn.tensor(63.62191415792077 , grad = 1.0)\n",
      "Loss at Epoch 1027 is : netwok_nn.tensor(63.48964634451158 , grad = 1.0)\n",
      "Loss at Epoch 1028 is : netwok_nn.tensor(63.357542242827215 , grad = 1.0)\n",
      "Loss at Epoch 1029 is : netwok_nn.tensor(63.225601769281646 , grad = 1.0)\n",
      "Loss at Epoch 1030 is : netwok_nn.tensor(63.09382484029737 , grad = 1.0)\n",
      "Loss at Epoch 1031 is : netwok_nn.tensor(62.96221137230555 , grad = 1.0)\n",
      "Loss at Epoch 1032 is : netwok_nn.tensor(62.830761281745815 , grad = 1.0)\n",
      "Loss at Epoch 1033 is : netwok_nn.tensor(62.69947448506654 , grad = 1.0)\n",
      "Loss at Epoch 1034 is : netwok_nn.tensor(62.5683508987247 , grad = 1.0)\n",
      "Loss at Epoch 1035 is : netwok_nn.tensor(62.43739043918609 , grad = 1.0)\n",
      "Loss at Epoch 1036 is : netwok_nn.tensor(62.3065930229252 , grad = 1.0)\n",
      "Loss at Epoch 1037 is : netwok_nn.tensor(62.17595856642532 , grad = 1.0)\n",
      "Loss at Epoch 1038 is : netwok_nn.tensor(62.0454869861786 , grad = 1.0)\n",
      "Loss at Epoch 1039 is : netwok_nn.tensor(61.91517819868607 , grad = 1.0)\n",
      "Loss at Epoch 1040 is : netwok_nn.tensor(61.78503212045769 , grad = 1.0)\n",
      "Loss at Epoch 1041 is : netwok_nn.tensor(61.655048668012334 , grad = 1.0)\n",
      "Loss at Epoch 1042 is : netwok_nn.tensor(61.52522775787791 , grad = 1.0)\n",
      "Loss at Epoch 1043 is : netwok_nn.tensor(61.39556930659133 , grad = 1.0)\n",
      "Loss at Epoch 1044 is : netwok_nn.tensor(61.26607323069857 , grad = 1.0)\n",
      "Loss at Epoch 1045 is : netwok_nn.tensor(61.136739446754746 , grad = 1.0)\n",
      "Loss at Epoch 1046 is : netwok_nn.tensor(61.00756787132406 , grad = 1.0)\n",
      "Loss at Epoch 1047 is : netwok_nn.tensor(60.87855842097997 , grad = 1.0)\n",
      "Loss at Epoch 1048 is : netwok_nn.tensor(60.74971101230506 , grad = 1.0)\n",
      "Loss at Epoch 1049 is : netwok_nn.tensor(60.62102556189121 , grad = 1.0)\n",
      "Loss at Epoch 1050 is : netwok_nn.tensor(60.49250198633959 , grad = 1.0)\n",
      "Loss at Epoch 1051 is : netwok_nn.tensor(60.36414020226067 , grad = 1.0)\n",
      "Loss at Epoch 1052 is : netwok_nn.tensor(60.23594012627428 , grad = 1.0)\n",
      "Loss at Epoch 1053 is : netwok_nn.tensor(60.10790167500965 , grad = 1.0)\n",
      "Loss at Epoch 1054 is : netwok_nn.tensor(59.980024765105426 , grad = 1.0)\n",
      "Loss at Epoch 1055 is : netwok_nn.tensor(59.85230931320971 , grad = 1.0)\n",
      "Loss at Epoch 1056 is : netwok_nn.tensor(59.72475523598009 , grad = 1.0)\n",
      "Loss at Epoch 1057 is : netwok_nn.tensor(59.59736245008376 , grad = 1.0)\n",
      "Loss at Epoch 1058 is : netwok_nn.tensor(59.470130872197345 , grad = 1.0)\n",
      "Loss at Epoch 1059 is : netwok_nn.tensor(59.34306041900716 , grad = 1.0)\n",
      "Loss at Epoch 1060 is : netwok_nn.tensor(59.216151007209156 , grad = 1.0)\n",
      "Loss at Epoch 1061 is : netwok_nn.tensor(59.089402553508855 , grad = 1.0)\n",
      "Loss at Epoch 1062 is : netwok_nn.tensor(58.96281497462157 , grad = 1.0)\n",
      "Loss at Epoch 1063 is : netwok_nn.tensor(58.83638818727231 , grad = 1.0)\n",
      "Loss at Epoch 1064 is : netwok_nn.tensor(58.71012210819585 , grad = 1.0)\n",
      "Loss at Epoch 1065 is : netwok_nn.tensor(58.58401665413673 , grad = 1.0)\n",
      "Loss at Epoch 1066 is : netwok_nn.tensor(58.45807174184934 , grad = 1.0)\n",
      "Loss at Epoch 1067 is : netwok_nn.tensor(58.332287288097945 , grad = 1.0)\n",
      "Loss at Epoch 1068 is : netwok_nn.tensor(58.20666320965668 , grad = 1.0)\n",
      "Loss at Epoch 1069 is : netwok_nn.tensor(58.0811994233096 , grad = 1.0)\n",
      "Loss at Epoch 1070 is : netwok_nn.tensor(57.95589584585073 , grad = 1.0)\n",
      "Loss at Epoch 1071 is : netwok_nn.tensor(57.830752394084065 , grad = 1.0)\n",
      "Loss at Epoch 1072 is : netwok_nn.tensor(57.705768984823614 , grad = 1.0)\n",
      "Loss at Epoch 1073 is : netwok_nn.tensor(57.58094553489349 , grad = 1.0)\n",
      "Loss at Epoch 1074 is : netwok_nn.tensor(57.45628196112777 , grad = 1.0)\n",
      "Loss at Epoch 1075 is : netwok_nn.tensor(57.33177818037077 , grad = 1.0)\n",
      "Loss at Epoch 1076 is : netwok_nn.tensor(57.20743410947685 , grad = 1.0)\n",
      "Loss at Epoch 1077 is : netwok_nn.tensor(57.0832496653106 , grad = 1.0)\n",
      "Loss at Epoch 1078 is : netwok_nn.tensor(56.95922476474681 , grad = 1.0)\n",
      "Loss at Epoch 1079 is : netwok_nn.tensor(56.83535932467044 , grad = 1.0)\n",
      "Loss at Epoch 1080 is : netwok_nn.tensor(56.71165326197679 , grad = 1.0)\n",
      "Loss at Epoch 1081 is : netwok_nn.tensor(56.588106493571416 , grad = 1.0)\n",
      "Loss at Epoch 1082 is : netwok_nn.tensor(56.464718936370154 , grad = 1.0)\n",
      "Loss at Epoch 1083 is : netwok_nn.tensor(56.341490507299305 , grad = 1.0)\n",
      "Loss at Epoch 1084 is : netwok_nn.tensor(56.218421123295414 , grad = 1.0)\n",
      "Loss at Epoch 1085 is : netwok_nn.tensor(56.09551070130558 , grad = 1.0)\n",
      "Loss at Epoch 1086 is : netwok_nn.tensor(55.97275915828722 , grad = 1.0)\n",
      "Loss at Epoch 1087 is : netwok_nn.tensor(55.85016641120829 , grad = 1.0)\n",
      "Loss at Epoch 1088 is : netwok_nn.tensor(55.72773237704723 , grad = 1.0)\n",
      "Loss at Epoch 1089 is : netwok_nn.tensor(55.605456972793 , grad = 1.0)\n",
      "Loss at Epoch 1090 is : netwok_nn.tensor(55.48334011544514 , grad = 1.0)\n",
      "Loss at Epoch 1091 is : netwok_nn.tensor(55.36138172201372 , grad = 1.0)\n",
      "Loss at Epoch 1092 is : netwok_nn.tensor(55.2395817095195 , grad = 1.0)\n",
      "Loss at Epoch 1093 is : netwok_nn.tensor(55.11793999499382 , grad = 1.0)\n",
      "Loss at Epoch 1094 is : netwok_nn.tensor(54.99645649547876 , grad = 1.0)\n",
      "Loss at Epoch 1095 is : netwok_nn.tensor(54.875131128027036 , grad = 1.0)\n",
      "Loss at Epoch 1096 is : netwok_nn.tensor(54.75396380970208 , grad = 1.0)\n",
      "Loss at Epoch 1097 is : netwok_nn.tensor(54.632954457578165 , grad = 1.0)\n",
      "Loss at Epoch 1098 is : netwok_nn.tensor(54.51210298874032 , grad = 1.0)\n",
      "Loss at Epoch 1099 is : netwok_nn.tensor(54.39140932028434 , grad = 1.0)\n",
      "Loss at Epoch 1100 is : netwok_nn.tensor(54.27087336931692 , grad = 1.0)\n",
      "Loss at Epoch 1101 is : netwok_nn.tensor(54.15049505295556 , grad = 1.0)\n",
      "Loss at Epoch 1102 is : netwok_nn.tensor(54.030274288328755 , grad = 1.0)\n",
      "Loss at Epoch 1103 is : netwok_nn.tensor(53.91021099257583 , grad = 1.0)\n",
      "Loss at Epoch 1104 is : netwok_nn.tensor(53.79030508284712 , grad = 1.0)\n",
      "Loss at Epoch 1105 is : netwok_nn.tensor(53.67055647630391 , grad = 1.0)\n",
      "Loss at Epoch 1106 is : netwok_nn.tensor(53.55096509011853 , grad = 1.0)\n",
      "Loss at Epoch 1107 is : netwok_nn.tensor(53.43153084147431 , grad = 1.0)\n",
      "Loss at Epoch 1108 is : netwok_nn.tensor(53.312253647565676 , grad = 1.0)\n",
      "Loss at Epoch 1109 is : netwok_nn.tensor(53.193133425598134 , grad = 1.0)\n",
      "Loss at Epoch 1110 is : netwok_nn.tensor(53.074170092788336 , grad = 1.0)\n",
      "Loss at Epoch 1111 is : netwok_nn.tensor(52.955363566364014 , grad = 1.0)\n",
      "Loss at Epoch 1112 is : netwok_nn.tensor(52.83671376356415 , grad = 1.0)\n",
      "Loss at Epoch 1113 is : netwok_nn.tensor(52.718220601638876 , grad = 1.0)\n",
      "Loss at Epoch 1114 is : netwok_nn.tensor(52.5998839978496 , grad = 1.0)\n",
      "Loss at Epoch 1115 is : netwok_nn.tensor(52.48170386946896 , grad = 1.0)\n",
      "Loss at Epoch 1116 is : netwok_nn.tensor(52.36368013378089 , grad = 1.0)\n",
      "Loss at Epoch 1117 is : netwok_nn.tensor(52.24581270808062 , grad = 1.0)\n",
      "Loss at Epoch 1118 is : netwok_nn.tensor(52.12810150967475 , grad = 1.0)\n",
      "Loss at Epoch 1119 is : netwok_nn.tensor(52.01054645588121 , grad = 1.0)\n",
      "Loss at Epoch 1120 is : netwok_nn.tensor(51.893147464029354 , grad = 1.0)\n",
      "Loss at Epoch 1121 is : netwok_nn.tensor(51.775904451459965 , grad = 1.0)\n",
      "Loss at Epoch 1122 is : netwok_nn.tensor(51.658817335525264 , grad = 1.0)\n",
      "Loss at Epoch 1123 is : netwok_nn.tensor(51.54188603358896 , grad = 1.0)\n",
      "Loss at Epoch 1124 is : netwok_nn.tensor(51.425110463026215 , grad = 1.0)\n",
      "Loss at Epoch 1125 is : netwok_nn.tensor(51.30849054122382 , grad = 1.0)\n",
      "Loss at Epoch 1126 is : netwok_nn.tensor(51.19202618558003 , grad = 1.0)\n",
      "Loss at Epoch 1127 is : netwok_nn.tensor(51.075717313504754 , grad = 1.0)\n",
      "Loss at Epoch 1128 is : netwok_nn.tensor(50.9595638424195 , grad = 1.0)\n",
      "Loss at Epoch 1129 is : netwok_nn.tensor(50.843565689757426 , grad = 1.0)\n",
      "Loss at Epoch 1130 is : netwok_nn.tensor(50.727722772963325 , grad = 1.0)\n",
      "Loss at Epoch 1131 is : netwok_nn.tensor(50.61203500949371 , grad = 1.0)\n",
      "Loss at Epoch 1132 is : netwok_nn.tensor(50.49650231681683 , grad = 1.0)\n",
      "Loss at Epoch 1133 is : netwok_nn.tensor(50.381124612412705 , grad = 1.0)\n",
      "Loss at Epoch 1134 is : netwok_nn.tensor(50.26590181377309 , grad = 1.0)\n",
      "Loss at Epoch 1135 is : netwok_nn.tensor(50.15083383840157 , grad = 1.0)\n",
      "Loss at Epoch 1136 is : netwok_nn.tensor(50.03592060381359 , grad = 1.0)\n",
      "Loss at Epoch 1137 is : netwok_nn.tensor(49.92116202753645 , grad = 1.0)\n",
      "Loss at Epoch 1138 is : netwok_nn.tensor(49.806558027109304 , grad = 1.0)\n",
      "Loss at Epoch 1139 is : netwok_nn.tensor(49.69210852008331 , grad = 1.0)\n",
      "Loss at Epoch 1140 is : netwok_nn.tensor(49.5778134240215 , grad = 1.0)\n",
      "Loss at Epoch 1141 is : netwok_nn.tensor(49.463672656498886 , grad = 1.0)\n",
      "Loss at Epoch 1142 is : netwok_nn.tensor(49.349686135102566 , grad = 1.0)\n",
      "Loss at Epoch 1143 is : netwok_nn.tensor(49.23585377743159 , grad = 1.0)\n",
      "Loss at Epoch 1144 is : netwok_nn.tensor(49.12217550109711 , grad = 1.0)\n",
      "Loss at Epoch 1145 is : netwok_nn.tensor(49.008651223722374 , grad = 1.0)\n",
      "Loss at Epoch 1146 is : netwok_nn.tensor(48.89528086294271 , grad = 1.0)\n",
      "Loss at Epoch 1147 is : netwok_nn.tensor(48.78206433640567 , grad = 1.0)\n",
      "Loss at Epoch 1148 is : netwok_nn.tensor(48.66900156177089 , grad = 1.0)\n",
      "Loss at Epoch 1149 is : netwok_nn.tensor(48.55609245671034 , grad = 1.0)\n",
      "Loss at Epoch 1150 is : netwok_nn.tensor(48.4433369389081 , grad = 1.0)\n",
      "Loss at Epoch 1151 is : netwok_nn.tensor(48.33073492606055 , grad = 1.0)\n",
      "Loss at Epoch 1152 is : netwok_nn.tensor(48.21828633587645 , grad = 1.0)\n",
      "Loss at Epoch 1153 is : netwok_nn.tensor(48.10599108607678 , grad = 1.0)\n",
      "Loss at Epoch 1154 is : netwok_nn.tensor(47.99384909439492 , grad = 1.0)\n",
      "Loss at Epoch 1155 is : netwok_nn.tensor(47.88186027857663 , grad = 1.0)\n",
      "Loss at Epoch 1156 is : netwok_nn.tensor(47.770024556380115 , grad = 1.0)\n",
      "Loss at Epoch 1157 is : netwok_nn.tensor(47.65834184557596 , grad = 1.0)\n",
      "Loss at Epoch 1158 is : netwok_nn.tensor(47.546812063947264 , grad = 1.0)\n",
      "Loss at Epoch 1159 is : netwok_nn.tensor(47.43543512928963 , grad = 1.0)\n",
      "Loss at Epoch 1160 is : netwok_nn.tensor(47.324210959411204 , grad = 1.0)\n",
      "Loss at Epoch 1161 is : netwok_nn.tensor(47.21313947213267 , grad = 1.0)\n",
      "Loss at Epoch 1162 is : netwok_nn.tensor(47.10222058528734 , grad = 1.0)\n",
      "Loss at Epoch 1163 is : netwok_nn.tensor(46.99145421672115 , grad = 1.0)\n",
      "Loss at Epoch 1164 is : netwok_nn.tensor(46.880840284292645 , grad = 1.0)\n",
      "Loss at Epoch 1165 is : netwok_nn.tensor(46.77037870587312 , grad = 1.0)\n",
      "Loss at Epoch 1166 is : netwok_nn.tensor(46.66006939934657 , grad = 1.0)\n",
      "Loss at Epoch 1167 is : netwok_nn.tensor(46.54991228260976 , grad = 1.0)\n",
      "Loss at Epoch 1168 is : netwok_nn.tensor(46.43990727357221 , grad = 1.0)\n",
      "Loss at Epoch 1169 is : netwok_nn.tensor(46.33005429015624 , grad = 1.0)\n",
      "Loss at Epoch 1170 is : netwok_nn.tensor(46.22035325029707 , grad = 1.0)\n",
      "Loss at Epoch 1171 is : netwok_nn.tensor(46.110804071942795 , grad = 1.0)\n",
      "Loss at Epoch 1172 is : netwok_nn.tensor(46.00140667305439 , grad = 1.0)\n",
      "Loss at Epoch 1173 is : netwok_nn.tensor(45.89216097160579 , grad = 1.0)\n",
      "Loss at Epoch 1174 is : netwok_nn.tensor(45.78306688558394 , grad = 1.0)\n",
      "Loss at Epoch 1175 is : netwok_nn.tensor(45.67412433298873 , grad = 1.0)\n",
      "Loss at Epoch 1176 is : netwok_nn.tensor(45.565333231833165 , grad = 1.0)\n",
      "Loss at Epoch 1177 is : netwok_nn.tensor(45.456693500143295 , grad = 1.0)\n",
      "Loss at Epoch 1178 is : netwok_nn.tensor(45.34820505595828 , grad = 1.0)\n",
      "Loss at Epoch 1179 is : netwok_nn.tensor(45.23986781733044 , grad = 1.0)\n",
      "Loss at Epoch 1180 is : netwok_nn.tensor(45.13168170232529 , grad = 1.0)\n",
      "Loss at Epoch 1181 is : netwok_nn.tensor(45.02364662902152 , grad = 1.0)\n",
      "Loss at Epoch 1182 is : netwok_nn.tensor(44.91576251551111 , grad = 1.0)\n",
      "Loss at Epoch 1183 is : netwok_nn.tensor(44.8080292798993 , grad = 1.0)\n",
      "Loss at Epoch 1184 is : netwok_nn.tensor(44.700446840304664 , grad = 1.0)\n",
      "Loss at Epoch 1185 is : netwok_nn.tensor(44.59301511485913 , grad = 1.0)\n",
      "Loss at Epoch 1186 is : netwok_nn.tensor(44.48573402170802 , grad = 1.0)\n",
      "Loss at Epoch 1187 is : netwok_nn.tensor(44.37860347901008 , grad = 1.0)\n",
      "Loss at Epoch 1188 is : netwok_nn.tensor(44.271623404937515 , grad = 1.0)\n",
      "Loss at Epoch 1189 is : netwok_nn.tensor(44.16479371767604 , grad = 1.0)\n",
      "Loss at Epoch 1190 is : netwok_nn.tensor(44.0581143354249 , grad = 1.0)\n",
      "Loss at Epoch 1191 is : netwok_nn.tensor(43.95158517639693 , grad = 1.0)\n",
      "Loss at Epoch 1192 is : netwok_nn.tensor(43.845206158818556 , grad = 1.0)\n",
      "Loss at Epoch 1193 is : netwok_nn.tensor(43.73897720092987 , grad = 1.0)\n",
      "Loss at Epoch 1194 is : netwok_nn.tensor(43.63289822098465 , grad = 1.0)\n",
      "Loss at Epoch 1195 is : netwok_nn.tensor(43.5269691372504 , grad = 1.0)\n",
      "Loss at Epoch 1196 is : netwok_nn.tensor(43.42118986800836 , grad = 1.0)\n",
      "Loss at Epoch 1197 is : netwok_nn.tensor(43.31556033155361 , grad = 1.0)\n",
      "Loss at Epoch 1198 is : netwok_nn.tensor(43.21008044619507 , grad = 1.0)\n",
      "Loss at Epoch 1199 is : netwok_nn.tensor(43.10475013025552 , grad = 1.0)\n",
      "Loss at Epoch 1200 is : netwok_nn.tensor(42.99956930207167 , grad = 1.0)\n",
      "Loss at Epoch 1201 is : netwok_nn.tensor(42.8945378799942 , grad = 1.0)\n",
      "Loss at Epoch 1202 is : netwok_nn.tensor(42.7896557823878 , grad = 1.0)\n",
      "Loss at Epoch 1203 is : netwok_nn.tensor(42.684922927631185 , grad = 1.0)\n",
      "Loss at Epoch 1204 is : netwok_nn.tensor(42.58033923411715 , grad = 1.0)\n",
      "Loss at Epoch 1205 is : netwok_nn.tensor(42.475904620252635 , grad = 1.0)\n",
      "Loss at Epoch 1206 is : netwok_nn.tensor(42.37161900445871 , grad = 1.0)\n",
      "Loss at Epoch 1207 is : netwok_nn.tensor(42.26748230517071 , grad = 1.0)\n",
      "Loss at Epoch 1208 is : netwok_nn.tensor(42.16349444083818 , grad = 1.0)\n",
      "Loss at Epoch 1209 is : netwok_nn.tensor(42.05965532992499 , grad = 1.0)\n",
      "Loss at Epoch 1210 is : netwok_nn.tensor(41.955964890909314 , grad = 1.0)\n",
      "Loss at Epoch 1211 is : netwok_nn.tensor(41.85242304228373 , grad = 1.0)\n",
      "Loss at Epoch 1212 is : netwok_nn.tensor(41.74902970255525 , grad = 1.0)\n",
      "Loss at Epoch 1213 is : netwok_nn.tensor(41.64578479024531 , grad = 1.0)\n",
      "Loss at Epoch 1214 is : netwok_nn.tensor(41.54268822388992 , grad = 1.0)\n",
      "Loss at Epoch 1215 is : netwok_nn.tensor(41.439739922039614 , grad = 1.0)\n",
      "Loss at Epoch 1216 is : netwok_nn.tensor(41.33693980325955 , grad = 1.0)\n",
      "Loss at Epoch 1217 is : netwok_nn.tensor(41.23428778612951 , grad = 1.0)\n",
      "Loss at Epoch 1218 is : netwok_nn.tensor(41.13178378924401 , grad = 1.0)\n",
      "Loss at Epoch 1219 is : netwok_nn.tensor(41.02942773121229 , grad = 1.0)\n",
      "Loss at Epoch 1220 is : netwok_nn.tensor(40.92721953065836 , grad = 1.0)\n",
      "Loss at Epoch 1221 is : netwok_nn.tensor(40.82515910622113 , grad = 1.0)\n",
      "Loss at Epoch 1222 is : netwok_nn.tensor(40.723246376554314 , grad = 1.0)\n",
      "Loss at Epoch 1223 is : netwok_nn.tensor(40.62148126032665 , grad = 1.0)\n",
      "Loss at Epoch 1224 is : netwok_nn.tensor(40.5198636762218 , grad = 1.0)\n",
      "Loss at Epoch 1225 is : netwok_nn.tensor(40.41839354293846 , grad = 1.0)\n",
      "Loss at Epoch 1226 is : netwok_nn.tensor(40.31707077919046 , grad = 1.0)\n",
      "Loss at Epoch 1227 is : netwok_nn.tensor(40.215895303706716 , grad = 1.0)\n",
      "Loss at Epoch 1228 is : netwok_nn.tensor(40.114867035231335 , grad = 1.0)\n",
      "Loss at Epoch 1229 is : netwok_nn.tensor(40.013985892523664 , grad = 1.0)\n",
      "Loss at Epoch 1230 is : netwok_nn.tensor(39.91325179435838 , grad = 1.0)\n",
      "Loss at Epoch 1231 is : netwok_nn.tensor(39.81266465952542 , grad = 1.0)\n",
      "Loss at Epoch 1232 is : netwok_nn.tensor(39.712224406830146 , grad = 1.0)\n",
      "Loss at Epoch 1233 is : netwok_nn.tensor(39.6119309550934 , grad = 1.0)\n",
      "Loss at Epoch 1234 is : netwok_nn.tensor(39.511784223151466 , grad = 1.0)\n",
      "Loss at Epoch 1235 is : netwok_nn.tensor(39.41178412985623 , grad = 1.0)\n",
      "Loss at Epoch 1236 is : netwok_nn.tensor(39.31193059407516 , grad = 1.0)\n",
      "Loss at Epoch 1237 is : netwok_nn.tensor(39.21222353469138 , grad = 1.0)\n",
      "Loss at Epoch 1238 is : netwok_nn.tensor(39.11266287060373 , grad = 1.0)\n",
      "Loss at Epoch 1239 is : netwok_nn.tensor(39.01324852072684 , grad = 1.0)\n",
      "Loss at Epoch 1240 is : netwok_nn.tensor(38.91398040399117 , grad = 1.0)\n",
      "Loss at Epoch 1241 is : netwok_nn.tensor(38.81485843934304 , grad = 1.0)\n",
      "Loss at Epoch 1242 is : netwok_nn.tensor(38.71588254574474 , grad = 1.0)\n",
      "Loss at Epoch 1243 is : netwok_nn.tensor(38.61705264217457 , grad = 1.0)\n",
      "Loss at Epoch 1244 is : netwok_nn.tensor(38.518368647626865 , grad = 1.0)\n",
      "Loss at Epoch 1245 is : netwok_nn.tensor(38.419830481112086 , grad = 1.0)\n",
      "Loss at Epoch 1246 is : netwok_nn.tensor(38.32143806165688 , grad = 1.0)\n",
      "Loss at Epoch 1247 is : netwok_nn.tensor(38.22319130830414 , grad = 1.0)\n",
      "Loss at Epoch 1248 is : netwok_nn.tensor(38.125090140113045 , grad = 1.0)\n",
      "Loss at Epoch 1249 is : netwok_nn.tensor(38.02713447615914 , grad = 1.0)\n",
      "Loss at Epoch 1250 is : netwok_nn.tensor(37.9293242355344 , grad = 1.0)\n",
      "Loss at Epoch 1251 is : netwok_nn.tensor(37.83165933734731 , grad = 1.0)\n",
      "Loss at Epoch 1252 is : netwok_nn.tensor(37.73413970072286 , grad = 1.0)\n",
      "Loss at Epoch 1253 is : netwok_nn.tensor(37.63676524480268 , grad = 1.0)\n",
      "Loss at Epoch 1254 is : netwok_nn.tensor(37.53953588874508 , grad = 1.0)\n",
      "Loss at Epoch 1255 is : netwok_nn.tensor(37.44245155172513 , grad = 1.0)\n",
      "Loss at Epoch 1256 is : netwok_nn.tensor(37.345512152934646 , grad = 1.0)\n",
      "Loss at Epoch 1257 is : netwok_nn.tensor(37.24871761158237 , grad = 1.0)\n",
      "Loss at Epoch 1258 is : netwok_nn.tensor(37.152067846894006 , grad = 1.0)\n",
      "Loss at Epoch 1259 is : netwok_nn.tensor(37.055562778112204 , grad = 1.0)\n",
      "Loss at Epoch 1260 is : netwok_nn.tensor(36.95920232449675 , grad = 1.0)\n",
      "Loss at Epoch 1261 is : netwok_nn.tensor(36.862986405324534 , grad = 1.0)\n",
      "Loss at Epoch 1262 is : netwok_nn.tensor(36.76691493988969 , grad = 1.0)\n",
      "Loss at Epoch 1263 is : netwok_nn.tensor(36.670987847503625 , grad = 1.0)\n",
      "Loss at Epoch 1264 is : netwok_nn.tensor(36.57520504749509 , grad = 1.0)\n",
      "Loss at Epoch 1265 is : netwok_nn.tensor(36.47956645921029 , grad = 1.0)\n",
      "Loss at Epoch 1266 is : netwok_nn.tensor(36.384072002012914 , grad = 1.0)\n",
      "Loss at Epoch 1267 is : netwok_nn.tensor(36.28872159528423 , grad = 1.0)\n",
      "Loss at Epoch 1268 is : netwok_nn.tensor(36.19351515842313 , grad = 1.0)\n",
      "Loss at Epoch 1269 is : netwok_nn.tensor(36.09845261084626 , grad = 1.0)\n",
      "Loss at Epoch 1270 is : netwok_nn.tensor(36.00353387198803 , grad = 1.0)\n",
      "Loss at Epoch 1271 is : netwok_nn.tensor(35.90875886130075 , grad = 1.0)\n",
      "Loss at Epoch 1272 is : netwok_nn.tensor(35.814127498254614 , grad = 1.0)\n",
      "Loss at Epoch 1273 is : netwok_nn.tensor(35.7196397023379 , grad = 1.0)\n",
      "Loss at Epoch 1274 is : netwok_nn.tensor(35.625295393057 , grad = 1.0)\n",
      "Loss at Epoch 1275 is : netwok_nn.tensor(35.53109448993639 , grad = 1.0)\n",
      "Loss at Epoch 1276 is : netwok_nn.tensor(35.4370369125189 , grad = 1.0)\n",
      "Loss at Epoch 1277 is : netwok_nn.tensor(35.343122580365645 , grad = 1.0)\n",
      "Loss at Epoch 1278 is : netwok_nn.tensor(35.24935141305618 , grad = 1.0)\n",
      "Loss at Epoch 1279 is : netwok_nn.tensor(35.155723330188536 , grad = 1.0)\n",
      "Loss at Epoch 1280 is : netwok_nn.tensor(35.06223825137933 , grad = 1.0)\n",
      "Loss at Epoch 1281 is : netwok_nn.tensor(34.96889609626384 , grad = 1.0)\n",
      "Loss at Epoch 1282 is : netwok_nn.tensor(34.875696784496114 , grad = 1.0)\n",
      "Loss at Epoch 1283 is : netwok_nn.tensor(34.78264023574901 , grad = 1.0)\n",
      "Loss at Epoch 1284 is : netwok_nn.tensor(34.689726369714286 , grad = 1.0)\n",
      "Loss at Epoch 1285 is : netwok_nn.tensor(34.59695510610274 , grad = 1.0)\n",
      "Loss at Epoch 1286 is : netwok_nn.tensor(34.5043263646442 , grad = 1.0)\n",
      "Loss at Epoch 1287 is : netwok_nn.tensor(34.4118400650877 , grad = 1.0)\n",
      "Loss at Epoch 1288 is : netwok_nn.tensor(34.31949612720157 , grad = 1.0)\n",
      "Loss at Epoch 1289 is : netwok_nn.tensor(34.22729447077346 , grad = 1.0)\n",
      "Loss at Epoch 1290 is : netwok_nn.tensor(34.13523501561043 , grad = 1.0)\n",
      "Loss at Epoch 1291 is : netwok_nn.tensor(34.04331768153911 , grad = 1.0)\n",
      "Loss at Epoch 1292 is : netwok_nn.tensor(33.951542388405734 , grad = 1.0)\n",
      "Loss at Epoch 1293 is : netwok_nn.tensor(33.85990905607625 , grad = 1.0)\n",
      "Loss at Epoch 1294 is : netwok_nn.tensor(33.76841760443645 , grad = 1.0)\n",
      "Loss at Epoch 1295 is : netwok_nn.tensor(33.677067953392005 , grad = 1.0)\n",
      "Loss at Epoch 1296 is : netwok_nn.tensor(33.585860022868545 , grad = 1.0)\n",
      "Loss at Epoch 1297 is : netwok_nn.tensor(33.49479373281188 , grad = 1.0)\n",
      "Loss at Epoch 1298 is : netwok_nn.tensor(33.403869003187886 , grad = 1.0)\n",
      "Loss at Epoch 1299 is : netwok_nn.tensor(33.31308575398281 , grad = 1.0)\n",
      "Loss at Epoch 1300 is : netwok_nn.tensor(33.22244390520328 , grad = 1.0)\n",
      "Loss at Epoch 1301 is : netwok_nn.tensor(33.13194337687637 , grad = 1.0)\n",
      "Loss at Epoch 1302 is : netwok_nn.tensor(33.04158408904979 , grad = 1.0)\n",
      "Loss at Epoch 1303 is : netwok_nn.tensor(32.95136596179186 , grad = 1.0)\n",
      "Loss at Epoch 1304 is : netwok_nn.tensor(32.861288915191764 , grad = 1.0)\n",
      "Loss at Epoch 1305 is : netwok_nn.tensor(32.771352869359475 , grad = 1.0)\n",
      "Loss at Epoch 1306 is : netwok_nn.tensor(32.68155774442606 , grad = 1.0)\n",
      "Loss at Epoch 1307 is : netwok_nn.tensor(32.59190346054361 , grad = 1.0)\n",
      "Loss at Epoch 1308 is : netwok_nn.tensor(32.5023899378855 , grad = 1.0)\n",
      "Loss at Epoch 1309 is : netwok_nn.tensor(32.41301709664631 , grad = 1.0)\n",
      "Loss at Epoch 1310 is : netwok_nn.tensor(32.323784857042085 , grad = 1.0)\n",
      "Loss at Epoch 1311 is : netwok_nn.tensor(32.23469313931037 , grad = 1.0)\n",
      "Loss at Epoch 1312 is : netwok_nn.tensor(32.14574186371041 , grad = 1.0)\n",
      "Loss at Epoch 1313 is : netwok_nn.tensor(32.05693095052309 , grad = 1.0)\n",
      "Loss at Epoch 1314 is : netwok_nn.tensor(31.968260320051193 , grad = 1.0)\n",
      "Loss at Epoch 1315 is : netwok_nn.tensor(31.879729892619512 , grad = 1.0)\n",
      "Loss at Epoch 1316 is : netwok_nn.tensor(31.791339588574857 , grad = 1.0)\n",
      "Loss at Epoch 1317 is : netwok_nn.tensor(31.703089328286236 , grad = 1.0)\n",
      "Loss at Epoch 1318 is : netwok_nn.tensor(31.614979032144998 , grad = 1.0)\n",
      "Loss at Epoch 1319 is : netwok_nn.tensor(31.527008620564867 , grad = 1.0)\n",
      "Loss at Epoch 1320 is : netwok_nn.tensor(31.43917801398217 , grad = 1.0)\n",
      "Loss at Epoch 1321 is : netwok_nn.tensor(31.35148713285582 , grad = 1.0)\n",
      "Loss at Epoch 1322 is : netwok_nn.tensor(31.26393589766755 , grad = 1.0)\n",
      "Loss at Epoch 1323 is : netwok_nn.tensor(31.17652422892197 , grad = 1.0)\n",
      "Loss at Epoch 1324 is : netwok_nn.tensor(31.089252047146733 , grad = 1.0)\n",
      "Loss at Epoch 1325 is : netwok_nn.tensor(31.002119272892614 , grad = 1.0)\n",
      "Loss at Epoch 1326 is : netwok_nn.tensor(30.91512582673361 , grad = 1.0)\n",
      "Loss at Epoch 1327 is : netwok_nn.tensor(30.828271629267192 , grad = 1.0)\n",
      "Loss at Epoch 1328 is : netwok_nn.tensor(30.741556601114265 , grad = 1.0)\n",
      "Loss at Epoch 1329 is : netwok_nn.tensor(30.65498066291942 , grad = 1.0)\n",
      "Loss at Epoch 1330 is : netwok_nn.tensor(30.56854373535097 , grad = 1.0)\n",
      "Loss at Epoch 1331 is : netwok_nn.tensor(30.482245739101167 , grad = 1.0)\n",
      "Loss at Epoch 1332 is : netwok_nn.tensor(30.396086594886256 , grad = 1.0)\n",
      "Loss at Epoch 1333 is : netwok_nn.tensor(30.310066223446658 , grad = 1.0)\n",
      "Loss at Epoch 1334 is : netwok_nn.tensor(30.22418454554703 , grad = 1.0)\n",
      "Loss at Epoch 1335 is : netwok_nn.tensor(30.138441481976514 , grad = 1.0)\n",
      "Loss at Epoch 1336 is : netwok_nn.tensor(30.052836953548773 , grad = 1.0)\n",
      "Loss at Epoch 1337 is : netwok_nn.tensor(29.967370881102124 , grad = 1.0)\n",
      "Loss at Epoch 1338 is : netwok_nn.tensor(29.882043185499768 , grad = 1.0)\n",
      "Loss at Epoch 1339 is : netwok_nn.tensor(29.79685378762981 , grad = 1.0)\n",
      "Loss at Epoch 1340 is : netwok_nn.tensor(29.711802608405492 , grad = 1.0)\n",
      "Loss at Epoch 1341 is : netwok_nn.tensor(29.626889568765293 , grad = 1.0)\n",
      "Loss at Epoch 1342 is : netwok_nn.tensor(29.54211458967302 , grad = 1.0)\n",
      "Loss at Epoch 1343 is : netwok_nn.tensor(29.45747759211809 , grad = 1.0)\n",
      "Loss at Epoch 1344 is : netwok_nn.tensor(29.37297849711549 , grad = 1.0)\n",
      "Loss at Epoch 1345 is : netwok_nn.tensor(29.288617225706062 , grad = 1.0)\n",
      "Loss at Epoch 1346 is : netwok_nn.tensor(29.204393698956604 , grad = 1.0)\n",
      "Loss at Epoch 1347 is : netwok_nn.tensor(29.120307837960002 , grad = 1.0)\n",
      "Loss at Epoch 1348 is : netwok_nn.tensor(29.03635956383539 , grad = 1.0)\n",
      "Loss at Epoch 1349 is : netwok_nn.tensor(28.95254879772829 , grad = 1.0)\n",
      "Loss at Epoch 1350 is : netwok_nn.tensor(28.868875460810774 , grad = 1.0)\n",
      "Loss at Epoch 1351 is : netwok_nn.tensor(28.785339474281624 , grad = 1.0)\n",
      "Loss at Epoch 1352 is : netwok_nn.tensor(28.701940759366448 , grad = 1.0)\n",
      "Loss at Epoch 1353 is : netwok_nn.tensor(28.618679237317863 , grad = 1.0)\n",
      "Loss at Epoch 1354 is : netwok_nn.tensor(28.535554829415645 , grad = 1.0)\n",
      "Loss at Epoch 1355 is : netwok_nn.tensor(28.4525674569669 , grad = 1.0)\n",
      "Loss at Epoch 1356 is : netwok_nn.tensor(28.36971704130617 , grad = 1.0)\n",
      "Loss at Epoch 1357 is : netwok_nn.tensor(28.28700350379569 , grad = 1.0)\n",
      "Loss at Epoch 1358 is : netwok_nn.tensor(28.204426765825403 , grad = 1.0)\n",
      "Loss at Epoch 1359 is : netwok_nn.tensor(28.12198674881323 , grad = 1.0)\n",
      "Loss at Epoch 1360 is : netwok_nn.tensor(28.039683374205246 , grad = 1.0)\n",
      "Loss at Epoch 1361 is : netwok_nn.tensor(27.957516563475757 , grad = 1.0)\n",
      "Loss at Epoch 1362 is : netwok_nn.tensor(27.8754862381275 , grad = 1.0)\n",
      "Loss at Epoch 1363 is : netwok_nn.tensor(27.79359231969188 , grad = 1.0)\n",
      "Loss at Epoch 1364 is : netwok_nn.tensor(27.711834729729027 , grad = 1.0)\n",
      "Loss at Epoch 1365 is : netwok_nn.tensor(27.63021338982802 , grad = 1.0)\n",
      "Loss at Epoch 1366 is : netwok_nn.tensor(27.548728221607067 , grad = 1.0)\n",
      "Loss at Epoch 1367 is : netwok_nn.tensor(27.467379146713608 , grad = 1.0)\n",
      "Loss at Epoch 1368 is : netwok_nn.tensor(27.38616608682465 , grad = 1.0)\n",
      "Loss at Epoch 1369 is : netwok_nn.tensor(27.305088963646707 , grad = 1.0)\n",
      "Loss at Epoch 1370 is : netwok_nn.tensor(27.22414769891618 , grad = 1.0)\n",
      "Loss at Epoch 1371 is : netwok_nn.tensor(27.143342214399414 , grad = 1.0)\n",
      "Loss at Epoch 1372 is : netwok_nn.tensor(27.062672431892953 , grad = 1.0)\n",
      "Loss at Epoch 1373 is : netwok_nn.tensor(26.982138273223622 , grad = 1.0)\n",
      "Loss at Epoch 1374 is : netwok_nn.tensor(26.901739660248833 , grad = 1.0)\n",
      "Loss at Epoch 1375 is : netwok_nn.tensor(26.821476514856645 , grad = 1.0)\n",
      "Loss at Epoch 1376 is : netwok_nn.tensor(26.741348758966033 , grad = 1.0)\n",
      "Loss at Epoch 1377 is : netwok_nn.tensor(26.66135631452703 , grad = 1.0)\n",
      "Loss at Epoch 1378 is : netwok_nn.tensor(26.581499103520926 , grad = 1.0)\n",
      "Loss at Epoch 1379 is : netwok_nn.tensor(26.501777047960466 , grad = 1.0)\n",
      "Loss at Epoch 1380 is : netwok_nn.tensor(26.422190069890007 , grad = 1.0)\n",
      "Loss at Epoch 1381 is : netwok_nn.tensor(26.34273809138574 , grad = 1.0)\n",
      "Loss at Epoch 1382 is : netwok_nn.tensor(26.26342103455585 , grad = 1.0)\n",
      "Loss at Epoch 1383 is : netwok_nn.tensor(26.184238821540784 , grad = 1.0)\n",
      "Loss at Epoch 1384 is : netwok_nn.tensor(26.105191374513332 , grad = 1.0)\n",
      "Loss at Epoch 1385 is : netwok_nn.tensor(26.026278615678898 , grad = 1.0)\n",
      "Loss at Epoch 1386 is : netwok_nn.tensor(25.9475004672757 , grad = 1.0)\n",
      "Loss at Epoch 1387 is : netwok_nn.tensor(25.8688568515749 , grad = 1.0)\n",
      "Loss at Epoch 1388 is : netwok_nn.tensor(25.790347690880903 , grad = 1.0)\n",
      "Loss at Epoch 1389 is : netwok_nn.tensor(25.71197290753149 , grad = 1.0)\n",
      "Loss at Epoch 1390 is : netwok_nn.tensor(25.633732423898014 , grad = 1.0)\n",
      "Loss at Epoch 1391 is : netwok_nn.tensor(25.55562616238566 , grad = 1.0)\n",
      "Loss at Epoch 1392 is : netwok_nn.tensor(25.4776540454336 , grad = 1.0)\n",
      "Loss at Epoch 1393 is : netwok_nn.tensor(25.399815995515237 , grad = 1.0)\n",
      "Loss at Epoch 1394 is : netwok_nn.tensor(25.322111935138356 , grad = 1.0)\n",
      "Loss at Epoch 1395 is : netwok_nn.tensor(25.24454178684545 , grad = 1.0)\n",
      "Loss at Epoch 1396 is : netwok_nn.tensor(25.167105473213773 , grad = 1.0)\n",
      "Loss at Epoch 1397 is : netwok_nn.tensor(25.089802916855657 , grad = 1.0)\n",
      "Loss at Epoch 1398 is : netwok_nn.tensor(25.012634040418746 , grad = 1.0)\n",
      "Loss at Epoch 1399 is : netwok_nn.tensor(24.935598766586104 , grad = 1.0)\n",
      "Loss at Epoch 1400 is : netwok_nn.tensor(24.858697018076544 , grad = 1.0)\n",
      "Loss at Epoch 1401 is : netwok_nn.tensor(24.7819287176448 , grad = 1.0)\n",
      "Loss at Epoch 1402 is : netwok_nn.tensor(24.70529378808172 , grad = 1.0)\n",
      "Loss at Epoch 1403 is : netwok_nn.tensor(24.628792152214523 , grad = 1.0)\n",
      "Loss at Epoch 1404 is : netwok_nn.tensor(24.552423732907037 , grad = 1.0)\n",
      "Loss at Epoch 1405 is : netwok_nn.tensor(24.476188453059887 , grad = 1.0)\n",
      "Loss at Epoch 1406 is : netwok_nn.tensor(24.40008623561073 , grad = 1.0)\n",
      "Loss at Epoch 1407 is : netwok_nn.tensor(24.324117003534493 , grad = 1.0)\n",
      "Loss at Epoch 1408 is : netwok_nn.tensor(24.248280679843603 , grad = 1.0)\n",
      "Loss at Epoch 1409 is : netwok_nn.tensor(24.172577187588214 , grad = 1.0)\n",
      "Loss at Epoch 1410 is : netwok_nn.tensor(24.097006449856405 , grad = 1.0)\n",
      "Loss at Epoch 1411 is : netwok_nn.tensor(24.021568389774497 , grad = 1.0)\n",
      "Loss at Epoch 1412 is : netwok_nn.tensor(23.946262930507224 , grad = 1.0)\n",
      "Loss at Epoch 1413 is : netwok_nn.tensor(23.87108999525792 , grad = 1.0)\n",
      "Loss at Epoch 1414 is : netwok_nn.tensor(23.796049507268922 , grad = 1.0)\n",
      "Loss at Epoch 1415 is : netwok_nn.tensor(23.72114138982163 , grad = 1.0)\n",
      "Loss at Epoch 1416 is : netwok_nn.tensor(23.646365566236856 , grad = 1.0)\n",
      "Loss at Epoch 1417 is : netwok_nn.tensor(23.571721959875045 , grad = 1.0)\n",
      "Loss at Epoch 1418 is : netwok_nn.tensor(23.497210494136485 , grad = 1.0)\n",
      "Loss at Epoch 1419 is : netwok_nn.tensor(23.422831092461603 , grad = 1.0)\n",
      "Loss at Epoch 1420 is : netwok_nn.tensor(23.34858367833121 , grad = 1.0)\n",
      "Loss at Epoch 1421 is : netwok_nn.tensor(23.274468175266662 , grad = 1.0)\n",
      "Loss at Epoch 1422 is : netwok_nn.tensor(23.20048450683024 , grad = 1.0)\n",
      "Loss at Epoch 1423 is : netwok_nn.tensor(23.12663259662531 , grad = 1.0)\n",
      "Loss at Epoch 1424 is : netwok_nn.tensor(23.052912368296596 , grad = 1.0)\n",
      "Loss at Epoch 1425 is : netwok_nn.tensor(22.979323745530486 , grad = 1.0)\n",
      "Loss at Epoch 1426 is : netwok_nn.tensor(22.905866652055217 , grad = 1.0)\n",
      "Loss at Epoch 1427 is : netwok_nn.tensor(22.832541011641194 , grad = 1.0)\n",
      "Loss at Epoch 1428 is : netwok_nn.tensor(22.75934674810115 , grad = 1.0)\n",
      "Loss at Epoch 1429 is : netwok_nn.tensor(22.68628378529057 , grad = 1.0)\n",
      "Loss at Epoch 1430 is : netwok_nn.tensor(22.6133520471078 , grad = 1.0)\n",
      "Loss at Epoch 1431 is : netwok_nn.tensor(22.540551457494406 , grad = 1.0)\n",
      "Loss at Epoch 1432 is : netwok_nn.tensor(22.467881940435394 , grad = 1.0)\n",
      "Loss at Epoch 1433 is : netwok_nn.tensor(22.395343419959467 , grad = 1.0)\n",
      "Loss at Epoch 1434 is : netwok_nn.tensor(22.322935820139378 , grad = 1.0)\n",
      "Loss at Epoch 1435 is : netwok_nn.tensor(22.250659065092062 , grad = 1.0)\n",
      "Loss at Epoch 1436 is : netwok_nn.tensor(22.178513078979066 , grad = 1.0)\n",
      "Loss at Epoch 1437 is : netwok_nn.tensor(22.10649778600669 , grad = 1.0)\n",
      "Loss at Epoch 1438 is : netwok_nn.tensor(22.034613110426367 , grad = 1.0)\n",
      "Loss at Epoch 1439 is : netwok_nn.tensor(21.962858976534832 , grad = 1.0)\n",
      "Loss at Epoch 1440 is : netwok_nn.tensor(21.891235308674485 , grad = 1.0)\n",
      "Loss at Epoch 1441 is : netwok_nn.tensor(21.819742031233663 , grad = 1.0)\n",
      "Loss at Epoch 1442 is : netwok_nn.tensor(21.74837906864689 , grad = 1.0)\n",
      "Loss at Epoch 1443 is : netwok_nn.tensor(21.677146345395162 , grad = 1.0)\n",
      "Loss at Epoch 1444 is : netwok_nn.tensor(21.606043786006243 , grad = 1.0)\n",
      "Loss at Epoch 1445 is : netwok_nn.tensor(21.53507131505499 , grad = 1.0)\n",
      "Loss at Epoch 1446 is : netwok_nn.tensor(21.464228857163548 , grad = 1.0)\n",
      "Loss at Epoch 1447 is : netwok_nn.tensor(21.393516337001742 , grad = 1.0)\n",
      "Loss at Epoch 1448 is : netwok_nn.tensor(21.32293367928728 , grad = 1.0)\n",
      "Loss at Epoch 1449 is : netwok_nn.tensor(21.25248080878612 , grad = 1.0)\n",
      "Loss at Epoch 1450 is : netwok_nn.tensor(21.182157650312725 , grad = 1.0)\n",
      "Loss at Epoch 1451 is : netwok_nn.tensor(21.11196412873032 , grad = 1.0)\n",
      "Loss at Epoch 1452 is : netwok_nn.tensor(21.041900168951294 , grad = 1.0)\n",
      "Loss at Epoch 1453 is : netwok_nn.tensor(20.97196569593741 , grad = 1.0)\n",
      "Loss at Epoch 1454 is : netwok_nn.tensor(20.902160634700163 , grad = 1.0)\n",
      "Loss at Epoch 1455 is : netwok_nn.tensor(20.832484910300995 , grad = 1.0)\n",
      "Loss at Epoch 1456 is : netwok_nn.tensor(20.76293844785171 , grad = 1.0)\n",
      "Loss at Epoch 1457 is : netwok_nn.tensor(20.693521172514703 , grad = 1.0)\n",
      "Loss at Epoch 1458 is : netwok_nn.tensor(20.624233009503286 , grad = 1.0)\n",
      "Loss at Epoch 1459 is : netwok_nn.tensor(20.555073884082017 , grad = 1.0)\n",
      "Loss at Epoch 1460 is : netwok_nn.tensor(20.48604372156696 , grad = 1.0)\n",
      "Loss at Epoch 1461 is : netwok_nn.tensor(20.417142447326068 , grad = 1.0)\n",
      "Loss at Epoch 1462 is : netwok_nn.tensor(20.348369986779417 , grad = 1.0)\n",
      "Loss at Epoch 1463 is : netwok_nn.tensor(20.279726265399578 , grad = 1.0)\n",
      "Loss at Epoch 1464 is : netwok_nn.tensor(20.211211208711948 , grad = 1.0)\n",
      "Loss at Epoch 1465 is : netwok_nn.tensor(20.142824742294945 , grad = 1.0)\n",
      "Loss at Epoch 1466 is : netwok_nn.tensor(20.074566791780505 , grad = 1.0)\n",
      "Loss at Epoch 1467 is : netwok_nn.tensor(20.00643728285425 , grad = 1.0)\n",
      "Loss at Epoch 1468 is : netwok_nn.tensor(19.93843614125591 , grad = 1.0)\n",
      "Loss at Epoch 1469 is : netwok_nn.tensor(19.870563292779593 , grad = 1.0)\n",
      "Loss at Epoch 1470 is : netwok_nn.tensor(19.802818663274103 , grad = 1.0)\n",
      "Loss at Epoch 1471 is : netwok_nn.tensor(19.735202178643345 , grad = 1.0)\n",
      "Loss at Epoch 1472 is : netwok_nn.tensor(19.667713764846532 , grad = 1.0)\n",
      "Loss at Epoch 1473 is : netwok_nn.tensor(19.600353347898622 , grad = 1.0)\n",
      "Loss at Epoch 1474 is : netwok_nn.tensor(19.533120853870564 , grad = 1.0)\n",
      "Loss at Epoch 1475 is : netwok_nn.tensor(19.4660162088897 , grad = 1.0)\n",
      "Loss at Epoch 1476 is : netwok_nn.tensor(19.39903933914008 , grad = 1.0)\n",
      "Loss at Epoch 1477 is : netwok_nn.tensor(19.33219017086275 , grad = 1.0)\n",
      "Loss at Epoch 1478 is : netwok_nn.tensor(19.265468630356132 , grad = 1.0)\n",
      "Loss at Epoch 1479 is : netwok_nn.tensor(19.19887464397638 , grad = 1.0)\n",
      "Loss at Epoch 1480 is : netwok_nn.tensor(19.13240813813768 , grad = 1.0)\n",
      "Loss at Epoch 1481 is : netwok_nn.tensor(19.066069039312573 , grad = 1.0)\n",
      "Loss at Epoch 1482 is : netwok_nn.tensor(18.999857274032376 , grad = 1.0)\n",
      "Loss at Epoch 1483 is : netwok_nn.tensor(18.93377276888743 , grad = 1.0)\n",
      "Loss at Epoch 1484 is : netwok_nn.tensor(18.867815450527544 , grad = 1.0)\n",
      "Loss at Epoch 1485 is : netwok_nn.tensor(18.801985245662237 , grad = 1.0)\n",
      "Loss at Epoch 1486 is : netwok_nn.tensor(18.736282081061184 , grad = 1.0)\n",
      "Loss at Epoch 1487 is : netwok_nn.tensor(18.670705883554476 , grad = 1.0)\n",
      "Loss at Epoch 1488 is : netwok_nn.tensor(18.605256580033032 , grad = 1.0)\n",
      "Loss at Epoch 1489 is : netwok_nn.tensor(18.539934097448928 , grad = 1.0)\n",
      "Loss at Epoch 1490 is : netwok_nn.tensor(18.474738362815756 , grad = 1.0)\n",
      "Loss at Epoch 1491 is : netwok_nn.tensor(18.409669303208997 , grad = 1.0)\n",
      "Loss at Epoch 1492 is : netwok_nn.tensor(18.34472684576632 , grad = 1.0)\n",
      "Loss at Epoch 1493 is : netwok_nn.tensor(18.279910917687978 , grad = 1.0)\n",
      "Loss at Epoch 1494 is : netwok_nn.tensor(18.21522144623718 , grad = 1.0)\n",
      "Loss at Epoch 1495 is : netwok_nn.tensor(18.15065835874042 , grad = 1.0)\n",
      "Loss at Epoch 1496 is : netwok_nn.tensor(18.08622158258785 , grad = 1.0)\n",
      "Loss at Epoch 1497 is : netwok_nn.tensor(18.02191104523364 , grad = 1.0)\n",
      "Loss at Epoch 1498 is : netwok_nn.tensor(17.95772667419637 , grad = 1.0)\n",
      "Loss at Epoch 1499 is : netwok_nn.tensor(17.893668397059322 , grad = 1.0)\n",
      "Loss at Epoch 1500 is : netwok_nn.tensor(17.829736141470917 , grad = 1.0)\n",
      "Loss at Epoch 1501 is : netwok_nn.tensor(17.76592983514506 , grad = 1.0)\n",
      "Loss at Epoch 1502 is : netwok_nn.tensor(17.702249405861497 , grad = 1.0)\n",
      "Loss at Epoch 1503 is : netwok_nn.tensor(17.638694781466196 , grad = 1.0)\n",
      "Loss at Epoch 1504 is : netwok_nn.tensor(17.57526588987168 , grad = 1.0)\n",
      "Loss at Epoch 1505 is : netwok_nn.tensor(17.511962659057474 , grad = 1.0)\n",
      "Loss at Epoch 1506 is : netwok_nn.tensor(17.44878501707041 , grad = 1.0)\n",
      "Loss at Epoch 1507 is : netwok_nn.tensor(17.385732892025047 , grad = 1.0)\n",
      "Loss at Epoch 1508 is : netwok_nn.tensor(17.322806212104 , grad = 1.0)\n",
      "Loss at Epoch 1509 is : netwok_nn.tensor(17.26000490555833 , grad = 1.0)\n",
      "Loss at Epoch 1510 is : netwok_nn.tensor(17.197328900707962 , grad = 1.0)\n",
      "Loss at Epoch 1511 is : netwok_nn.tensor(17.134778125942013 , grad = 1.0)\n",
      "Loss at Epoch 1512 is : netwok_nn.tensor(17.072352509719202 , grad = 1.0)\n",
      "Loss at Epoch 1513 is : netwok_nn.tensor(17.010051980568186 , grad = 1.0)\n",
      "Loss at Epoch 1514 is : netwok_nn.tensor(16.947876467088005 , grad = 1.0)\n",
      "Loss at Epoch 1515 is : netwok_nn.tensor(16.885825897948433 , grad = 1.0)\n",
      "Loss at Epoch 1516 is : netwok_nn.tensor(16.82390020189034 , grad = 1.0)\n",
      "Loss at Epoch 1517 is : netwok_nn.tensor(16.762099307726086 , grad = 1.0)\n",
      "Loss at Epoch 1518 is : netwok_nn.tensor(16.700423144339947 , grad = 1.0)\n",
      "Loss at Epoch 1519 is : netwok_nn.tensor(16.638871640688453 , grad = 1.0)\n",
      "Loss at Epoch 1520 is : netwok_nn.tensor(16.57744472580079 , grad = 1.0)\n",
      "Loss at Epoch 1521 is : netwok_nn.tensor(16.5161423287792 , grad = 1.0)\n",
      "Loss at Epoch 1522 is : netwok_nn.tensor(16.454964378799318 , grad = 1.0)\n",
      "Loss at Epoch 1523 is : netwok_nn.tensor(16.39391080511064 , grad = 1.0)\n",
      "Loss at Epoch 1524 is : netwok_nn.tensor(16.332981537036876 , grad = 1.0)\n",
      "Loss at Epoch 1525 is : netwok_nn.tensor(16.2721765039763 , grad = 1.0)\n",
      "Loss at Epoch 1526 is : netwok_nn.tensor(16.21149563540222 , grad = 1.0)\n",
      "Loss at Epoch 1527 is : netwok_nn.tensor(16.15093886086332 , grad = 1.0)\n",
      "Loss at Epoch 1528 is : netwok_nn.tensor(16.09050610998404 , grad = 1.0)\n",
      "Loss at Epoch 1529 is : netwok_nn.tensor(16.03019731246503 , grad = 1.0)\n",
      "Loss at Epoch 1530 is : netwok_nn.tensor(15.970012398083464 , grad = 1.0)\n",
      "Loss at Epoch 1531 is : netwok_nn.tensor(15.90995129669351 , grad = 1.0)\n",
      "Loss at Epoch 1532 is : netwok_nn.tensor(15.850013938226704 , grad = 1.0)\n",
      "Loss at Epoch 1533 is : netwok_nn.tensor(15.790200252692287 , grad = 1.0)\n",
      "Loss at Epoch 1534 is : netwok_nn.tensor(15.73051017017771 , grad = 1.0)\n",
      "Loss at Epoch 1535 is : netwok_nn.tensor(15.670943620848938 , grad = 1.0)\n",
      "Loss at Epoch 1536 is : netwok_nn.tensor(15.611500534950876 , grad = 1.0)\n",
      "Loss at Epoch 1537 is : netwok_nn.tensor(15.552180842807816 , grad = 1.0)\n",
      "Loss at Epoch 1538 is : netwok_nn.tensor(15.492984474823743 , grad = 1.0)\n",
      "Loss at Epoch 1539 is : netwok_nn.tensor(15.433911361482826 , grad = 1.0)\n",
      "Loss at Epoch 1540 is : netwok_nn.tensor(15.37496143334976 , grad = 1.0)\n",
      "Loss at Epoch 1541 is : netwok_nn.tensor(15.316134621070173 , grad = 1.0)\n",
      "Loss at Epoch 1542 is : netwok_nn.tensor(15.257430855371075 , grad = 1.0)\n",
      "Loss at Epoch 1543 is : netwok_nn.tensor(15.198850067061171 , grad = 1.0)\n",
      "Loss at Epoch 1544 is : netwok_nn.tensor(15.140392187031374 , grad = 1.0)\n",
      "Loss at Epoch 1545 is : netwok_nn.tensor(15.082057146255076 , grad = 1.0)\n",
      "Loss at Epoch 1546 is : netwok_nn.tensor(15.023844875788681 , grad = 1.0)\n",
      "Loss at Epoch 1547 is : netwok_nn.tensor(14.965755306771909 , grad = 1.0)\n",
      "Loss at Epoch 1548 is : netwok_nn.tensor(14.907788370428252 , grad = 1.0)\n",
      "Loss at Epoch 1549 is : netwok_nn.tensor(14.849943998065367 , grad = 1.0)\n",
      "Loss at Epoch 1550 is : netwok_nn.tensor(14.792222121075454 , grad = 1.0)\n",
      "Loss at Epoch 1551 is : netwok_nn.tensor(14.734622670935687 , grad = 1.0)\n",
      "Loss at Epoch 1552 is : netwok_nn.tensor(14.677145579208595 , grad = 1.0)\n",
      "Loss at Epoch 1553 is : netwok_nn.tensor(14.6197907775425 , grad = 1.0)\n",
      "Loss at Epoch 1554 is : netwok_nn.tensor(14.562558197671883 , grad = 1.0)\n",
      "Loss at Epoch 1555 is : netwok_nn.tensor(14.505447771417792 , grad = 1.0)\n",
      "Loss at Epoch 1556 is : netwok_nn.tensor(14.448459430688276 , grad = 1.0)\n",
      "Loss at Epoch 1557 is : netwok_nn.tensor(14.391593107478762 , grad = 1.0)\n",
      "Loss at Epoch 1558 is : netwok_nn.tensor(14.334848733872432 , grad = 1.0)\n",
      "Loss at Epoch 1559 is : netwok_nn.tensor(14.278226242040708 , grad = 1.0)\n",
      "Loss at Epoch 1560 is : netwok_nn.tensor(14.221725564243554 , grad = 1.0)\n",
      "Loss at Epoch 1561 is : netwok_nn.tensor(14.16534663282998 , grad = 1.0)\n",
      "Loss at Epoch 1562 is : netwok_nn.tensor(14.109089380238329 , grad = 1.0)\n",
      "Loss at Epoch 1563 is : netwok_nn.tensor(14.052953738996782 , grad = 1.0)\n",
      "Loss at Epoch 1564 is : netwok_nn.tensor(13.996939641723719 , grad = 1.0)\n",
      "Loss at Epoch 1565 is : netwok_nn.tensor(13.941047021128101 , grad = 1.0)\n",
      "Loss at Epoch 1566 is : netwok_nn.tensor(13.88527581000992 , grad = 1.0)\n",
      "Loss at Epoch 1567 is : netwok_nn.tensor(13.829625941260524 , grad = 1.0)\n",
      "Loss at Epoch 1568 is : netwok_nn.tensor(13.774097347863117 , grad = 1.0)\n",
      "Loss at Epoch 1569 is : netwok_nn.tensor(13.718689962893066 , grad = 1.0)\n",
      "Loss at Epoch 1570 is : netwok_nn.tensor(13.663403719518358 , grad = 1.0)\n",
      "Loss at Epoch 1571 is : netwok_nn.tensor(13.608238550999992 , grad = 1.0)\n",
      "Loss at Epoch 1572 is : netwok_nn.tensor(13.553194390692331 , grad = 1.0)\n",
      "Loss at Epoch 1573 is : netwok_nn.tensor(13.498271172043571 , grad = 1.0)\n",
      "Loss at Epoch 1574 is : netwok_nn.tensor(13.44346882859607 , grad = 1.0)\n",
      "Loss at Epoch 1575 is : netwok_nn.tensor(13.388787293986784 , grad = 1.0)\n",
      "Loss at Epoch 1576 is : netwok_nn.tensor(13.334226501947649 , grad = 1.0)\n",
      "Loss at Epoch 1577 is : netwok_nn.tensor(13.279786386305986 , grad = 1.0)\n",
      "Loss at Epoch 1578 is : netwok_nn.tensor(13.225466880984904 , grad = 1.0)\n",
      "Loss at Epoch 1579 is : netwok_nn.tensor(13.171267920003647 , grad = 1.0)\n",
      "Loss at Epoch 1580 is : netwok_nn.tensor(13.117189437478038 , grad = 1.0)\n",
      "Loss at Epoch 1581 is : netwok_nn.tensor(13.063231367620828 , grad = 1.0)\n",
      "Loss at Epoch 1582 is : netwok_nn.tensor(13.009393644742147 , grad = 1.0)\n",
      "Loss at Epoch 1583 is : netwok_nn.tensor(12.95567620324979 , grad = 1.0)\n",
      "Loss at Epoch 1584 is : netwok_nn.tensor(12.902078977649728 , grad = 1.0)\n",
      "Loss at Epoch 1585 is : netwok_nn.tensor(12.848601902546397 , grad = 1.0)\n",
      "Loss at Epoch 1586 is : netwok_nn.tensor(12.795244912643124 , grad = 1.0)\n",
      "Loss at Epoch 1587 is : netwok_nn.tensor(12.742007942742527 , grad = 1.0)\n",
      "Loss at Epoch 1588 is : netwok_nn.tensor(12.688890927746861 , grad = 1.0)\n",
      "Loss at Epoch 1589 is : netwok_nn.tensor(12.63589380265842 , grad = 1.0)\n",
      "Loss at Epoch 1590 is : netwok_nn.tensor(12.583016502579953 , grad = 1.0)\n",
      "Loss at Epoch 1591 is : netwok_nn.tensor(12.530258962714948 , grad = 1.0)\n",
      "Loss at Epoch 1592 is : netwok_nn.tensor(12.477621118368122 , grad = 1.0)\n",
      "Loss at Epoch 1593 is : netwok_nn.tensor(12.425102904945717 , grad = 1.0)\n",
      "Loss at Epoch 1594 is : netwok_nn.tensor(12.372704257955903 , grad = 1.0)\n",
      "Loss at Epoch 1595 is : netwok_nn.tensor(12.320425113009145 , grad = 1.0)\n",
      "Loss at Epoch 1596 is : netwok_nn.tensor(12.268265405818607 , grad = 1.0)\n",
      "Loss at Epoch 1597 is : netwok_nn.tensor(12.216225072200487 , grad = 1.0)\n",
      "Loss at Epoch 1598 is : netwok_nn.tensor(12.16430404807438 , grad = 1.0)\n",
      "Loss at Epoch 1599 is : netwok_nn.tensor(12.112502269463683 , grad = 1.0)\n",
      "Loss at Epoch 1600 is : netwok_nn.tensor(12.060819672495912 , grad = 1.0)\n",
      "Loss at Epoch 1601 is : netwok_nn.tensor(12.00925619340311 , grad = 1.0)\n",
      "Loss at Epoch 1602 is : netwok_nn.tensor(11.95781176852217 , grad = 1.0)\n",
      "Loss at Epoch 1603 is : netwok_nn.tensor(11.90648633429524 , grad = 1.0)\n",
      "Loss at Epoch 1604 is : netwok_nn.tensor(11.855279827270031 , grad = 1.0)\n",
      "Loss at Epoch 1605 is : netwok_nn.tensor(11.8041921841002 , grad = 1.0)\n",
      "Loss at Epoch 1606 is : netwok_nn.tensor(11.753223341545711 , grad = 1.0)\n",
      "Loss at Epoch 1607 is : netwok_nn.tensor(11.702373236473171 , grad = 1.0)\n",
      "Loss at Epoch 1608 is : netwok_nn.tensor(11.651641805856164 , grad = 1.0)\n",
      "Loss at Epoch 1609 is : netwok_nn.tensor(11.601028986775644 , grad = 1.0)\n",
      "Loss at Epoch 1610 is : netwok_nn.tensor(11.550534716420236 , grad = 1.0)\n",
      "Loss at Epoch 1611 is : netwok_nn.tensor(11.500158932086588 , grad = 1.0)\n",
      "Loss at Epoch 1612 is : netwok_nn.tensor(11.44990157117973 , grad = 1.0)\n",
      "Loss at Epoch 1613 is : netwok_nn.tensor(11.399762571213408 , grad = 1.0)\n",
      "Loss at Epoch 1614 is : netwok_nn.tensor(11.3497418698104 , grad = 1.0)\n",
      "Loss at Epoch 1615 is : netwok_nn.tensor(11.29983940470285 , grad = 1.0)\n",
      "Loss at Epoch 1616 is : netwok_nn.tensor(11.250055113732623 , grad = 1.0)\n",
      "Loss at Epoch 1617 is : netwok_nn.tensor(11.200388934851631 , grad = 1.0)\n",
      "Loss at Epoch 1618 is : netwok_nn.tensor(11.150840806122103 , grad = 1.0)\n",
      "Loss at Epoch 1619 is : netwok_nn.tensor(11.101410665716974 , grad = 1.0)\n",
      "Loss at Epoch 1620 is : netwok_nn.tensor(11.052098451920203 , grad = 1.0)\n",
      "Loss at Epoch 1621 is : netwok_nn.tensor(11.00290410312703 , grad = 1.0)\n",
      "Loss at Epoch 1622 is : netwok_nn.tensor(10.95382755784433 , grad = 1.0)\n",
      "Loss at Epoch 1623 is : netwok_nn.tensor(10.904868754690945 , grad = 1.0)\n",
      "Loss at Epoch 1624 is : netwok_nn.tensor(10.85602763239796 , grad = 1.0)\n",
      "Loss at Epoch 1625 is : netwok_nn.tensor(10.807304129808976 , grad = 1.0)\n",
      "Loss at Epoch 1626 is : netwok_nn.tensor(10.75869818588051 , grad = 1.0)\n",
      "Loss at Epoch 1627 is : netwok_nn.tensor(10.710209739682195 , grad = 1.0)\n",
      "Loss at Epoch 1628 is : netwok_nn.tensor(10.661838730397122 , grad = 1.0)\n",
      "Loss at Epoch 1629 is : netwok_nn.tensor(10.61358509732214 , grad = 1.0)\n",
      "Loss at Epoch 1630 is : netwok_nn.tensor(10.56544877986812 , grad = 1.0)\n",
      "Loss at Epoch 1631 is : netwok_nn.tensor(10.517429717560255 , grad = 1.0)\n",
      "Loss at Epoch 1632 is : netwok_nn.tensor(10.46952785003834 , grad = 1.0)\n",
      "Loss at Epoch 1633 is : netwok_nn.tensor(10.421743117057044 , grad = 1.0)\n",
      "Loss at Epoch 1634 is : netwok_nn.tensor(10.3740754584862 , grad = 1.0)\n",
      "Loss at Epoch 1635 is : netwok_nn.tensor(10.326524814311059 , grad = 1.0)\n",
      "Loss at Epoch 1636 is : netwok_nn.tensor(10.279091124632595 , grad = 1.0)\n",
      "Loss at Epoch 1637 is : netwok_nn.tensor(10.231774329667704 , grad = 1.0)\n",
      "Loss at Epoch 1638 is : netwok_nn.tensor(10.184574369749521 , grad = 1.0)\n",
      "Loss at Epoch 1639 is : netwok_nn.tensor(10.137491185327676 , grad = 1.0)\n",
      "Loss at Epoch 1640 is : netwok_nn.tensor(10.0905247169685 , grad = 1.0)\n",
      "Loss at Epoch 1641 is : netwok_nn.tensor(10.043674905355344 , grad = 1.0)\n",
      "Loss at Epoch 1642 is : netwok_nn.tensor(9.996941691288738 , grad = 1.0)\n",
      "Loss at Epoch 1643 is : netwok_nn.tensor(9.950325015686737 , grad = 1.0)\n",
      "Loss at Epoch 1644 is : netwok_nn.tensor(9.903824819585061 , grad = 1.0)\n",
      "Loss at Epoch 1645 is : netwok_nn.tensor(9.857441044137396 , grad = 1.0)\n",
      "Loss at Epoch 1646 is : netwok_nn.tensor(9.811173630615585 , grad = 1.0)\n",
      "Loss at Epoch 1647 is : netwok_nn.tensor(9.765022520409882 , grad = 1.0)\n",
      "Loss at Epoch 1648 is : netwok_nn.tensor(9.718987655029135 , grad = 1.0)\n",
      "Loss at Epoch 1649 is : netwok_nn.tensor(9.67306897610105 , grad = 1.0)\n",
      "Loss at Epoch 1650 is : netwok_nn.tensor(9.627266425372358 , grad = 1.0)\n",
      "Loss at Epoch 1651 is : netwok_nn.tensor(9.58157994470907 , grad = 1.0)\n",
      "Loss at Epoch 1652 is : netwok_nn.tensor(9.536009476096625 , grad = 1.0)\n",
      "Loss at Epoch 1653 is : netwok_nn.tensor(9.490554961640136 , grad = 1.0)\n",
      "Loss at Epoch 1654 is : netwok_nn.tensor(9.445216343564585 , grad = 1.0)\n",
      "Loss at Epoch 1655 is : netwok_nn.tensor(9.399993564214956 , grad = 1.0)\n",
      "Loss at Epoch 1656 is : netwok_nn.tensor(9.354886566056498 , grad = 1.0)\n",
      "Loss at Epoch 1657 is : netwok_nn.tensor(9.309895291674856 , grad = 1.0)\n",
      "Loss at Epoch 1658 is : netwok_nn.tensor(9.265019683776242 , grad = 1.0)\n",
      "Loss at Epoch 1659 is : netwok_nn.tensor(9.22025968518764 , grad = 1.0)\n",
      "Loss at Epoch 1660 is : netwok_nn.tensor(9.175615238856961 , grad = 1.0)\n",
      "Loss at Epoch 1661 is : netwok_nn.tensor(9.131086287853204 , grad = 1.0)\n",
      "Loss at Epoch 1662 is : netwok_nn.tensor(9.086672775366559 , grad = 1.0)\n",
      "Loss at Epoch 1663 is : netwok_nn.tensor(9.042374644708675 , grad = 1.0)\n",
      "Loss at Epoch 1664 is : netwok_nn.tensor(8.9981918393127 , grad = 1.0)\n",
      "Loss at Epoch 1665 is : netwok_nn.tensor(8.95412430273345 , grad = 1.0)\n",
      "Loss at Epoch 1666 is : netwok_nn.tensor(8.910171978647586 , grad = 1.0)\n",
      "Loss at Epoch 1667 is : netwok_nn.tensor(8.8663348108537 , grad = 1.0)\n",
      "Loss at Epoch 1668 is : netwok_nn.tensor(8.822612743272435 , grad = 1.0)\n",
      "Loss at Epoch 1669 is : netwok_nn.tensor(8.779005719946658 , grad = 1.0)\n",
      "Loss at Epoch 1670 is : netwok_nn.tensor(8.73551368504154 , grad = 1.0)\n",
      "Loss at Epoch 1671 is : netwok_nn.tensor(8.692136582844636 , grad = 1.0)\n",
      "Loss at Epoch 1672 is : netwok_nn.tensor(8.648874357766035 , grad = 1.0)\n",
      "Loss at Epoch 1673 is : netwok_nn.tensor(8.605726954338472 , grad = 1.0)\n",
      "Loss at Epoch 1674 is : netwok_nn.tensor(8.562694317217353 , grad = 1.0)\n",
      "Loss at Epoch 1675 is : netwok_nn.tensor(8.519776391180896 , grad = 1.0)\n",
      "Loss at Epoch 1676 is : netwok_nn.tensor(8.476973121130207 , grad = 1.0)\n",
      "Loss at Epoch 1677 is : netwok_nn.tensor(8.434284452089358 , grad = 1.0)\n",
      "Loss at Epoch 1678 is : netwok_nn.tensor(8.391710329205411 , grad = 1.0)\n",
      "Loss at Epoch 1679 is : netwok_nn.tensor(8.349250697748547 , grad = 1.0)\n",
      "Loss at Epoch 1680 is : netwok_nn.tensor(8.30690550311209 , grad = 1.0)\n",
      "Loss at Epoch 1681 is : netwok_nn.tensor(8.264674690812548 , grad = 1.0)\n",
      "Loss at Epoch 1682 is : netwok_nn.tensor(8.222558206489706 , grad = 1.0)\n",
      "Loss at Epoch 1683 is : netwok_nn.tensor(8.180555995906625 , grad = 1.0)\n",
      "Loss at Epoch 1684 is : netwok_nn.tensor(8.138668004949709 , grad = 1.0)\n",
      "Loss at Epoch 1685 is : netwok_nn.tensor(8.096894179628675 , grad = 1.0)\n",
      "Loss at Epoch 1686 is : netwok_nn.tensor(8.055234466076653 , grad = 1.0)\n",
      "Loss at Epoch 1687 is : netwok_nn.tensor(8.013688810550159 , grad = 1.0)\n",
      "Loss at Epoch 1688 is : netwok_nn.tensor(7.972257159429094 , grad = 1.0)\n",
      "Loss at Epoch 1689 is : netwok_nn.tensor(7.9309394592167815 , grad = 1.0)\n",
      "Loss at Epoch 1690 is : netwok_nn.tensor(7.88973565653995 , grad = 1.0)\n",
      "Loss at Epoch 1691 is : netwok_nn.tensor(7.848645698148724 , grad = 1.0)\n",
      "Loss at Epoch 1692 is : netwok_nn.tensor(7.80766953091661 , grad = 1.0)\n",
      "Loss at Epoch 1693 is : netwok_nn.tensor(7.766807101840457 , grad = 1.0)\n",
      "Loss at Epoch 1694 is : netwok_nn.tensor(7.726058358040478 , grad = 1.0)\n",
      "Loss at Epoch 1695 is : netwok_nn.tensor(7.685423246760163 , grad = 1.0)\n",
      "Loss at Epoch 1696 is : netwok_nn.tensor(7.644901715366268 , grad = 1.0)\n",
      "Loss at Epoch 1697 is : netwok_nn.tensor(7.604493711348761 , grad = 1.0)\n",
      "Loss at Epoch 1698 is : netwok_nn.tensor(7.564199182320762 , grad = 1.0)\n",
      "Loss at Epoch 1699 is : netwok_nn.tensor(7.524018076018499 , grad = 1.0)\n",
      "Loss at Epoch 1700 is : netwok_nn.tensor(7.483950340301229 , grad = 1.0)\n",
      "Loss at Epoch 1701 is : netwok_nn.tensor(7.443995923151151 , grad = 1.0)\n",
      "Loss at Epoch 1702 is : netwok_nn.tensor(7.404154772673345 , grad = 1.0)\n",
      "Loss at Epoch 1703 is : netwok_nn.tensor(7.364426837095704 , grad = 1.0)\n",
      "Loss at Epoch 1704 is : netwok_nn.tensor(7.324812064768797 , grad = 1.0)\n",
      "Loss at Epoch 1705 is : netwok_nn.tensor(7.285310404165779 , grad = 1.0)\n",
      "Loss at Epoch 1706 is : netwok_nn.tensor(7.245921803882307 , grad = 1.0)\n",
      "Loss at Epoch 1707 is : netwok_nn.tensor(7.206646212636429 , grad = 1.0)\n",
      "Loss at Epoch 1708 is : netwok_nn.tensor(7.167483579268401 , grad = 1.0)\n",
      "Loss at Epoch 1709 is : netwok_nn.tensor(7.12843385274063 , grad = 1.0)\n",
      "Loss at Epoch 1710 is : netwok_nn.tensor(7.089496982137515 , grad = 1.0)\n",
      "Loss at Epoch 1711 is : netwok_nn.tensor(7.0506729166653 , grad = 1.0)\n",
      "Loss at Epoch 1712 is : netwok_nn.tensor(7.0119616056519165 , grad = 1.0)\n",
      "Loss at Epoch 1713 is : netwok_nn.tensor(6.973362998546835 , grad = 1.0)\n",
      "Loss at Epoch 1714 is : netwok_nn.tensor(6.934877044920928 , grad = 1.0)\n",
      "Loss at Epoch 1715 is : netwok_nn.tensor(6.896503694466255 , grad = 1.0)\n",
      "Loss at Epoch 1716 is : netwok_nn.tensor(6.858242896995899 , grad = 1.0)\n",
      "Loss at Epoch 1717 is : netwok_nn.tensor(6.820094602443806 , grad = 1.0)\n",
      "Loss at Epoch 1718 is : netwok_nn.tensor(6.782058760864588 , grad = 1.0)\n",
      "Loss at Epoch 1719 is : netwok_nn.tensor(6.744135322433286 , grad = 1.0)\n",
      "Loss at Epoch 1720 is : netwok_nn.tensor(6.706324237445195 , grad = 1.0)\n",
      "Loss at Epoch 1721 is : netwok_nn.tensor(6.668625456315658 , grad = 1.0)\n",
      "Loss at Epoch 1722 is : netwok_nn.tensor(6.631038929579817 , grad = 1.0)\n",
      "Loss at Epoch 1723 is : netwok_nn.tensor(6.593564607892427 , grad = 1.0)\n",
      "Loss at Epoch 1724 is : netwok_nn.tensor(6.556202442027578 , grad = 1.0)\n",
      "Loss at Epoch 1725 is : netwok_nn.tensor(6.518952382878463 , grad = 1.0)\n",
      "Loss at Epoch 1726 is : netwok_nn.tensor(6.48181438145715 , grad = 1.0)\n",
      "Loss at Epoch 1727 is : netwok_nn.tensor(6.444788388894321 , grad = 1.0)\n",
      "Loss at Epoch 1728 is : netwok_nn.tensor(6.407874356438976 , grad = 1.0)\n",
      "Loss at Epoch 1729 is : netwok_nn.tensor(6.371072235458205 , grad = 1.0)\n",
      "Loss at Epoch 1730 is : netwok_nn.tensor(6.3343819774368635 , grad = 1.0)\n",
      "Loss at Epoch 1731 is : netwok_nn.tensor(6.297803533977332 , grad = 1.0)\n",
      "Loss at Epoch 1732 is : netwok_nn.tensor(6.261336856799193 , grad = 1.0)\n",
      "Loss at Epoch 1733 is : netwok_nn.tensor(6.224981897738945 , grad = 1.0)\n",
      "Loss at Epoch 1734 is : netwok_nn.tensor(6.188738608749676 , grad = 1.0)\n",
      "Loss at Epoch 1735 is : netwok_nn.tensor(6.152606941900757 , grad = 1.0)\n",
      "Loss at Epoch 1736 is : netwok_nn.tensor(6.116586849377541 , grad = 1.0)\n",
      "Loss at Epoch 1737 is : netwok_nn.tensor(6.080678283481006 , grad = 1.0)\n",
      "Loss at Epoch 1738 is : netwok_nn.tensor(6.044881196627411 , grad = 1.0)\n",
      "Loss at Epoch 1739 is : netwok_nn.tensor(6.009195541347975 , grad = 1.0)\n",
      "Loss at Epoch 1740 is : netwok_nn.tensor(5.973621270288515 , grad = 1.0)\n",
      "Loss at Epoch 1741 is : netwok_nn.tensor(5.938158336209084 , grad = 1.0)\n",
      "Loss at Epoch 1742 is : netwok_nn.tensor(5.902806691983593 , grad = 1.0)\n",
      "Loss at Epoch 1743 is : netwok_nn.tensor(5.867566290599469 , grad = 1.0)\n",
      "Loss at Epoch 1744 is : netwok_nn.tensor(5.832437085157233 , grad = 1.0)\n",
      "Loss at Epoch 1745 is : netwok_nn.tensor(5.797419028870153 , grad = 1.0)\n",
      "Loss at Epoch 1746 is : netwok_nn.tensor(5.762512075063789 , grad = 1.0)\n",
      "Loss at Epoch 1747 is : netwok_nn.tensor(5.72771617717565 , grad = 1.0)\n",
      "Loss at Epoch 1748 is : netwok_nn.tensor(5.693031288754746 , grad = 1.0)\n",
      "Loss at Epoch 1749 is : netwok_nn.tensor(5.65845736346118 , grad = 1.0)\n",
      "Loss at Epoch 1750 is : netwok_nn.tensor(5.623994355065722 , grad = 1.0)\n",
      "Loss at Epoch 1751 is : netwok_nn.tensor(5.589642217449363 , grad = 1.0)\n",
      "Loss at Epoch 1752 is : netwok_nn.tensor(5.555400904602906 , grad = 1.0)\n",
      "Loss at Epoch 1753 is : netwok_nn.tensor(5.521270370626484 , grad = 1.0)\n",
      "Loss at Epoch 1754 is : netwok_nn.tensor(5.487250569729125 , grad = 1.0)\n",
      "Loss at Epoch 1755 is : netwok_nn.tensor(5.453341456228269 , grad = 1.0)\n",
      "Loss at Epoch 1756 is : netwok_nn.tensor(5.419542984549334 , grad = 1.0)\n",
      "Loss at Epoch 1757 is : netwok_nn.tensor(5.385855109225186 , grad = 1.0)\n",
      "Loss at Epoch 1758 is : netwok_nn.tensor(5.35227778489572 , grad = 1.0)\n",
      "Loss at Epoch 1759 is : netwok_nn.tensor(5.318810966307299 , grad = 1.0)\n",
      "Loss at Epoch 1760 is : netwok_nn.tensor(5.28545460831231 , grad = 1.0)\n",
      "Loss at Epoch 1761 is : netwok_nn.tensor(5.252208665868627 , grad = 1.0)\n",
      "Loss at Epoch 1762 is : netwok_nn.tensor(5.219073094039119 , grad = 1.0)\n",
      "Loss at Epoch 1763 is : netwok_nn.tensor(5.1860478479911105 , grad = 1.0)\n",
      "Loss at Epoch 1764 is : netwok_nn.tensor(5.153132882995868 , grad = 1.0)\n",
      "Loss at Epoch 1765 is : netwok_nn.tensor(5.120328154428064 , grad = 1.0)\n",
      "Loss at Epoch 1766 is : netwok_nn.tensor(5.087633617765218 , grad = 1.0)\n",
      "Loss at Epoch 1767 is : netwok_nn.tensor(5.0550492285871735 , grad = 1.0)\n",
      "Loss at Epoch 1768 is : netwok_nn.tensor(5.022574942575548 , grad = 1.0)\n",
      "Loss at Epoch 1769 is : netwok_nn.tensor(4.990210715513124 , grad = 1.0)\n",
      "Loss at Epoch 1770 is : netwok_nn.tensor(4.957956503283329 , grad = 1.0)\n",
      "Loss at Epoch 1771 is : netwok_nn.tensor(4.92581226186964 , grad = 1.0)\n",
      "Loss at Epoch 1772 is : netwok_nn.tensor(4.8937779473549945 , grad = 1.0)\n",
      "Loss at Epoch 1773 is : netwok_nn.tensor(4.861853515921222 , grad = 1.0)\n",
      "Loss at Epoch 1774 is : netwok_nn.tensor(4.830038923848424 , grad = 1.0)\n",
      "Loss at Epoch 1775 is : netwok_nn.tensor(4.798334127514389 , grad = 1.0)\n",
      "Loss at Epoch 1776 is : netwok_nn.tensor(4.76673908339398 , grad = 1.0)\n",
      "Loss at Epoch 1777 is : netwok_nn.tensor(4.735253748058492 , grad = 1.0)\n",
      "Loss at Epoch 1778 is : netwok_nn.tensor(4.703878078175068 , grad = 1.0)\n",
      "Loss at Epoch 1779 is : netwok_nn.tensor(4.6726120305060395 , grad = 1.0)\n",
      "Loss at Epoch 1780 is : netwok_nn.tensor(4.64145556190832 , grad = 1.0)\n",
      "Loss at Epoch 1781 is : netwok_nn.tensor(4.61040862933274 , grad = 1.0)\n",
      "Loss at Epoch 1782 is : netwok_nn.tensor(4.579471189823391 , grad = 1.0)\n",
      "Loss at Epoch 1783 is : netwok_nn.tensor(4.548643200516989 , grad = 1.0)\n",
      "Loss at Epoch 1784 is : netwok_nn.tensor(4.5179246186422235 , grad = 1.0)\n",
      "Loss at Epoch 1785 is : netwok_nn.tensor(4.487315401519043 , grad = 1.0)\n",
      "Loss at Epoch 1786 is : netwok_nn.tensor(4.456815506558029 , grad = 1.0)\n",
      "Loss at Epoch 1787 is : netwok_nn.tensor(4.426424891259699 , grad = 1.0)\n",
      "Loss at Epoch 1788 is : netwok_nn.tensor(4.396143513213817 , grad = 1.0)\n",
      "Loss at Epoch 1789 is : netwok_nn.tensor(4.365971330098689 , grad = 1.0)\n",
      "Loss at Epoch 1790 is : netwok_nn.tensor(4.33590829968049 , grad = 1.0)\n",
      "Loss at Epoch 1791 is : netwok_nn.tensor(4.305954379812537 , grad = 1.0)\n",
      "Loss at Epoch 1792 is : netwok_nn.tensor(4.276109528434606 , grad = 1.0)\n",
      "Loss at Epoch 1793 is : netwok_nn.tensor(4.2463737035721865 , grad = 1.0)\n",
      "Loss at Epoch 1794 is : netwok_nn.tensor(4.216746863335762 , grad = 1.0)\n",
      "Loss at Epoch 1795 is : netwok_nn.tensor(4.187228965920107 , grad = 1.0)\n",
      "Loss at Epoch 1796 is : netwok_nn.tensor(4.157819969603522 , grad = 1.0)\n",
      "Loss at Epoch 1797 is : netwok_nn.tensor(4.128519832747132 , grad = 1.0)\n",
      "Loss at Epoch 1798 is : netwok_nn.tensor(4.099328513794107 , grad = 1.0)\n",
      "Loss at Epoch 1799 is : netwok_nn.tensor(4.070245971268914 , grad = 1.0)\n",
      "Loss at Epoch 1800 is : netwok_nn.tensor(4.041272163776584 , grad = 1.0)\n",
      "Loss at Epoch 1801 is : netwok_nn.tensor(4.012407050001942 , grad = 1.0)\n",
      "Loss at Epoch 1802 is : netwok_nn.tensor(3.9836505887088247 , grad = 1.0)\n",
      "Loss at Epoch 1803 is : netwok_nn.tensor(3.955002738739336 , grad = 1.0)\n",
      "Loss at Epoch 1804 is : netwok_nn.tensor(3.92646345901304 , grad = 1.0)\n",
      "Loss at Epoch 1805 is : netwok_nn.tensor(3.898032708526214 , grad = 1.0)\n",
      "Loss at Epoch 1806 is : netwok_nn.tensor(3.8697104463510215 , grad = 1.0)\n",
      "Loss at Epoch 1807 is : netwok_nn.tensor(3.841496631634753 , grad = 1.0)\n",
      "Loss at Epoch 1808 is : netwok_nn.tensor(3.813391223599012 , grad = 1.0)\n",
      "Loss at Epoch 1809 is : netwok_nn.tensor(3.7853941815389267 , grad = 1.0)\n",
      "Loss at Epoch 1810 is : netwok_nn.tensor(3.7575054648223283 , grad = 1.0)\n",
      "Loss at Epoch 1811 is : netwok_nn.tensor(3.729725032888949 , grad = 1.0)\n",
      "Loss at Epoch 1812 is : netwok_nn.tensor(3.7020528452496047 , grad = 1.0)\n",
      "Loss at Epoch 1813 is : netwok_nn.tensor(3.67448886148538 , grad = 1.0)\n",
      "Loss at Epoch 1814 is : netwok_nn.tensor(3.6470330412467886 , grad = 1.0)\n",
      "Loss at Epoch 1815 is : netwok_nn.tensor(3.6196853442529626 , grad = 1.0)\n",
      "Loss at Epoch 1816 is : netwok_nn.tensor(3.5924457302908053 , grad = 1.0)\n",
      "Loss at Epoch 1817 is : netwok_nn.tensor(3.565314159214164 , grad = 1.0)\n",
      "Loss at Epoch 1818 is : netwok_nn.tensor(3.5382905909429816 , grad = 1.0)\n",
      "Loss at Epoch 1819 is : netwok_nn.tensor(3.5113749854624423 , grad = 1.0)\n",
      "Loss at Epoch 1820 is : netwok_nn.tensor(3.484567302822146 , grad = 1.0)\n",
      "Loss at Epoch 1821 is : netwok_nn.tensor(3.4578675031352386 , grad = 1.0)\n",
      "Loss at Epoch 1822 is : netwok_nn.tensor(3.4312755465775435 , grad = 1.0)\n",
      "Loss at Epoch 1823 is : netwok_nn.tensor(3.4047913933867364 , grad = 1.0)\n",
      "Loss at Epoch 1824 is : netwok_nn.tensor(3.3784150038614253 , grad = 1.0)\n",
      "Loss at Epoch 1825 is : netwok_nn.tensor(3.3521463383603445 , grad = 1.0)\n",
      "Loss at Epoch 1826 is : netwok_nn.tensor(3.3259853573014335 , grad = 1.0)\n",
      "Loss at Epoch 1827 is : netwok_nn.tensor(3.299932021160992 , grad = 1.0)\n",
      "Loss at Epoch 1828 is : netwok_nn.tensor(3.273986290472781 , grad = 1.0)\n",
      "Loss at Epoch 1829 is : netwok_nn.tensor(3.2481481258271447 , grad = 1.0)\n",
      "Loss at Epoch 1830 is : netwok_nn.tensor(3.222417487870141 , grad = 1.0)\n",
      "Loss at Epoch 1831 is : netwok_nn.tensor(3.1967943373026326 , grad = 1.0)\n",
      "Loss at Epoch 1832 is : netwok_nn.tensor(3.1712786348794175 , grad = 1.0)\n",
      "Loss at Epoch 1833 is : netwok_nn.tensor(3.1458703414083065 , grad = 1.0)\n",
      "Loss at Epoch 1834 is : netwok_nn.tensor(3.1205694177492496 , grad = 1.0)\n",
      "Loss at Epoch 1835 is : netwok_nn.tensor(3.09537582481343 , grad = 1.0)\n",
      "Loss at Epoch 1836 is : netwok_nn.tensor(3.070289523562356 , grad = 1.0)\n",
      "Loss at Epoch 1837 is : netwok_nn.tensor(3.045310475006955 , grad = 1.0)\n",
      "Loss at Epoch 1838 is : netwok_nn.tensor(3.020438640206685 , grad = 1.0)\n",
      "Loss at Epoch 1839 is : netwok_nn.tensor(2.995673980268616 , grad = 1.0)\n",
      "Loss at Epoch 1840 is : netwok_nn.tensor(2.9710164563464865 , grad = 1.0)\n",
      "Loss at Epoch 1841 is : netwok_nn.tensor(2.946466029639842 , grad = 1.0)\n",
      "Loss at Epoch 1842 is : netwok_nn.tensor(2.922022661393082 , grad = 1.0)\n",
      "Loss at Epoch 1843 is : netwok_nn.tensor(2.897686312894556 , grad = 1.0)\n",
      "Loss at Epoch 1844 is : netwok_nn.tensor(2.873456945475636 , grad = 1.0)\n",
      "Loss at Epoch 1845 is : netwok_nn.tensor(2.849334520509801 , grad = 1.0)\n",
      "Loss at Epoch 1846 is : netwok_nn.tensor(2.825318999411699 , grad = 1.0)\n",
      "Loss at Epoch 1847 is : netwok_nn.tensor(2.8014103436362525 , grad = 1.0)\n",
      "Loss at Epoch 1848 is : netwok_nn.tensor(2.7776085146776954 , grad = 1.0)\n",
      "Loss at Epoch 1849 is : netwok_nn.tensor(2.753913474068661 , grad = 1.0)\n",
      "Loss at Epoch 1850 is : netwok_nn.tensor(2.730325183379274 , grad = 1.0)\n",
      "Loss at Epoch 1851 is : netwok_nn.tensor(2.706843604216161 , grad = 1.0)\n",
      "Loss at Epoch 1852 is : netwok_nn.tensor(2.683468698221585 , grad = 1.0)\n",
      "Loss at Epoch 1853 is : netwok_nn.tensor(2.6602004270724633 , grad = 1.0)\n",
      "Loss at Epoch 1854 is : netwok_nn.tensor(2.6370387524794565 , grad = 1.0)\n",
      "Loss at Epoch 1855 is : netwok_nn.tensor(2.6139836361860302 , grad = 1.0)\n",
      "Loss at Epoch 1856 is : netwok_nn.tensor(2.5910350399675086 , grad = 1.0)\n",
      "Loss at Epoch 1857 is : netwok_nn.tensor(2.568192925630153 , grad = 1.0)\n",
      "Loss at Epoch 1858 is : netwok_nn.tensor(2.545457255010201 , grad = 1.0)\n",
      "Loss at Epoch 1859 is : netwok_nn.tensor(2.5228279899729618 , grad = 1.0)\n",
      "Loss at Epoch 1860 is : netwok_nn.tensor(2.500305092411851 , grad = 1.0)\n",
      "Loss at Epoch 1861 is : netwok_nn.tensor(2.477888524247456 , grad = 1.0)\n",
      "Loss at Epoch 1862 is : netwok_nn.tensor(2.4555782474265975 , grad = 1.0)\n",
      "Loss at Epoch 1863 is : netwok_nn.tensor(2.4333742239214073 , grad = 1.0)\n",
      "Loss at Epoch 1864 is : netwok_nn.tensor(2.4112764157283615 , grad = 1.0)\n",
      "Loss at Epoch 1865 is : netwok_nn.tensor(2.3892847848673586 , grad = 1.0)\n",
      "Loss at Epoch 1866 is : netwok_nn.tensor(2.3673992933807737 , grad = 1.0)\n",
      "Loss at Epoch 1867 is : netwok_nn.tensor(2.345619903332521 , grad = 1.0)\n",
      "Loss at Epoch 1868 is : netwok_nn.tensor(2.3239465768071104 , grad = 1.0)\n",
      "Loss at Epoch 1869 is : netwok_nn.tensor(2.3023792759087285 , grad = 1.0)\n",
      "Loss at Epoch 1870 is : netwok_nn.tensor(2.2809179627602676 , grad = 1.0)\n",
      "Loss at Epoch 1871 is : netwok_nn.tensor(2.259562599502417 , grad = 1.0)\n",
      "Loss at Epoch 1872 is : netwok_nn.tensor(2.2383131482927077 , grad = 1.0)\n",
      "Loss at Epoch 1873 is : netwok_nn.tensor(2.2171695713045905 , grad = 1.0)\n",
      "Loss at Epoch 1874 is : netwok_nn.tensor(2.1961318307264848 , grad = 1.0)\n",
      "Loss at Epoch 1875 is : netwok_nn.tensor(2.1751998887608566 , grad = 1.0)\n",
      "Loss at Epoch 1876 is : netwok_nn.tensor(2.154373707623292 , grad = 1.0)\n",
      "Loss at Epoch 1877 is : netwok_nn.tensor(2.1336532495415383 , grad = 1.0)\n",
      "Loss at Epoch 1878 is : netwok_nn.tensor(2.1130384767545913 , grad = 1.0)\n",
      "Loss at Epoch 1879 is : netwok_nn.tensor(2.092529351511775 , grad = 1.0)\n",
      "Loss at Epoch 1880 is : netwok_nn.tensor(2.072125836071787 , grad = 1.0)\n",
      "Loss at Epoch 1881 is : netwok_nn.tensor(2.0518278927018003 , grad = 1.0)\n",
      "Loss at Epoch 1882 is : netwok_nn.tensor(2.0316354836765087 , grad = 1.0)\n",
      "Loss at Epoch 1883 is : netwok_nn.tensor(2.0115485712772236 , grad = 1.0)\n",
      "Loss at Epoch 1884 is : netwok_nn.tensor(1.991567117790945 , grad = 1.0)\n",
      "Loss at Epoch 1885 is : netwok_nn.tensor(1.9716910855094445 , grad = 1.0)\n",
      "Loss at Epoch 1886 is : netwok_nn.tensor(1.9519204367283416 , grad = 1.0)\n",
      "Loss at Epoch 1887 is : netwok_nn.tensor(1.932255133746184 , grad = 1.0)\n",
      "Loss at Epoch 1888 is : netwok_nn.tensor(1.9126951388635418 , grad = 1.0)\n",
      "Loss at Epoch 1889 is : netwok_nn.tensor(1.8932404143821007 , grad = 1.0)\n",
      "Loss at Epoch 1890 is : netwok_nn.tensor(1.8738909226037272 , grad = 1.0)\n",
      "Loss at Epoch 1891 is : netwok_nn.tensor(1.854646625829598 , grad = 1.0)\n",
      "Loss at Epoch 1892 is : netwok_nn.tensor(1.835507486359253 , grad = 1.0)\n",
      "Loss at Epoch 1893 is : netwok_nn.tensor(1.8164734664897195 , grad = 1.0)\n",
      "Loss at Epoch 1894 is : netwok_nn.tensor(1.7975445285145977 , grad = 1.0)\n",
      "Loss at Epoch 1895 is : netwok_nn.tensor(1.7787206347231825 , grad = 1.0)\n",
      "Loss at Epoch 1896 is : netwok_nn.tensor(1.7600017473995546 , grad = 1.0)\n",
      "Loss at Epoch 1897 is : netwok_nn.tensor(1.7413878288216775 , grad = 1.0)\n",
      "Loss at Epoch 1898 is : netwok_nn.tensor(1.7228788412605298 , grad = 1.0)\n",
      "Loss at Epoch 1899 is : netwok_nn.tensor(1.7044747469792048 , grad = 1.0)\n",
      "Loss at Epoch 1900 is : netwok_nn.tensor(1.686175508232032 , grad = 1.0)\n",
      "Loss at Epoch 1901 is : netwok_nn.tensor(1.6679810872636889 , grad = 1.0)\n",
      "Loss at Epoch 1902 is : netwok_nn.tensor(1.6498914463083434 , grad = 1.0)\n",
      "Loss at Epoch 1903 is : netwok_nn.tensor(1.6319065475887533 , grad = 1.0)\n",
      "Loss at Epoch 1904 is : netwok_nn.tensor(1.6140263533154209 , grad = 1.0)\n",
      "Loss at Epoch 1905 is : netwok_nn.tensor(1.5962508256857024 , grad = 1.0)\n",
      "Loss at Epoch 1906 is : netwok_nn.tensor(1.5785799268829583 , grad = 1.0)\n",
      "Loss at Epoch 1907 is : netwok_nn.tensor(1.5610136190756965 , grad = 1.0)\n",
      "Loss at Epoch 1908 is : netwok_nn.tensor(1.5435518644167021 , grad = 1.0)\n",
      "Loss at Epoch 1909 is : netwok_nn.tensor(1.526194625042197 , grad = 1.0)\n",
      "Loss at Epoch 1910 is : netwok_nn.tensor(1.508941863070977 , grad = 1.0)\n",
      "Loss at Epoch 1911 is : netwok_nn.tensor(1.4917935406035803 , grad = 1.0)\n",
      "Loss at Epoch 1912 is : netwok_nn.tensor(1.4747496197214442 , grad = 1.0)\n",
      "Loss at Epoch 1913 is : netwok_nn.tensor(1.457810062486057 , grad = 1.0)\n",
      "Loss at Epoch 1914 is : netwok_nn.tensor(1.4409748309381294 , grad = 1.0)\n",
      "Loss at Epoch 1915 is : netwok_nn.tensor(1.4242438870967704 , grad = 1.0)\n",
      "Loss at Epoch 1916 is : netwok_nn.tensor(1.4076171929586547 , grad = 1.0)\n",
      "Loss at Epoch 1917 is : netwok_nn.tensor(1.3910947104972105 , grad = 1.0)\n",
      "Loss at Epoch 1918 is : netwok_nn.tensor(1.37467640166179 , grad = 1.0)\n",
      "Loss at Epoch 1919 is : netwok_nn.tensor(1.358362228376873 , grad = 1.0)\n",
      "Loss at Epoch 1920 is : netwok_nn.tensor(1.3421521525412339 , grad = 1.0)\n",
      "Loss at Epoch 1921 is : netwok_nn.tensor(1.3260461360271614 , grad = 1.0)\n",
      "Loss at Epoch 1922 is : netwok_nn.tensor(1.3100441406796575 , grad = 1.0)\n",
      "Loss at Epoch 1923 is : netwok_nn.tensor(1.2941461283156297 , grad = 1.0)\n",
      "Loss at Epoch 1924 is : netwok_nn.tensor(1.2783520607231145 , grad = 1.0)\n",
      "Loss at Epoch 1925 is : netwok_nn.tensor(1.2626618996604781 , grad = 1.0)\n",
      "Loss at Epoch 1926 is : netwok_nn.tensor(1.2470756068556483 , grad = 1.0)\n",
      "Loss at Epoch 1927 is : netwok_nn.tensor(1.2315931440053312 , grad = 1.0)\n",
      "Loss at Epoch 1928 is : netwok_nn.tensor(1.216214472774248 , grad = 1.0)\n",
      "Loss at Epoch 1929 is : netwok_nn.tensor(1.2009395547943584 , grad = 1.0)\n",
      "Loss at Epoch 1930 is : netwok_nn.tensor(1.1857683516641118 , grad = 1.0)\n",
      "Loss at Epoch 1931 is : netwok_nn.tensor(1.1707008249476796 , grad = 1.0)\n",
      "Loss at Epoch 1932 is : netwok_nn.tensor(1.155736936174212 , grad = 1.0)\n",
      "Loss at Epoch 1933 is : netwok_nn.tensor(1.1408766468370888 , grad = 1.0)\n",
      "Loss at Epoch 1934 is : netwok_nn.tensor(1.1261199183931805 , grad = 1.0)\n",
      "Loss at Epoch 1935 is : netwok_nn.tensor(1.111466712262117 , grad = 1.0)\n",
      "Loss at Epoch 1936 is : netwok_nn.tensor(1.0969169898255444 , grad = 1.0)\n",
      "Loss at Epoch 1937 is : netwok_nn.tensor(1.0824707124264084 , grad = 1.0)\n",
      "Loss at Epoch 1938 is : netwok_nn.tensor(1.0681278413682433 , grad = 1.0)\n",
      "Loss at Epoch 1939 is : netwok_nn.tensor(1.053888337914442 , grad = 1.0)\n",
      "Loss at Epoch 1940 is : netwok_nn.tensor(1.0397521632875566 , grad = 1.0)\n",
      "Loss at Epoch 1941 is : netwok_nn.tensor(1.0257192786685956 , grad = 1.0)\n",
      "Loss at Epoch 1942 is : netwok_nn.tensor(1.0117896451963169 , grad = 1.0)\n",
      "Loss at Epoch 1943 is : netwok_nn.tensor(0.9979632239665476 , grad = 1.0)\n",
      "Loss at Epoch 1944 is : netwok_nn.tensor(0.9842399760314929 , grad = 1.0)\n",
      "Loss at Epoch 1945 is : netwok_nn.tensor(0.9706198623990488 , grad = 1.0)\n",
      "Loss at Epoch 1946 is : netwok_nn.tensor(0.9571028440321337 , grad = 1.0)\n",
      "Loss at Epoch 1947 is : netwok_nn.tensor(0.943688881848024 , grad = 1.0)\n",
      "Loss at Epoch 1948 is : netwok_nn.tensor(0.9303779367176742 , grad = 1.0)\n",
      "Loss at Epoch 1949 is : netwok_nn.tensor(0.9171699694650708 , grad = 1.0)\n",
      "Loss at Epoch 1950 is : netwok_nn.tensor(0.9040649408665754 , grad = 1.0)\n",
      "Loss at Epoch 1951 is : netwok_nn.tensor(0.8910628116502839 , grad = 1.0)\n",
      "Loss at Epoch 1952 is : netwok_nn.tensor(0.8781635424953808 , grad = 1.0)\n",
      "Loss at Epoch 1953 is : netwok_nn.tensor(0.8653670940315037 , grad = 1.0)\n",
      "Loss at Epoch 1954 is : netwok_nn.tensor(0.8526734268381145 , grad = 1.0)\n",
      "Loss at Epoch 1955 is : netwok_nn.tensor(0.8400825014438789 , grad = 1.0)\n",
      "Loss at Epoch 1956 is : netwok_nn.tensor(0.8275942783260501 , grad = 1.0)\n",
      "Loss at Epoch 1957 is : netwok_nn.tensor(0.8152087179098513 , grad = 1.0)\n",
      "Loss at Epoch 1958 is : netwok_nn.tensor(0.8029257805678821 , grad = 1.0)\n",
      "Loss at Epoch 1959 is : netwok_nn.tensor(0.7907454266195069 , grad = 1.0)\n",
      "Loss at Epoch 1960 is : netwok_nn.tensor(0.778667616330274 , grad = 1.0)\n",
      "Loss at Epoch 1961 is : netwok_nn.tensor(0.7666923099113181 , grad = 1.0)\n",
      "Loss at Epoch 1962 is : netwok_nn.tensor(0.7548194675187838 , grad = 1.0)\n",
      "Loss at Epoch 1963 is : netwok_nn.tensor(0.7430490492532533 , grad = 1.0)\n",
      "Loss at Epoch 1964 is : netwok_nn.tensor(0.7313810151591769 , grad = 1.0)\n",
      "Loss at Epoch 1965 is : netwok_nn.tensor(0.7198153252243104 , grad = 1.0)\n",
      "Loss at Epoch 1966 is : netwok_nn.tensor(0.7083519393791563 , grad = 1.0)\n",
      "Loss at Epoch 1967 is : netwok_nn.tensor(0.6969908174964147 , grad = 1.0)\n",
      "Loss at Epoch 1968 is : netwok_nn.tensor(0.6857319193904479 , grad = 1.0)\n",
      "Loss at Epoch 1969 is : netwok_nn.tensor(0.6745752048167281 , grad = 1.0)\n",
      "Loss at Epoch 1970 is : netwok_nn.tensor(0.6635206334713218 , grad = 1.0)\n",
      "Loss at Epoch 1971 is : netwok_nn.tensor(0.6525681649903511 , grad = 1.0)\n",
      "Loss at Epoch 1972 is : netwok_nn.tensor(0.6417177589494786 , grad = 1.0)\n",
      "Loss at Epoch 1973 is : netwok_nn.tensor(0.6309693748634074 , grad = 1.0)\n",
      "Loss at Epoch 1974 is : netwok_nn.tensor(0.620322972185357 , grad = 1.0)\n",
      "Loss at Epoch 1975 is : netwok_nn.tensor(0.609778510306573 , grad = 1.0)\n",
      "Loss at Epoch 1976 is : netwok_nn.tensor(0.5993359485558278 , grad = 1.0)\n",
      "Loss at Epoch 1977 is : netwok_nn.tensor(0.5889952461989434 , grad = 1.0)\n",
      "Loss at Epoch 1978 is : netwok_nn.tensor(0.5787563624383023 , grad = 1.0)\n",
      "Loss at Epoch 1979 is : netwok_nn.tensor(0.5686192564123695 , grad = 1.0)\n",
      "Loss at Epoch 1980 is : netwok_nn.tensor(0.5585838871952344 , grad = 1.0)\n",
      "Loss at Epoch 1981 is : netwok_nn.tensor(0.5486502137961375 , grad = 1.0)\n",
      "Loss at Epoch 1982 is : netwok_nn.tensor(0.5388181951590273 , grad = 1.0)\n",
      "Loss at Epoch 1983 is : netwok_nn.tensor(0.5290877901620964 , grad = 1.0)\n",
      "Loss at Epoch 1984 is : netwok_nn.tensor(0.5194589576173488 , grad = 1.0)\n",
      "Loss at Epoch 1985 is : netwok_nn.tensor(0.5099316562701626 , grad = 1.0)\n",
      "Loss at Epoch 1986 is : netwok_nn.tensor(0.500505844798849 , grad = 1.0)\n",
      "Loss at Epoch 1987 is : netwok_nn.tensor(0.49118148181424304 , grad = 1.0)\n",
      "Loss at Epoch 1988 is : netwok_nn.tensor(0.4819585258592731 , grad = 1.0)\n",
      "Loss at Epoch 1989 is : netwok_nn.tensor(0.4728369354085586 , grad = 1.0)\n",
      "Loss at Epoch 1990 is : netwok_nn.tensor(0.4638166688679962 , grad = 1.0)\n",
      "Loss at Epoch 1991 is : netwok_nn.tensor(0.4548976845743627 , grad = 1.0)\n",
      "Loss at Epoch 1992 is : netwok_nn.tensor(0.4460799407949305 , grad = 1.0)\n",
      "Loss at Epoch 1993 is : netwok_nn.tensor(0.4373633957270737 , grad = 1.0)\n",
      "Loss at Epoch 1994 is : netwok_nn.tensor(0.4287480074978865 , grad = 1.0)\n",
      "Loss at Epoch 1995 is : netwok_nn.tensor(0.4202337341638102 , grad = 1.0)\n",
      "Loss at Epoch 1996 is : netwok_nn.tensor(0.4118205337102666 , grad = 1.0)\n",
      "Loss at Epoch 1997 is : netwok_nn.tensor(0.40350836405130264 , grad = 1.0)\n",
      "Loss at Epoch 1998 is : netwok_nn.tensor(0.3952971830292233 , grad = 1.0)\n",
      "Loss at Epoch 1999 is : netwok_nn.tensor(0.3871869484142523 , grad = 1.0)\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(in_features=1)\n",
    "optimiser = AdamOptimizer(lr=0.001)\n",
    "for epoch in range(2000):\n",
    "    out = model(x)\n",
    "    loss = mse(predictions=out, targets=y)\n",
    "    loss.backprop()\n",
    "    print(f\"Loss at Epoch {epoch} is : {loss}\")\n",
    "    optimiser.step(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
