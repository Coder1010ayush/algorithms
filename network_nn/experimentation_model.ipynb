{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------- utf-8 encoding -----------------------------------------\n",
    "# this file contains kinds of layers test cases that are implemented here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensor import Tensor\n",
    "from initializer_w import Initializer\n",
    "from layers.models import Linear\n",
    "from optimizer.optim import GradientOptimiser, AdamOptimizer\n",
    "from layers.module import Module\n",
    "from autograd.autodiff import mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int = 5,\n",
    "        out_features: int = 1,\n",
    "        init_type=\"uniform\",\n",
    "        meta: dict = {\"low\": 0.0, \"high\": 1.0},\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_feature = in_features\n",
    "        self.out_feature = out_features\n",
    "        self.init_type = init_type\n",
    "        self.meta =  meta\n",
    "        self.linear = Linear(in_feature= self.in_feature , out_feature=self.out_feature , init_type=self.init_type  , meta=self.meta)\n",
    "        self.add_module(\"linear\", self.linear)\n",
    "    def forward(self, x: Tensor):\n",
    "\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.LinearModel object at 0x7c94641e6a40>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining input data for this\n",
    "init_w  = Initializer()\n",
    "# x = init_w.forward(shape=(50 , 5) , init_type=\"random\"  , retain_grad=True , meta=None)\n",
    "# y = init_w.forward(shape=(50, 1), init_type=\"random\", retain_grad=True, meta=None)\n",
    "\n",
    "\n",
    "x = np.linspace(-10, 10, 50).reshape(-1, 1)\n",
    "# noise = np.random.normal(0, 2, size=x.shape)\n",
    "y = (3 * x + 2).reshape(-1, 1)\n",
    "x = Tensor(data=x, retain_grad=True)\n",
    "y = Tensor(data=y ,retain_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at Epoch 0 is : netwok_nn.tensor(191.42739215874528 , grad = 1.0)\n",
      "Loss at Epoch 1 is : netwok_nn.tensor(191.2628650693754 , grad = 1.0)\n",
      "Loss at Epoch 2 is : netwok_nn.tensor(191.10413037884493 , grad = 1.0)\n",
      "Loss at Epoch 3 is : netwok_nn.tensor(190.9466400780475 , grad = 1.0)\n",
      "Loss at Epoch 4 is : netwok_nn.tensor(190.78881786749528 , grad = 1.0)\n",
      "Loss at Epoch 5 is : netwok_nn.tensor(190.62993915547008 , grad = 1.0)\n",
      "Loss at Epoch 6 is : netwok_nn.tensor(190.46961707821148 , grad = 1.0)\n",
      "Loss at Epoch 7 is : netwok_nn.tensor(190.30762634228537 , grad = 1.0)\n",
      "Loss at Epoch 8 is : netwok_nn.tensor(190.14382931324417 , grad = 1.0)\n",
      "Loss at Epoch 9 is : netwok_nn.tensor(189.9781404940304 , grad = 1.0)\n",
      "Loss at Epoch 10 is : netwok_nn.tensor(189.81050767960122 , grad = 1.0)\n",
      "Loss at Epoch 11 is : netwok_nn.tensor(189.64090116732604 , grad = 1.0)\n",
      "Loss at Epoch 12 is : netwok_nn.tensor(189.46930718822688 , grad = 1.0)\n",
      "Loss at Epoch 13 is : netwok_nn.tensor(189.29572369677962 , grad = 1.0)\n",
      "Loss at Epoch 14 is : netwok_nn.tensor(189.12015754962488 , grad = 1.0)\n",
      "Loss at Epoch 15 is : netwok_nn.tensor(188.94262253878802 , grad = 1.0)\n",
      "Loss at Epoch 16 is : netwok_nn.tensor(188.76313797066058 , grad = 1.0)\n",
      "Loss at Epoch 17 is : netwok_nn.tensor(188.58172760514717 , grad = 1.0)\n",
      "Loss at Epoch 18 is : netwok_nn.tensor(188.39841883957806 , grad = 1.0)\n",
      "Loss at Epoch 19 is : netwok_nn.tensor(188.21324206352529 , grad = 1.0)\n",
      "Loss at Epoch 20 is : netwok_nn.tensor(188.02623013604483 , grad = 1.0)\n",
      "Loss at Epoch 21 is : netwok_nn.tensor(187.83741795281986 , grad = 1.0)\n",
      "Loss at Epoch 22 is : netwok_nn.tensor(187.64684208095503 , grad = 1.0)\n",
      "Loss at Epoch 23 is : netwok_nn.tensor(187.45454044593032 , grad = 1.0)\n",
      "Loss at Epoch 24 is : netwok_nn.tensor(187.26055205974933 , grad = 1.0)\n",
      "Loss at Epoch 25 is : netwok_nn.tensor(187.064916782402 , grad = 1.0)\n",
      "Loss at Epoch 26 is : netwok_nn.tensor(186.867675110885 , grad = 1.0)\n",
      "Loss at Epoch 27 is : netwok_nn.tensor(186.6688679915095 , grad = 1.0)\n",
      "Loss at Epoch 28 is : netwok_nn.tensor(186.46853665227118 , grad = 1.0)\n",
      "Loss at Epoch 29 is : netwok_nn.tensor(186.26672245279923 , grad = 1.0)\n",
      "Loss at Epoch 30 is : netwok_nn.tensor(186.06346674993563 , grad = 1.0)\n",
      "Loss at Epoch 31 is : netwok_nn.tensor(185.85881077737417 , grad = 1.0)\n",
      "Loss at Epoch 32 is : netwok_nn.tensor(185.6527955380704 , grad = 1.0)\n",
      "Loss at Epoch 33 is : netwok_nn.tensor(185.44546170833172 , grad = 1.0)\n",
      "Loss at Epoch 34 is : netwok_nn.tensor(185.23684955264773 , grad = 1.0)\n",
      "Loss at Epoch 35 is : netwok_nn.tensor(185.0269988484301 , grad = 1.0)\n",
      "Loss at Epoch 36 is : netwok_nn.tensor(184.815948819913 , grad = 1.0)\n",
      "Loss at Epoch 37 is : netwok_nn.tensor(184.60373808053168 , grad = 1.0)\n",
      "Loss at Epoch 38 is : netwok_nn.tensor(184.39040458314435 , grad = 1.0)\n",
      "Loss at Epoch 39 is : netwok_nn.tensor(184.17598557750338 , grad = 1.0)\n",
      "Loss at Epoch 40 is : netwok_nn.tensor(183.96051757441987 , grad = 1.0)\n",
      "Loss at Epoch 41 is : netwok_nn.tensor(183.74403631608936 , grad = 1.0)\n",
      "Loss at Epoch 42 is : netwok_nn.tensor(183.5265767520812 , grad = 1.0)\n",
      "Loss at Epoch 43 is : netwok_nn.tensor(183.30817302051247 , grad = 1.0)\n",
      "Loss at Epoch 44 is : netwok_nn.tensor(183.0888584339573 , grad = 1.0)\n",
      "Loss at Epoch 45 is : netwok_nn.tensor(182.86866546966223 , grad = 1.0)\n",
      "Loss at Epoch 46 is : netwok_nn.tensor(182.64762576366303 , grad = 1.0)\n",
      "Loss at Epoch 47 is : netwok_nn.tensor(182.42577010842132 , grad = 1.0)\n",
      "Loss at Epoch 48 is : netwok_nn.tensor(182.20312845361985 , grad = 1.0)\n",
      "Loss at Epoch 49 is : netwok_nn.tensor(181.97972990978076 , grad = 1.0)\n",
      "Loss at Epoch 50 is : netwok_nn.tensor(181.7556027543884 , grad = 1.0)\n",
      "Loss at Epoch 51 is : netwok_nn.tensor(181.53077444022426 , grad = 1.0)\n",
      "Loss at Epoch 52 is : netwok_nn.tensor(181.30527160563892 , grad = 1.0)\n",
      "Loss at Epoch 53 is : netwok_nn.tensor(181.0791200865074 , grad = 1.0)\n",
      "Loss at Epoch 54 is : netwok_nn.tensor(180.85234492963377 , grad = 1.0)\n",
      "Loss at Epoch 55 is : netwok_nn.tensor(180.62497040739018 , grad = 1.0)\n",
      "Loss at Epoch 56 is : netwok_nn.tensor(180.39702003339139 , grad = 1.0)\n",
      "Loss at Epoch 57 is : netwok_nn.tensor(180.16851657902617 , grad = 1.0)\n",
      "Loss at Epoch 58 is : netwok_nn.tensor(179.93948209068066 , grad = 1.0)\n",
      "Loss at Epoch 59 is : netwok_nn.tensor(179.70993790750433 , grad = 1.0)\n",
      "Loss at Epoch 60 is : netwok_nn.tensor(179.4799046795865 , grad = 1.0)\n",
      "Loss at Epoch 61 is : netwok_nn.tensor(179.2494023864203 , grad = 1.0)\n",
      "Loss at Epoch 62 is : netwok_nn.tensor(179.01845035554805 , grad = 1.0)\n",
      "Loss at Epoch 63 is : netwok_nn.tensor(178.78706728129112 , grad = 1.0)\n",
      "Loss at Epoch 64 is : netwok_nn.tensor(178.5552712434794 , grad = 1.0)\n",
      "Loss at Epoch 65 is : netwok_nn.tensor(178.3230797261054 , grad = 1.0)\n",
      "Loss at Epoch 66 is : netwok_nn.tensor(178.09050963583687 , grad = 1.0)\n",
      "Loss at Epoch 67 is : netwok_nn.tensor(177.85757732033164 , grad = 1.0)\n",
      "Loss at Epoch 68 is : netwok_nn.tensor(177.6242985863048 , grad = 1.0)\n",
      "Loss at Epoch 69 is : netwok_nn.tensor(177.39068871730558 , grad = 1.0)\n",
      "Loss at Epoch 70 is : netwok_nn.tensor(177.1567624911696 , grad = 1.0)\n",
      "Loss at Epoch 71 is : netwok_nn.tensor(176.9225341971154 , grad = 1.0)\n",
      "Loss at Epoch 72 is : netwok_nn.tensor(176.68801765246147 , grad = 1.0)\n",
      "Loss at Epoch 73 is : netwok_nn.tensor(176.45322621894334 , grad = 1.0)\n",
      "Loss at Epoch 74 is : netwok_nn.tensor(176.21817281861613 , grad = 1.0)\n",
      "Loss at Epoch 75 is : netwok_nn.tensor(175.98286994933002 , grad = 1.0)\n",
      "Loss at Epoch 76 is : netwok_nn.tensor(175.74732969977114 , grad = 1.0)\n",
      "Loss at Epoch 77 is : netwok_nn.tensor(175.51156376406158 , grad = 1.0)\n",
      "Loss at Epoch 78 is : netwok_nn.tensor(175.27558345591694 , grad = 1.0)\n",
      "Loss at Epoch 79 is : netwok_nn.tensor(175.03939972236032 , grad = 1.0)\n",
      "Loss at Epoch 80 is : netwok_nn.tensor(174.80302315699478 , grad = 1.0)\n",
      "Loss at Epoch 81 is : netwok_nn.tensor(174.56646401283749 , grad = 1.0)\n",
      "Loss at Epoch 82 is : netwok_nn.tensor(174.3297322147207 , grad = 1.0)\n",
      "Loss at Epoch 83 is : netwok_nn.tensor(174.09283737126566 , grad = 1.0)\n",
      "Loss at Epoch 84 is : netwok_nn.tensor(173.8557887864365 , grad = 1.0)\n",
      "Loss at Epoch 85 is : netwok_nn.tensor(173.618595470683 , grad = 1.0)\n",
      "Loss at Epoch 86 is : netwok_nn.tensor(173.38126615168053 , grad = 1.0)\n",
      "Loss at Epoch 87 is : netwok_nn.tensor(173.1438092846767 , grad = 1.0)\n",
      "Loss at Epoch 88 is : netwok_nn.tensor(172.90623306245547 , grad = 1.0)\n",
      "Loss at Epoch 89 is : netwok_nn.tensor(172.66854542492828 , grad = 1.0)\n",
      "Loss at Epoch 90 is : netwok_nn.tensor(172.43075406836343 , grad = 1.0)\n",
      "Loss at Epoch 91 is : netwok_nn.tensor(172.19286645426456 , grad = 1.0)\n",
      "Loss at Epoch 92 is : netwok_nn.tensor(171.95488981790822 , grad = 1.0)\n",
      "Loss at Epoch 93 is : netwok_nn.tensor(171.71683117655348 , grad = 1.0)\n",
      "Loss at Epoch 94 is : netwok_nn.tensor(171.47869733733248 , grad = 1.0)\n",
      "Loss at Epoch 95 is : netwok_nn.tensor(171.24049490483387 , grad = 1.0)\n",
      "Loss at Epoch 96 is : netwok_nn.tensor(171.00223028839002 , grad = 1.0)\n",
      "Loss at Epoch 97 is : netwok_nn.tensor(170.7639097090783 , grad = 1.0)\n",
      "Loss at Epoch 98 is : netwok_nn.tensor(170.52553920644664 , grad = 1.0)\n",
      "Loss at Epoch 99 is : netwok_nn.tensor(170.28712464497445 , grad = 1.0)\n",
      "Loss at Epoch 100 is : netwok_nn.tensor(170.0486717202779 , grad = 1.0)\n",
      "Loss at Epoch 101 is : netwok_nn.tensor(169.81018596507027 , grad = 1.0)\n",
      "Loss at Epoch 102 is : netwok_nn.tensor(169.57167275488618 , grad = 1.0)\n",
      "Loss at Epoch 103 is : netwok_nn.tensor(169.33313731357933 , grad = 1.0)\n",
      "Loss at Epoch 104 is : netwok_nn.tensor(169.09458471860268 , grad = 1.0)\n",
      "Loss at Epoch 105 is : netwok_nn.tensor(168.85601990607975 , grad = 1.0)\n",
      "Loss at Epoch 106 is : netwok_nn.tensor(168.61744767567532 , grad = 1.0)\n",
      "Loss at Epoch 107 is : netwok_nn.tensor(168.37887269527397 , grad = 1.0)\n",
      "Loss at Epoch 108 is : netwok_nn.tensor(168.140299505474 , grad = 1.0)\n",
      "Loss at Epoch 109 is : netwok_nn.tensor(167.9017325239045 , grad = 1.0)\n",
      "Loss at Epoch 110 is : netwok_nn.tensor(167.66317604937277 , grad = 1.0)\n",
      "Loss at Epoch 111 is : netwok_nn.tensor(167.42463426584948 , grad = 1.0)\n",
      "Loss at Epoch 112 is : netwok_nn.tensor(167.1861112462976 , grad = 1.0)\n",
      "Loss at Epoch 113 is : netwok_nn.tensor(166.947610956352 , grad = 1.0)\n",
      "Loss at Epoch 114 is : netwok_nn.tensor(166.7091372578567 , grad = 1.0)\n",
      "Loss at Epoch 115 is : netwok_nn.tensor(166.47069391226415 , grad = 1.0)\n",
      "Loss at Epoch 116 is : netwok_nn.tensor(166.23228458390366 , grad = 1.0)\n",
      "Loss at Epoch 117 is : netwok_nn.tensor(165.99391284312424 , grad = 1.0)\n",
      "Loss at Epoch 118 is : netwok_nn.tensor(165.75558216931626 , grad = 1.0)\n",
      "Loss at Epoch 119 is : netwok_nn.tensor(165.5172959538184 , grad = 1.0)\n",
      "Loss at Epoch 120 is : netwok_nn.tensor(165.27905750271356 , grad = 1.0)\n",
      "Loss at Epoch 121 is : netwok_nn.tensor(165.040870039519 , grad = 1.0)\n",
      "Loss at Epoch 122 is : netwok_nn.tensor(164.8027367077749 , grad = 1.0)\n",
      "Loss at Epoch 123 is : netwok_nn.tensor(164.56466057353595 , grad = 1.0)\n",
      "Loss at Epoch 124 is : netwok_nn.tensor(164.32664462776935 , grad = 1.0)\n",
      "Loss at Epoch 125 is : netwok_nn.tensor(164.08869178866405 , grad = 1.0)\n",
      "Loss at Epoch 126 is : netwok_nn.tensor(163.85080490385408 , grad = 1.0)\n",
      "Loss at Epoch 127 is : netwok_nn.tensor(163.6129867525601 , grad = 1.0)\n",
      "Loss at Epoch 128 is : netwok_nn.tensor(163.37524004765262 , grad = 1.0)\n",
      "Loss at Epoch 129 is : netwok_nn.tensor(163.1375674376394 , grad = 1.0)\n",
      "Loss at Epoch 130 is : netwok_nn.tensor(162.89997150858107 , grad = 1.0)\n",
      "Loss at Epoch 131 is : netwok_nn.tensor(162.66245478593774 , grad = 1.0)\n",
      "Loss at Epoch 132 is : netwok_nn.tensor(162.42501973634876 , grad = 1.0)\n",
      "Loss at Epoch 133 is : netwok_nn.tensor(162.18766876934927 , grad = 1.0)\n",
      "Loss at Epoch 134 is : netwok_nn.tensor(161.95040423902554 , grad = 1.0)\n",
      "Loss at Epoch 135 is : netwok_nn.tensor(161.713228445612 , grad = 1.0)\n",
      "Loss at Epoch 136 is : netwok_nn.tensor(161.47614363703187 , grad = 1.0)\n",
      "Loss at Epoch 137 is : netwok_nn.tensor(161.23915201038406 , grad = 1.0)\n",
      "Loss at Epoch 138 is : netwok_nn.tensor(161.0022557133784 , grad = 1.0)\n",
      "Loss at Epoch 139 is : netwok_nn.tensor(160.76545684572113 , grad = 1.0)\n",
      "Loss at Epoch 140 is : netwok_nn.tensor(160.5287574604529 , grad = 1.0)\n",
      "Loss at Epoch 141 is : netwok_nn.tensor(160.292159565241 , grad = 1.0)\n",
      "Loss at Epoch 142 is : netwok_nn.tensor(160.0556651236275 , grad = 1.0)\n",
      "Loss at Epoch 143 is : netwok_nn.tensor(159.81927605623542 , grad = 1.0)\n",
      "Loss at Epoch 144 is : netwok_nn.tensor(159.58299424193433 , grad = 1.0)\n",
      "Loss at Epoch 145 is : netwok_nn.tensor(159.3468215189669 , grad = 1.0)\n",
      "Loss at Epoch 146 is : netwok_nn.tensor(159.11075968603805 , grad = 1.0)\n",
      "Loss at Epoch 147 is : netwok_nn.tensor(158.8748105033684 , grad = 1.0)\n",
      "Loss at Epoch 148 is : netwok_nn.tensor(158.63897569371275 , grad = 1.0)\n",
      "Loss at Epoch 149 is : netwok_nn.tensor(158.40325694334547 , grad = 1.0)\n",
      "Loss at Epoch 150 is : netwok_nn.tensor(158.167655903014 , grad = 1.0)\n",
      "Loss at Epoch 151 is : netwok_nn.tensor(157.93217418886158 , grad = 1.0)\n",
      "Loss at Epoch 152 is : netwok_nn.tensor(157.69681338332023 , grad = 1.0)\n",
      "Loss at Epoch 153 is : netwok_nn.tensor(157.46157503597533 , grad = 1.0)\n",
      "Loss at Epoch 154 is : netwok_nn.tensor(157.22646066440294 , grad = 1.0)\n",
      "Loss at Epoch 155 is : netwok_nn.tensor(156.99147175498044 , grad = 1.0)\n",
      "Loss at Epoch 156 is : netwok_nn.tensor(156.75660976367215 , grad = 1.0)\n",
      "Loss at Epoch 157 is : netwok_nn.tensor(156.52187611678994 , grad = 1.0)\n",
      "Loss at Epoch 158 is : netwok_nn.tensor(156.28727221173102 , grad = 1.0)\n",
      "Loss at Epoch 159 is : netwok_nn.tensor(156.05279941769228 , grad = 1.0)\n",
      "Loss at Epoch 160 is : netwok_nn.tensor(155.81845907636307 , grad = 1.0)\n",
      "Loss at Epoch 161 is : netwok_nn.tensor(155.58425250259725 , grad = 1.0)\n",
      "Loss at Epoch 162 is : netwok_nn.tensor(155.35018098506407 , grad = 1.0)\n",
      "Loss at Epoch 163 is : netwok_nn.tensor(155.11624578688034 , grad = 1.0)\n",
      "Loss at Epoch 164 is : netwok_nn.tensor(154.88244814622314 , grad = 1.0)\n",
      "Loss at Epoch 165 is : netwok_nn.tensor(154.64878927692448 , grad = 1.0)\n",
      "Loss at Epoch 166 is : netwok_nn.tensor(154.41527036904833 , grad = 1.0)\n",
      "Loss at Epoch 167 is : netwok_nn.tensor(154.18189258945083 , grad = 1.0)\n",
      "Loss at Epoch 168 is : netwok_nn.tensor(153.94865708232396 , grad = 1.0)\n",
      "Loss at Epoch 169 is : netwok_nn.tensor(153.7155649697233 , grad = 1.0)\n",
      "Loss at Epoch 170 is : netwok_nn.tensor(153.4826173520808 , grad = 1.0)\n",
      "Loss at Epoch 171 is : netwok_nn.tensor(153.24981530870286 , grad = 1.0)\n",
      "Loss at Epoch 172 is : netwok_nn.tensor(153.01715989825362 , grad = 1.0)\n",
      "Loss at Epoch 173 is : netwok_nn.tensor(152.7846521592253 , grad = 1.0)\n",
      "Loss at Epoch 174 is : netwok_nn.tensor(152.55229311039437 , grad = 1.0)\n",
      "Loss at Epoch 175 is : netwok_nn.tensor(152.32008375126586 , grad = 1.0)\n",
      "Loss at Epoch 176 is : netwok_nn.tensor(152.0880250625045 , grad = 1.0)\n",
      "Loss at Epoch 177 is : netwok_nn.tensor(151.85611800635402 , grad = 1.0)\n",
      "Loss at Epoch 178 is : netwok_nn.tensor(151.62436352704518 , grad = 1.0)\n",
      "Loss at Epoch 179 is : netwok_nn.tensor(151.39276255119216 , grad = 1.0)\n",
      "Loss at Epoch 180 is : netwok_nn.tensor(151.16131598817853 , grad = 1.0)\n",
      "Loss at Epoch 181 is : netwok_nn.tensor(150.93002473053224 , grad = 1.0)\n",
      "Loss at Epoch 182 is : netwok_nn.tensor(150.69888965429092 , grad = 1.0)\n",
      "Loss at Epoch 183 is : netwok_nn.tensor(150.467911619357 , grad = 1.0)\n",
      "Loss at Epoch 184 is : netwok_nn.tensor(150.23709146984365 , grad = 1.0)\n",
      "Loss at Epoch 185 is : netwok_nn.tensor(150.00643003441107 , grad = 1.0)\n",
      "Loss at Epoch 186 is : netwok_nn.tensor(149.77592812659438 , grad = 1.0)\n",
      "Loss at Epoch 187 is : netwok_nn.tensor(149.54558654512255 , grad = 1.0)\n",
      "Loss at Epoch 188 is : netwok_nn.tensor(149.31540607422886 , grad = 1.0)\n",
      "Loss at Epoch 189 is : netwok_nn.tensor(149.08538748395375 , grad = 1.0)\n",
      "Loss at Epoch 190 is : netwok_nn.tensor(148.85553153043946 , grad = 1.0)\n",
      "Loss at Epoch 191 is : netwok_nn.tensor(148.6258389562168 , grad = 1.0)\n",
      "Loss at Epoch 192 is : netwok_nn.tensor(148.3963104904852 , grad = 1.0)\n",
      "Loss at Epoch 193 is : netwok_nn.tensor(148.1669468493854 , grad = 1.0)\n",
      "Loss at Epoch 194 is : netwok_nn.tensor(147.9377487362646 , grad = 1.0)\n",
      "Loss at Epoch 195 is : netwok_nn.tensor(147.70871684193608 , grad = 1.0)\n",
      "Loss at Epoch 196 is : netwok_nn.tensor(147.47985184493098 , grad = 1.0)\n",
      "Loss at Epoch 197 is : netwok_nn.tensor(147.25115441174484 , grad = 1.0)\n",
      "Loss at Epoch 198 is : netwok_nn.tensor(147.02262519707742 , grad = 1.0)\n",
      "Loss at Epoch 199 is : netwok_nn.tensor(146.79426484406676 , grad = 1.0)\n",
      "Loss at Epoch 200 is : netwok_nn.tensor(146.56607398451754 , grad = 1.0)\n",
      "Loss at Epoch 201 is : netwok_nn.tensor(146.33805323912367 , grad = 1.0)\n",
      "Loss at Epoch 202 is : netwok_nn.tensor(146.11020321768547 , grad = 1.0)\n",
      "Loss at Epoch 203 is : netwok_nn.tensor(145.88252451932166 , grad = 1.0)\n",
      "Loss at Epoch 204 is : netwok_nn.tensor(145.65501773267647 , grad = 1.0)\n",
      "Loss at Epoch 205 is : netwok_nn.tensor(145.42768343612101 , grad = 1.0)\n",
      "Loss at Epoch 206 is : netwok_nn.tensor(145.20052219795082 , grad = 1.0)\n",
      "Loss at Epoch 207 is : netwok_nn.tensor(144.97353457657766 , grad = 1.0)\n",
      "Loss at Epoch 208 is : netwok_nn.tensor(144.74672112071792 , grad = 1.0)\n",
      "Loss at Epoch 209 is : netwok_nn.tensor(144.5200823695754 , grad = 1.0)\n",
      "Loss at Epoch 210 is : netwok_nn.tensor(144.29361885302066 , grad = 1.0)\n",
      "Loss at Epoch 211 is : netwok_nn.tensor(144.0673310917659 , grad = 1.0)\n",
      "Loss at Epoch 212 is : netwok_nn.tensor(143.84121959753554 , grad = 1.0)\n",
      "Loss at Epoch 213 is : netwok_nn.tensor(143.61528487323324 , grad = 1.0)\n",
      "Loss at Epoch 214 is : netwok_nn.tensor(143.38952741310493 , grad = 1.0)\n",
      "Loss at Epoch 215 is : netwok_nn.tensor(143.1639477028978 , grad = 1.0)\n",
      "Loss at Epoch 216 is : netwok_nn.tensor(142.9385462200163 , grad = 1.0)\n",
      "Loss at Epoch 217 is : netwok_nn.tensor(142.71332343367382 , grad = 1.0)\n",
      "Loss at Epoch 218 is : netwok_nn.tensor(142.48827980504177 , grad = 1.0)\n",
      "Loss at Epoch 219 is : netwok_nn.tensor(142.26341578739445 , grad = 1.0)\n",
      "Loss at Epoch 220 is : netwok_nn.tensor(142.0387318262514 , grad = 1.0)\n",
      "Loss at Epoch 221 is : netwok_nn.tensor(141.81422835951605 , grad = 1.0)\n",
      "Loss at Epoch 222 is : netwok_nn.tensor(141.58990581761182 , grad = 1.0)\n",
      "Loss at Epoch 223 is : netwok_nn.tensor(141.36576462361438 , grad = 1.0)\n",
      "Loss at Epoch 224 is : netwok_nn.tensor(141.1418051933822 , grad = 1.0)\n",
      "Loss at Epoch 225 is : netwok_nn.tensor(140.91802793568283 , grad = 1.0)\n",
      "Loss at Epoch 226 is : netwok_nn.tensor(140.6944332523178 , grad = 1.0)\n",
      "Loss at Epoch 227 is : netwok_nn.tensor(140.47102153824372 , grad = 1.0)\n",
      "Loss at Epoch 228 is : netwok_nn.tensor(140.24779318169132 , grad = 1.0)\n",
      "Loss at Epoch 229 is : netwok_nn.tensor(140.02474856428185 , grad = 1.0)\n",
      "Loss at Epoch 230 is : netwok_nn.tensor(139.80188806114103 , grad = 1.0)\n",
      "Loss at Epoch 231 is : netwok_nn.tensor(139.57921204101015 , grad = 1.0)\n",
      "Loss at Epoch 232 is : netwok_nn.tensor(139.35672086635554 , grad = 1.0)\n",
      "Loss at Epoch 233 is : netwok_nn.tensor(139.13441489347503 , grad = 1.0)\n",
      "Loss at Epoch 234 is : netwok_nn.tensor(138.91229447260258 , grad = 1.0)\n",
      "Loss at Epoch 235 is : netwok_nn.tensor(138.69035994801044 , grad = 1.0)\n",
      "Loss at Epoch 236 is : netwok_nn.tensor(138.4686116581096 , grad = 1.0)\n",
      "Loss at Epoch 237 is : netwok_nn.tensor(138.24704993554766 , grad = 1.0)\n",
      "Loss at Epoch 238 is : netwok_nn.tensor(138.02567510730486 , grad = 1.0)\n",
      "Loss at Epoch 239 is : netwok_nn.tensor(137.80448749478833 , grad = 1.0)\n",
      "Loss at Epoch 240 is : netwok_nn.tensor(137.5834874139241 , grad = 1.0)\n",
      "Loss at Epoch 241 is : netwok_nn.tensor(137.36267517524732 , grad = 1.0)\n",
      "Loss at Epoch 242 is : netwok_nn.tensor(137.1420510839908 , grad = 1.0)\n",
      "Loss at Epoch 243 is : netwok_nn.tensor(136.92161544017156 , grad = 1.0)\n",
      "Loss at Epoch 244 is : netwok_nn.tensor(136.70136853867572 , grad = 1.0)\n",
      "Loss at Epoch 245 is : netwok_nn.tensor(136.4813106693416 , grad = 1.0)\n",
      "Loss at Epoch 246 is : netwok_nn.tensor(136.26144211704133 , grad = 1.0)\n",
      "Loss at Epoch 247 is : netwok_nn.tensor(136.04176316176063 , grad = 1.0)\n",
      "Loss at Epoch 248 is : netwok_nn.tensor(135.82227407867708 , grad = 1.0)\n",
      "Loss at Epoch 249 is : netwok_nn.tensor(135.60297513823687 , grad = 1.0)\n",
      "Loss at Epoch 250 is : netwok_nn.tensor(135.3838666062301 , grad = 1.0)\n",
      "Loss at Epoch 251 is : netwok_nn.tensor(135.16494874386441 , grad = 1.0)\n",
      "Loss at Epoch 252 is : netwok_nn.tensor(134.94622180783728 , grad = 1.0)\n",
      "Loss at Epoch 253 is : netwok_nn.tensor(134.72768605040693 , grad = 1.0)\n",
      "Loss at Epoch 254 is : netwok_nn.tensor(134.50934171946196 , grad = 1.0)\n",
      "Loss at Epoch 255 is : netwok_nn.tensor(134.2911890585893 , grad = 1.0)\n",
      "Loss at Epoch 256 is : netwok_nn.tensor(134.0732283071412 , grad = 1.0)\n",
      "Loss at Epoch 257 is : netwok_nn.tensor(133.85545970030068 , grad = 1.0)\n",
      "Loss at Epoch 258 is : netwok_nn.tensor(133.63788346914606 , grad = 1.0)\n",
      "Loss at Epoch 259 is : netwok_nn.tensor(133.42049984071383 , grad = 1.0)\n",
      "Loss at Epoch 260 is : netwok_nn.tensor(133.20330903806067 , grad = 1.0)\n",
      "Loss at Epoch 261 is : netwok_nn.tensor(132.9863112803241 , grad = 1.0)\n",
      "Loss at Epoch 262 is : netwok_nn.tensor(132.76950678278214 , grad = 1.0)\n",
      "Loss at Epoch 263 is : netwok_nn.tensor(132.5528957569118 , grad = 1.0)\n",
      "Loss at Epoch 264 is : netwok_nn.tensor(132.3364784104463 , grad = 1.0)\n",
      "Loss at Epoch 265 is : netwok_nn.tensor(132.12025494743145 , grad = 1.0)\n",
      "Loss at Epoch 266 is : netwok_nn.tensor(131.90422556828102 , grad = 1.0)\n",
      "Loss at Epoch 267 is : netwok_nn.tensor(131.68839046983078 , grad = 1.0)\n",
      "Loss at Epoch 268 is : netwok_nn.tensor(131.472749845392 , grad = 1.0)\n",
      "Loss at Epoch 269 is : netwok_nn.tensor(131.25730388480343 , grad = 1.0)\n",
      "Loss at Epoch 270 is : netwok_nn.tensor(131.0420527744828 , grad = 1.0)\n",
      "Loss at Epoch 271 is : netwok_nn.tensor(130.82699669747723 , grad = 1.0)\n",
      "Loss at Epoch 272 is : netwok_nn.tensor(130.61213583351253 , grad = 1.0)\n",
      "Loss at Epoch 273 is : netwok_nn.tensor(130.39747035904185 , grad = 1.0)\n",
      "Loss at Epoch 274 is : netwok_nn.tensor(130.1830004472935 , grad = 1.0)\n",
      "Loss at Epoch 275 is : netwok_nn.tensor(129.96872626831745 , grad = 1.0)\n",
      "Loss at Epoch 276 is : netwok_nn.tensor(129.75464798903187 , grad = 1.0)\n",
      "Loss at Epoch 277 is : netwok_nn.tensor(129.54076577326774 , grad = 1.0)\n",
      "Loss at Epoch 278 is : netwok_nn.tensor(129.32707978181367 , grad = 1.0)\n",
      "Loss at Epoch 279 is : netwok_nn.tensor(129.1135901724593 , grad = 1.0)\n",
      "Loss at Epoch 280 is : netwok_nn.tensor(128.90029710003807 , grad = 1.0)\n",
      "Loss at Epoch 281 is : netwok_nn.tensor(128.6872007164696 , grad = 1.0)\n",
      "Loss at Epoch 282 is : netwok_nn.tensor(128.47430117080066 , grad = 1.0)\n",
      "Loss at Epoch 283 is : netwok_nn.tensor(128.26159860924602 , grad = 1.0)\n",
      "Loss at Epoch 284 is : netwok_nn.tensor(128.04909317522834 , grad = 1.0)\n",
      "Loss at Epoch 285 is : netwok_nn.tensor(127.83678500941734 , grad = 1.0)\n",
      "Loss at Epoch 286 is : netwok_nn.tensor(127.62467424976838 , grad = 1.0)\n",
      "Loss at Epoch 287 is : netwok_nn.tensor(127.41276103156042 , grad = 1.0)\n",
      "Loss at Epoch 288 is : netwok_nn.tensor(127.20104548743313 , grad = 1.0)\n",
      "Loss at Epoch 289 is : netwok_nn.tensor(126.9895277474236 , grad = 1.0)\n",
      "Loss at Epoch 290 is : netwok_nn.tensor(126.77820793900226 , grad = 1.0)\n",
      "Loss at Epoch 291 is : netwok_nn.tensor(126.56708618710827 , grad = 1.0)\n",
      "Loss at Epoch 292 is : netwok_nn.tensor(126.3561626141843 , grad = 1.0)\n",
      "Loss at Epoch 293 is : netwok_nn.tensor(126.1454373402108 , grad = 1.0)\n",
      "Loss at Epoch 294 is : netwok_nn.tensor(125.9349104827394 , grad = 1.0)\n",
      "Loss at Epoch 295 is : netwok_nn.tensor(125.7245821569262 , grad = 1.0)\n",
      "Loss at Epoch 296 is : netwok_nn.tensor(125.51445247556417 , grad = 1.0)\n",
      "Loss at Epoch 297 is : netwok_nn.tensor(125.3045215491151 , grad = 1.0)\n",
      "Loss at Epoch 298 is : netwok_nn.tensor(125.09478948574095 , grad = 1.0)\n",
      "Loss at Epoch 299 is : netwok_nn.tensor(124.88525639133509 , grad = 1.0)\n",
      "Loss at Epoch 300 is : netwok_nn.tensor(124.67592236955232 , grad = 1.0)\n",
      "Loss at Epoch 301 is : netwok_nn.tensor(124.466787521839 , grad = 1.0)\n",
      "Loss at Epoch 302 is : netwok_nn.tensor(124.25785194746237 , grad = 1.0)\n",
      "Loss at Epoch 303 is : netwok_nn.tensor(124.0491157435396 , grad = 1.0)\n",
      "Loss at Epoch 304 is : netwok_nn.tensor(123.84057900506619 , grad = 1.0)\n",
      "Loss at Epoch 305 is : netwok_nn.tensor(123.63224182494399 , grad = 1.0)\n",
      "Loss at Epoch 306 is : netwok_nn.tensor(123.4241042940088 , grad = 1.0)\n",
      "Loss at Epoch 307 is : netwok_nn.tensor(123.2161665010573 , grad = 1.0)\n",
      "Loss at Epoch 308 is : netwok_nn.tensor(123.00842853287415 , grad = 1.0)\n",
      "Loss at Epoch 309 is : netwok_nn.tensor(122.80089047425773 , grad = 1.0)\n",
      "Loss at Epoch 310 is : netwok_nn.tensor(122.59355240804635 , grad = 1.0)\n",
      "Loss at Epoch 311 is : netwok_nn.tensor(122.3864144151436 , grad = 1.0)\n",
      "Loss at Epoch 312 is : netwok_nn.tensor(122.17947657454333 , grad = 1.0)\n",
      "Loss at Epoch 313 is : netwok_nn.tensor(121.97273896335417 , grad = 1.0)\n",
      "Loss at Epoch 314 is : netwok_nn.tensor(121.76620165682408 , grad = 1.0)\n",
      "Loss at Epoch 315 is : netwok_nn.tensor(121.5598647283639 , grad = 1.0)\n",
      "Loss at Epoch 316 is : netwok_nn.tensor(121.35372824957109 , grad = 1.0)\n",
      "Loss at Epoch 317 is : netwok_nn.tensor(121.14779229025264 , grad = 1.0)\n",
      "Loss at Epoch 318 is : netwok_nn.tensor(120.94205691844807 , grad = 1.0)\n",
      "Loss at Epoch 319 is : netwok_nn.tensor(120.73652220045162 , grad = 1.0)\n",
      "Loss at Epoch 320 is : netwok_nn.tensor(120.53118820083456 , grad = 1.0)\n",
      "Loss at Epoch 321 is : netwok_nn.tensor(120.32605498246664 , grad = 1.0)\n",
      "Loss at Epoch 322 is : netwok_nn.tensor(120.12112260653775 , grad = 1.0)\n",
      "Loss at Epoch 323 is : netwok_nn.tensor(119.91639113257887 , grad = 1.0)\n",
      "Loss at Epoch 324 is : netwok_nn.tensor(119.7118606184828 , grad = 1.0)\n",
      "Loss at Epoch 325 is : netwok_nn.tensor(119.50753112052467 , grad = 1.0)\n",
      "Loss at Epoch 326 is : netwok_nn.tensor(119.30340269338203 , grad = 1.0)\n",
      "Loss at Epoch 327 is : netwok_nn.tensor(119.0994753901547 , grad = 1.0)\n",
      "Loss at Epoch 328 is : netwok_nn.tensor(118.89574926238416 , grad = 1.0)\n",
      "Loss at Epoch 329 is : netwok_nn.tensor(118.69222436007303 , grad = 1.0)\n",
      "Loss at Epoch 330 is : netwok_nn.tensor(118.48890073170385 , grad = 1.0)\n",
      "Loss at Epoch 331 is : netwok_nn.tensor(118.28577842425776 , grad = 1.0)\n",
      "Loss at Epoch 332 is : netwok_nn.tensor(118.08285748323284 , grad = 1.0)\n",
      "Loss at Epoch 333 is : netwok_nn.tensor(117.88013795266234 , grad = 1.0)\n",
      "Loss at Epoch 334 is : netwok_nn.tensor(117.67761987513249 , grad = 1.0)\n",
      "Loss at Epoch 335 is : netwok_nn.tensor(117.47530329180003 , grad = 1.0)\n",
      "Loss at Epoch 336 is : netwok_nn.tensor(117.27318824240957 , grad = 1.0)\n",
      "Loss at Epoch 337 is : netwok_nn.tensor(117.07127476531068 , grad = 1.0)\n",
      "Loss at Epoch 338 is : netwok_nn.tensor(116.8695628974746 , grad = 1.0)\n",
      "Loss at Epoch 339 is : netwok_nn.tensor(116.668052674511 , grad = 1.0)\n",
      "Loss at Epoch 340 is : netwok_nn.tensor(116.46674413068413 , grad = 1.0)\n",
      "Loss at Epoch 341 is : netwok_nn.tensor(116.26563729892911 , grad = 1.0)\n",
      "Loss at Epoch 342 is : netwok_nn.tensor(116.06473221086767 , grad = 1.0)\n",
      "Loss at Epoch 343 is : netwok_nn.tensor(115.86402889682367 , grad = 1.0)\n",
      "Loss at Epoch 344 is : netwok_nn.tensor(115.66352738583888 , grad = 1.0)\n",
      "Loss at Epoch 345 is : netwok_nn.tensor(115.46322770568784 , grad = 1.0)\n",
      "Loss at Epoch 346 is : netwok_nn.tensor(115.26312988289287 , grad = 1.0)\n",
      "Loss at Epoch 347 is : netwok_nn.tensor(115.06323394273906 , grad = 1.0)\n",
      "Loss at Epoch 348 is : netwok_nn.tensor(114.86353990928859 , grad = 1.0)\n",
      "Loss at Epoch 349 is : netwok_nn.tensor(114.66404780539514 , grad = 1.0)\n",
      "Loss at Epoch 350 is : netwok_nn.tensor(114.46475765271818 , grad = 1.0)\n",
      "Loss at Epoch 351 is : netwok_nn.tensor(114.26566947173669 , grad = 1.0)\n",
      "Loss at Epoch 352 is : netwok_nn.tensor(114.06678328176305 , grad = 1.0)\n",
      "Loss at Epoch 353 is : netwok_nn.tensor(113.86809910095653 , grad = 1.0)\n",
      "Loss at Epoch 354 is : netwok_nn.tensor(113.66961694633683 , grad = 1.0)\n",
      "Loss at Epoch 355 is : netwok_nn.tensor(113.47133683379694 , grad = 1.0)\n",
      "Loss at Epoch 356 is : netwok_nn.tensor(113.27325877811647 , grad = 1.0)\n",
      "Loss at Epoch 357 is : netwok_nn.tensor(113.07538279297432 , grad = 1.0)\n",
      "Loss at Epoch 358 is : netwok_nn.tensor(112.87770889096126 , grad = 1.0)\n",
      "Loss at Epoch 359 is : netwok_nn.tensor(112.68023708359262 , grad = 1.0)\n",
      "Loss at Epoch 360 is : netwok_nn.tensor(112.48296738132026 , grad = 1.0)\n",
      "Loss at Epoch 361 is : netwok_nn.tensor(112.28589979354508 , grad = 1.0)\n",
      "Loss at Epoch 362 is : netwok_nn.tensor(112.08903432862867 , grad = 1.0)\n",
      "Loss at Epoch 363 is : netwok_nn.tensor(111.89237099390527 , grad = 1.0)\n",
      "Loss at Epoch 364 is : netwok_nn.tensor(111.69590979569342 , grad = 1.0)\n",
      "Loss at Epoch 365 is : netwok_nn.tensor(111.49965073930733 , grad = 1.0)\n",
      "Loss at Epoch 366 is : netwok_nn.tensor(111.30359382906836 , grad = 1.0)\n",
      "Loss at Epoch 367 is : netwok_nn.tensor(111.10773906831604 , grad = 1.0)\n",
      "Loss at Epoch 368 is : netwok_nn.tensor(110.91208645941936 , grad = 1.0)\n",
      "Loss at Epoch 369 is : netwok_nn.tensor(110.71663600378719 , grad = 1.0)\n",
      "Loss at Epoch 370 is : netwok_nn.tensor(110.52138770187956 , grad = 1.0)\n",
      "Loss at Epoch 371 is : netwok_nn.tensor(110.32634155321783 , grad = 1.0)\n",
      "Loss at Epoch 372 is : netwok_nn.tensor(110.13149755639537 , grad = 1.0)\n",
      "Loss at Epoch 373 is : netwok_nn.tensor(109.93685570908771 , grad = 1.0)\n",
      "Loss at Epoch 374 is : netwok_nn.tensor(109.7424160080629 , grad = 1.0)\n",
      "Loss at Epoch 375 is : netwok_nn.tensor(109.54817844919144 , grad = 1.0)\n",
      "Loss at Epoch 376 is : netwok_nn.tensor(109.35414302745617 , grad = 1.0)\n",
      "Loss at Epoch 377 is : netwok_nn.tensor(109.1603097369621 , grad = 1.0)\n",
      "Loss at Epoch 378 is : netwok_nn.tensor(108.96667857094612 , grad = 1.0)\n",
      "Loss at Epoch 379 is : netwok_nn.tensor(108.77324952178633 , grad = 1.0)\n",
      "Loss at Epoch 380 is : netwok_nn.tensor(108.58002258101163 , grad = 1.0)\n",
      "Loss at Epoch 381 is : netwok_nn.tensor(108.38699773931097 , grad = 1.0)\n",
      "Loss at Epoch 382 is : netwok_nn.tensor(108.19417498654241 , grad = 1.0)\n",
      "Loss at Epoch 383 is : netwok_nn.tensor(108.00155431174232 , grad = 1.0)\n",
      "Loss at Epoch 384 is : netwok_nn.tensor(107.80913570313415 , grad = 1.0)\n",
      "Loss at Epoch 385 is : netwok_nn.tensor(107.61691914813726 , grad = 1.0)\n",
      "Loss at Epoch 386 is : netwok_nn.tensor(107.42490463337579 , grad = 1.0)\n",
      "Loss at Epoch 387 is : netwok_nn.tensor(107.23309214468705 , grad = 1.0)\n",
      "Loss at Epoch 388 is : netwok_nn.tensor(107.04148166713009 , grad = 1.0)\n",
      "Loss at Epoch 389 is : netwok_nn.tensor(106.85007318499403 , grad = 1.0)\n",
      "Loss at Epoch 390 is : netwok_nn.tensor(106.65886668180632 , grad = 1.0)\n",
      "Loss at Epoch 391 is : netwok_nn.tensor(106.46786214034096 , grad = 1.0)\n",
      "Loss at Epoch 392 is : netwok_nn.tensor(106.2770595426265 , grad = 1.0)\n",
      "Loss at Epoch 393 is : netwok_nn.tensor(106.08645886995404 , grad = 1.0)\n",
      "Loss at Epoch 394 is : netwok_nn.tensor(105.89606010288499 , grad = 1.0)\n",
      "Loss at Epoch 395 is : netwok_nn.tensor(105.70586322125894 , grad = 1.0)\n",
      "Loss at Epoch 396 is : netwok_nn.tensor(105.51586820420131 , grad = 1.0)\n",
      "Loss at Epoch 397 is : netwok_nn.tensor(105.3260750301308 , grad = 1.0)\n",
      "Loss at Epoch 398 is : netwok_nn.tensor(105.13648367676694 , grad = 1.0)\n",
      "Loss at Epoch 399 is : netwok_nn.tensor(104.94709412113757 , grad = 1.0)\n",
      "Loss at Epoch 400 is : netwok_nn.tensor(104.75790633958583 , grad = 1.0)\n",
      "Loss at Epoch 401 is : netwok_nn.tensor(104.56892030777773 , grad = 1.0)\n",
      "Loss at Epoch 402 is : netwok_nn.tensor(104.38013600070896 , grad = 1.0)\n",
      "Loss at Epoch 403 is : netwok_nn.tensor(104.19155339271208 , grad = 1.0)\n",
      "Loss at Epoch 404 is : netwok_nn.tensor(104.00317245746328 , grad = 1.0)\n",
      "Loss at Epoch 405 is : netwok_nn.tensor(103.81499316798953 , grad = 1.0)\n",
      "Loss at Epoch 406 is : netwok_nn.tensor(103.62701549667497 , grad = 1.0)\n",
      "Loss at Epoch 407 is : netwok_nn.tensor(103.43923941526796 , grad = 1.0)\n",
      "Loss at Epoch 408 is : netwok_nn.tensor(103.2516648948874 , grad = 1.0)\n",
      "Loss at Epoch 409 is : netwok_nn.tensor(103.0642919060293 , grad = 1.0)\n",
      "Loss at Epoch 410 is : netwok_nn.tensor(102.87712041857345 , grad = 1.0)\n",
      "Loss at Epoch 411 is : netwok_nn.tensor(102.69015040178948 , grad = 1.0)\n",
      "Loss at Epoch 412 is : netwok_nn.tensor(102.50338182434332 , grad = 1.0)\n",
      "Loss at Epoch 413 is : netwok_nn.tensor(102.31681465430341 , grad = 1.0)\n",
      "Loss at Epoch 414 is : netwok_nn.tensor(102.13044885914677 , grad = 1.0)\n",
      "Loss at Epoch 415 is : netwok_nn.tensor(101.94428440576509 , grad = 1.0)\n",
      "Loss at Epoch 416 is : netwok_nn.tensor(101.75832126047084 , grad = 1.0)\n",
      "Loss at Epoch 417 is : netwok_nn.tensor(101.57255938900296 , grad = 1.0)\n",
      "Loss at Epoch 418 is : netwok_nn.tensor(101.38699875653293 , grad = 1.0)\n",
      "Loss at Epoch 419 is : netwok_nn.tensor(101.20163932767043 , grad = 1.0)\n",
      "Loss at Epoch 420 is : netwok_nn.tensor(101.01648106646911 , grad = 1.0)\n",
      "Loss at Epoch 421 is : netwok_nn.tensor(100.83152393643219 , grad = 1.0)\n",
      "Loss at Epoch 422 is : netwok_nn.tensor(100.64676790051811 , grad = 1.0)\n",
      "Loss at Epoch 423 is : netwok_nn.tensor(100.46221292114598 , grad = 1.0)\n",
      "Loss at Epoch 424 is : netwok_nn.tensor(100.27785896020104 , grad = 1.0)\n",
      "Loss at Epoch 425 is : netwok_nn.tensor(100.09370597904008 , grad = 1.0)\n",
      "Loss at Epoch 426 is : netwok_nn.tensor(99.90975393849678 , grad = 1.0)\n",
      "Loss at Epoch 427 is : netwok_nn.tensor(99.7260027988869 , grad = 1.0)\n",
      "Loss at Epoch 428 is : netwok_nn.tensor(99.54245252001354 , grad = 1.0)\n",
      "Loss at Epoch 429 is : netwok_nn.tensor(99.35910306117226 , grad = 1.0)\n",
      "Loss at Epoch 430 is : netwok_nn.tensor(99.17595438115617 , grad = 1.0)\n",
      "Loss at Epoch 431 is : netwok_nn.tensor(98.993006438261 , grad = 1.0)\n",
      "Loss at Epoch 432 is : netwok_nn.tensor(98.81025919028988 , grad = 1.0)\n",
      "Loss at Epoch 433 is : netwok_nn.tensor(98.62771259455855 , grad = 1.0)\n",
      "Loss at Epoch 434 is : netwok_nn.tensor(98.44536660789994 , grad = 1.0)\n",
      "Loss at Epoch 435 is : netwok_nn.tensor(98.26322118666913 , grad = 1.0)\n",
      "Loss at Epoch 436 is : netwok_nn.tensor(98.081276286748 , grad = 1.0)\n",
      "Loss at Epoch 437 is : netwok_nn.tensor(97.89953186355 , grad = 1.0)\n",
      "Loss at Epoch 438 is : netwok_nn.tensor(97.71798787202476 , grad = 1.0)\n",
      "Loss at Epoch 439 is : netwok_nn.tensor(97.5366442666626 , grad = 1.0)\n",
      "Loss at Epoch 440 is : netwok_nn.tensor(97.35550100149912 , grad = 1.0)\n",
      "Loss at Epoch 441 is : netwok_nn.tensor(97.17455803011978 , grad = 1.0)\n",
      "Loss at Epoch 442 is : netwok_nn.tensor(96.9938153056641 , grad = 1.0)\n",
      "Loss at Epoch 443 is : netwok_nn.tensor(96.8132727808303 , grad = 1.0)\n",
      "Loss at Epoch 444 is : netwok_nn.tensor(96.63293040787941 , grad = 1.0)\n",
      "Loss at Epoch 445 is : netwok_nn.tensor(96.45278813863965 , grad = 1.0)\n",
      "Loss at Epoch 446 is : netwok_nn.tensor(96.2728459245107 , grad = 1.0)\n",
      "Loss at Epoch 447 is : netwok_nn.tensor(96.09310371646784 , grad = 1.0)\n",
      "Loss at Epoch 448 is : netwok_nn.tensor(95.91356146506614 , grad = 1.0)\n",
      "Loss at Epoch 449 is : netwok_nn.tensor(95.73421912044445 , grad = 1.0)\n",
      "Loss at Epoch 450 is : netwok_nn.tensor(95.55507663232954 , grad = 1.0)\n",
      "Loss at Epoch 451 is : netwok_nn.tensor(95.37613395004011 , grad = 1.0)\n",
      "Loss at Epoch 452 is : netwok_nn.tensor(95.19739102249066 , grad = 1.0)\n",
      "Loss at Epoch 453 is : netwok_nn.tensor(95.01884779819558 , grad = 1.0)\n",
      "Loss at Epoch 454 is : netwok_nn.tensor(94.84050422527287 , grad = 1.0)\n",
      "Loss at Epoch 455 is : netwok_nn.tensor(94.66236025144799 , grad = 1.0)\n",
      "Loss at Epoch 456 is : netwok_nn.tensor(94.48441582405775 , grad = 1.0)\n",
      "Loss at Epoch 457 is : netwok_nn.tensor(94.30667089005388 , grad = 1.0)\n",
      "Loss at Epoch 458 is : netwok_nn.tensor(94.129125396007 , grad = 1.0)\n",
      "Loss at Epoch 459 is : netwok_nn.tensor(93.95177928811003 , grad = 1.0)\n",
      "Loss at Epoch 460 is : netwok_nn.tensor(93.77463251218201 , grad = 1.0)\n",
      "Loss at Epoch 461 is : netwok_nn.tensor(93.59768501367157 , grad = 1.0)\n",
      "Loss at Epoch 462 is : netwok_nn.tensor(93.42093673766047 , grad = 1.0)\n",
      "Loss at Epoch 463 is : netwok_nn.tensor(93.24438762886729 , grad = 1.0)\n",
      "Loss at Epoch 464 is : netwok_nn.tensor(93.06803763165063 , grad = 1.0)\n",
      "Loss at Epoch 465 is : netwok_nn.tensor(92.89188669001287 , grad = 1.0)\n",
      "Loss at Epoch 466 is : netwok_nn.tensor(92.71593474760324 , grad = 1.0)\n",
      "Loss at Epoch 467 is : netwok_nn.tensor(92.54018174772145 , grad = 1.0)\n",
      "Loss at Epoch 468 is : netwok_nn.tensor(92.36462763332086 , grad = 1.0)\n",
      "Loss at Epoch 469 is : netwok_nn.tensor(92.18927234701185 , grad = 1.0)\n",
      "Loss at Epoch 470 is : netwok_nn.tensor(92.01411583106503 , grad = 1.0)\n",
      "Loss at Epoch 471 is : netwok_nn.tensor(91.8391580274145 , grad = 1.0)\n",
      "Loss at Epoch 472 is : netwok_nn.tensor(91.66439887766103 , grad = 1.0)\n",
      "Loss at Epoch 473 is : netwok_nn.tensor(91.48983832307523 , grad = 1.0)\n",
      "Loss at Epoch 474 is : netwok_nn.tensor(91.31547630460064 , grad = 1.0)\n",
      "Loss at Epoch 475 is : netwok_nn.tensor(91.14131276285683 , grad = 1.0)\n",
      "Loss at Epoch 476 is : netwok_nn.tensor(90.96734763814253 , grad = 1.0)\n",
      "Loss at Epoch 477 is : netwok_nn.tensor(90.79358087043849 , grad = 1.0)\n",
      "Loss at Epoch 478 is : netwok_nn.tensor(90.62001239941065 , grad = 1.0)\n",
      "Loss at Epoch 479 is : netwok_nn.tensor(90.446642164413 , grad = 1.0)\n",
      "Loss at Epoch 480 is : netwok_nn.tensor(90.27347010449057 , grad = 1.0)\n",
      "Loss at Epoch 481 is : netwok_nn.tensor(90.10049615838223 , grad = 1.0)\n",
      "Loss at Epoch 482 is : netwok_nn.tensor(89.92772026452377 , grad = 1.0)\n",
      "Loss at Epoch 483 is : netwok_nn.tensor(89.75514236105045 , grad = 1.0)\n",
      "Loss at Epoch 484 is : netwok_nn.tensor(89.58276238580005 , grad = 1.0)\n",
      "Loss at Epoch 485 is : netwok_nn.tensor(89.41058027631561 , grad = 1.0)\n",
      "Loss at Epoch 486 is : netwok_nn.tensor(89.23859596984806 , grad = 1.0)\n",
      "Loss at Epoch 487 is : netwok_nn.tensor(89.06680940335912 , grad = 1.0)\n",
      "Loss at Epoch 488 is : netwok_nn.tensor(88.8952205135238 , grad = 1.0)\n",
      "Loss at Epoch 489 is : netwok_nn.tensor(88.72382923673327 , grad = 1.0)\n",
      "Loss at Epoch 490 is : netwok_nn.tensor(88.55263550909744 , grad = 1.0)\n",
      "Loss at Epoch 491 is : netwok_nn.tensor(88.38163926644748 , grad = 1.0)\n",
      "Loss at Epoch 492 is : netwok_nn.tensor(88.21084044433846 , grad = 1.0)\n",
      "Loss at Epoch 493 is : netwok_nn.tensor(88.04023897805207 , grad = 1.0)\n",
      "Loss at Epoch 494 is : netwok_nn.tensor(87.86983480259889 , grad = 1.0)\n",
      "Loss at Epoch 495 is : netwok_nn.tensor(87.69962785272111 , grad = 1.0)\n",
      "Loss at Epoch 496 is : netwok_nn.tensor(87.52961806289491 , grad = 1.0)\n",
      "Loss at Epoch 497 is : netwok_nn.tensor(87.35980536733297 , grad = 1.0)\n",
      "Loss at Epoch 498 is : netwok_nn.tensor(87.19018969998687 , grad = 1.0)\n",
      "Loss at Epoch 499 is : netwok_nn.tensor(87.02077099454958 , grad = 1.0)\n",
      "Loss at Epoch 500 is : netwok_nn.tensor(86.85154918445772 , grad = 1.0)\n",
      "Loss at Epoch 501 is : netwok_nn.tensor(86.68252420289406 , grad = 1.0)\n",
      "Loss at Epoch 502 is : netwok_nn.tensor(86.5136959827897 , grad = 1.0)\n",
      "Loss at Epoch 503 is : netwok_nn.tensor(86.34506445682659 , grad = 1.0)\n",
      "Loss at Epoch 504 is : netwok_nn.tensor(86.17662955743967 , grad = 1.0)\n",
      "Loss at Epoch 505 is : netwok_nn.tensor(86.00839121681918 , grad = 1.0)\n",
      "Loss at Epoch 506 is : netwok_nn.tensor(85.84034936691292 , grad = 1.0)\n",
      "Loss at Epoch 507 is : netwok_nn.tensor(85.67250393942851 , grad = 1.0)\n",
      "Loss at Epoch 508 is : netwok_nn.tensor(85.50485486583553 , grad = 1.0)\n",
      "Loss at Epoch 509 is : netwok_nn.tensor(85.3374020773677 , grad = 1.0)\n",
      "Loss at Epoch 510 is : netwok_nn.tensor(85.17014550502512 , grad = 1.0)\n",
      "Loss at Epoch 511 is : netwok_nn.tensor(85.00308507957631 , grad = 1.0)\n",
      "Loss at Epoch 512 is : netwok_nn.tensor(84.83622073156045 , grad = 1.0)\n",
      "Loss at Epoch 513 is : netwok_nn.tensor(84.66955239128936 , grad = 1.0)\n",
      "Loss at Epoch 514 is : netwok_nn.tensor(84.50307998884963 , grad = 1.0)\n",
      "Loss at Epoch 515 is : netwok_nn.tensor(84.33680345410468 , grad = 1.0)\n",
      "Loss at Epoch 516 is : netwok_nn.tensor(84.17072271669676 , grad = 1.0)\n",
      "Loss at Epoch 517 is : netwok_nn.tensor(84.00483770604907 , grad = 1.0)\n",
      "Loss at Epoch 518 is : netwok_nn.tensor(83.8391483513676 , grad = 1.0)\n",
      "Loss at Epoch 519 is : netwok_nn.tensor(83.67365458164322 , grad = 1.0)\n",
      "Loss at Epoch 520 is : netwok_nn.tensor(83.50835632565366 , grad = 1.0)\n",
      "Loss at Epoch 521 is : netwok_nn.tensor(83.34325351196532 , grad = 1.0)\n",
      "Loss at Epoch 522 is : netwok_nn.tensor(83.17834606893535 , grad = 1.0)\n",
      "Loss at Epoch 523 is : netwok_nn.tensor(83.01363392471342 , grad = 1.0)\n",
      "Loss at Epoch 524 is : netwok_nn.tensor(82.84911700724366 , grad = 1.0)\n",
      "Loss at Epoch 525 is : netwok_nn.tensor(82.68479524426658 , grad = 1.0)\n",
      "Loss at Epoch 526 is : netwok_nn.tensor(82.52066856332081 , grad = 1.0)\n",
      "Loss at Epoch 527 is : netwok_nn.tensor(82.356736891745 , grad = 1.0)\n",
      "Loss at Epoch 528 is : netwok_nn.tensor(82.19300015667966 , grad = 1.0)\n",
      "Loss at Epoch 529 is : netwok_nn.tensor(82.02945828506886 , grad = 1.0)\n",
      "Loss at Epoch 530 is : netwok_nn.tensor(81.86611120366204 , grad = 1.0)\n",
      "Loss at Epoch 531 is : netwok_nn.tensor(81.70295883901588 , grad = 1.0)\n",
      "Loss at Epoch 532 is : netwok_nn.tensor(81.5400011174959 , grad = 1.0)\n",
      "Loss at Epoch 533 is : netwok_nn.tensor(81.37723796527825 , grad = 1.0)\n",
      "Loss at Epoch 534 is : netwok_nn.tensor(81.21466930835147 , grad = 1.0)\n",
      "Loss at Epoch 535 is : netwok_nn.tensor(81.05229507251809 , grad = 1.0)\n",
      "Loss at Epoch 536 is : netwok_nn.tensor(80.89011518339636 , grad = 1.0)\n",
      "Loss at Epoch 537 is : netwok_nn.tensor(80.7281295664219 , grad = 1.0)\n",
      "Loss at Epoch 538 is : netwok_nn.tensor(80.56633814684942 , grad = 1.0)\n",
      "Loss at Epoch 539 is : netwok_nn.tensor(80.40474084975422 , grad = 1.0)\n",
      "Loss at Epoch 540 is : netwok_nn.tensor(80.24333760003391 , grad = 1.0)\n",
      "Loss at Epoch 541 is : netwok_nn.tensor(80.08212832240999 , grad = 1.0)\n",
      "Loss at Epoch 542 is : netwok_nn.tensor(79.92111294142941 , grad = 1.0)\n",
      "Loss at Epoch 543 is : netwok_nn.tensor(79.76029138146617 , grad = 1.0)\n",
      "Loss at Epoch 544 is : netwok_nn.tensor(79.59966356672288 , grad = 1.0)\n",
      "Loss at Epoch 545 is : netwok_nn.tensor(79.43922942123227 , grad = 1.0)\n",
      "Loss at Epoch 546 is : netwok_nn.tensor(79.27898886885878 , grad = 1.0)\n",
      "Loss at Epoch 547 is : netwok_nn.tensor(79.11894183329996 , grad = 1.0)\n",
      "Loss at Epoch 548 is : netwok_nn.tensor(78.95908823808814 , grad = 1.0)\n",
      "Loss at Epoch 549 is : netwok_nn.tensor(78.79942800659178 , grad = 1.0)\n",
      "Loss at Epoch 550 is : netwok_nn.tensor(78.63996106201698 , grad = 1.0)\n",
      "Loss at Epoch 551 is : netwok_nn.tensor(78.48068732740897 , grad = 1.0)\n",
      "Loss at Epoch 552 is : netwok_nn.tensor(78.32160672565351 , grad = 1.0)\n",
      "Loss at Epoch 553 is : netwok_nn.tensor(78.16271917947836 , grad = 1.0)\n",
      "Loss at Epoch 554 is : netwok_nn.tensor(78.00402461145467 , grad = 1.0)\n",
      "Loss at Epoch 555 is : netwok_nn.tensor(77.84552294399842 , grad = 1.0)\n",
      "Loss at Epoch 556 is : netwok_nn.tensor(77.68721409937183 , grad = 1.0)\n",
      "Loss at Epoch 557 is : netwok_nn.tensor(77.5290979996846 , grad = 1.0)\n",
      "Loss at Epoch 558 is : netwok_nn.tensor(77.37117456689548 , grad = 1.0)\n",
      "Loss at Epoch 559 is : netwok_nn.tensor(77.21344372281351 , grad = 1.0)\n",
      "Loss at Epoch 560 is : netwok_nn.tensor(77.05590538909937 , grad = 1.0)\n",
      "Loss at Epoch 561 is : netwok_nn.tensor(76.89855948726671 , grad = 1.0)\n",
      "Loss at Epoch 562 is : netwok_nn.tensor(76.74140593868354 , grad = 1.0)\n",
      "Loss at Epoch 563 is : netwok_nn.tensor(76.58444466457344 , grad = 1.0)\n",
      "Loss at Epoch 564 is : netwok_nn.tensor(76.42767558601686 , grad = 1.0)\n",
      "Loss at Epoch 565 is : netwok_nn.tensor(76.27109862395257 , grad = 1.0)\n",
      "Loss at Epoch 566 is : netwok_nn.tensor(76.11471369917864 , grad = 1.0)\n",
      "Loss at Epoch 567 is : netwok_nn.tensor(75.95852073235397 , grad = 1.0)\n",
      "Loss at Epoch 568 is : netwok_nn.tensor(75.8025196439994 , grad = 1.0)\n",
      "Loss at Epoch 569 is : netwok_nn.tensor(75.64671035449899 , grad = 1.0)\n",
      "Loss at Epoch 570 is : netwok_nn.tensor(75.49109278410121 , grad = 1.0)\n",
      "Loss at Epoch 571 is : netwok_nn.tensor(75.33566685292023 , grad = 1.0)\n",
      "Loss at Epoch 572 is : netwok_nn.tensor(75.18043248093701 , grad = 1.0)\n",
      "Loss at Epoch 573 is : netwok_nn.tensor(75.02538958800062 , grad = 1.0)\n",
      "Loss at Epoch 574 is : netwok_nn.tensor(74.87053809382935 , grad = 1.0)\n",
      "Loss at Epoch 575 is : netwok_nn.tensor(74.71587791801193 , grad = 1.0)\n",
      "Loss at Epoch 576 is : netwok_nn.tensor(74.56140898000855 , grad = 1.0)\n",
      "Loss at Epoch 577 is : netwok_nn.tensor(74.40713119915223 , grad = 1.0)\n",
      "Loss at Epoch 578 is : netwok_nn.tensor(74.25304449464981 , grad = 1.0)\n",
      "Loss at Epoch 579 is : netwok_nn.tensor(74.09914878558317 , grad = 1.0)\n",
      "Loss at Epoch 580 is : netwok_nn.tensor(73.94544399091025 , grad = 1.0)\n",
      "Loss at Epoch 581 is : netwok_nn.tensor(73.7919300294662 , grad = 1.0)\n",
      "Loss at Epoch 582 is : netwok_nn.tensor(73.63860681996461 , grad = 1.0)\n",
      "Loss at Epoch 583 is : netwok_nn.tensor(73.4854742809984 , grad = 1.0)\n",
      "Loss at Epoch 584 is : netwok_nn.tensor(73.33253233104102 , grad = 1.0)\n",
      "Loss at Epoch 585 is : netwok_nn.tensor(73.17978088844751 , grad = 1.0)\n",
      "Loss at Epoch 586 is : netwok_nn.tensor(73.02721987145553 , grad = 1.0)\n",
      "Loss at Epoch 587 is : netwok_nn.tensor(72.87484919818644 , grad = 1.0)\n",
      "Loss at Epoch 588 is : netwok_nn.tensor(72.72266878664637 , grad = 1.0)\n",
      "Loss at Epoch 589 is : netwok_nn.tensor(72.57067855472718 , grad = 1.0)\n",
      "Loss at Epoch 590 is : netwok_nn.tensor(72.41887842020759 , grad = 1.0)\n",
      "Loss at Epoch 591 is : netwok_nn.tensor(72.2672683007541 , grad = 1.0)\n",
      "Loss at Epoch 592 is : netwok_nn.tensor(72.11584811392204 , grad = 1.0)\n",
      "Loss at Epoch 593 is : netwok_nn.tensor(71.96461777715662 , grad = 1.0)\n",
      "Loss at Epoch 594 is : netwok_nn.tensor(71.81357720779378 , grad = 1.0)\n",
      "Loss at Epoch 595 is : netwok_nn.tensor(71.66272632306135 , grad = 1.0)\n",
      "Loss at Epoch 596 is : netwok_nn.tensor(71.5120650400799 , grad = 1.0)\n",
      "Loss at Epoch 597 is : netwok_nn.tensor(71.36159327586373 , grad = 1.0)\n",
      "Loss at Epoch 598 is : netwok_nn.tensor(71.21131094732188 , grad = 1.0)\n",
      "Loss at Epoch 599 is : netwok_nn.tensor(71.06121797125901 , grad = 1.0)\n",
      "Loss at Epoch 600 is : netwok_nn.tensor(70.91131426437637 , grad = 1.0)\n",
      "Loss at Epoch 601 is : netwok_nn.tensor(70.76159974327275 , grad = 1.0)\n",
      "Loss at Epoch 602 is : netwok_nn.tensor(70.6120743244454 , grad = 1.0)\n",
      "Loss at Epoch 603 is : netwok_nn.tensor(70.46273792429089 , grad = 1.0)\n",
      "Loss at Epoch 604 is : netwok_nn.tensor(70.31359045910612 , grad = 1.0)\n",
      "Loss at Epoch 605 is : netwok_nn.tensor(70.16463184508908 , grad = 1.0)\n",
      "Loss at Epoch 606 is : netwok_nn.tensor(70.01586199833994 , grad = 1.0)\n",
      "Loss at Epoch 607 is : netwok_nn.tensor(69.86728083486173 , grad = 1.0)\n",
      "Loss at Epoch 608 is : netwok_nn.tensor(69.71888827056138 , grad = 1.0)\n",
      "Loss at Epoch 609 is : netwok_nn.tensor(69.57068422125045 , grad = 1.0)\n",
      "Loss at Epoch 610 is : netwok_nn.tensor(69.42266860264611 , grad = 1.0)\n",
      "Loss at Epoch 611 is : netwok_nn.tensor(69.27484133037194 , grad = 1.0)\n",
      "Loss at Epoch 612 is : netwok_nn.tensor(69.12720231995878 , grad = 1.0)\n",
      "Loss at Epoch 613 is : netwok_nn.tensor(68.97975148684563 , grad = 1.0)\n",
      "Loss at Epoch 614 is : netwok_nn.tensor(68.83248874638038 , grad = 1.0)\n",
      "Loss at Epoch 615 is : netwok_nn.tensor(68.68541401382068 , grad = 1.0)\n",
      "Loss at Epoch 616 is : netwok_nn.tensor(68.53852720433478 , grad = 1.0)\n",
      "Loss at Epoch 617 is : netwok_nn.tensor(68.39182823300237 , grad = 1.0)\n",
      "Loss at Epoch 618 is : netwok_nn.tensor(68.24531701481533 , grad = 1.0)\n",
      "Loss at Epoch 619 is : netwok_nn.tensor(68.09899346467851 , grad = 1.0)\n",
      "Loss at Epoch 620 is : netwok_nn.tensor(67.95285749741059 , grad = 1.0)\n",
      "Loss at Epoch 621 is : netwok_nn.tensor(67.80690902774488 , grad = 1.0)\n",
      "Loss at Epoch 622 is : netwok_nn.tensor(67.66114797032996 , grad = 1.0)\n",
      "Loss at Epoch 623 is : netwok_nn.tensor(67.51557423973061 , grad = 1.0)\n",
      "Loss at Epoch 624 is : netwok_nn.tensor(67.3701877504285 , grad = 1.0)\n",
      "Loss at Epoch 625 is : netwok_nn.tensor(67.22498841682294 , grad = 1.0)\n",
      "Loss at Epoch 626 is : netwok_nn.tensor(67.07997615323171 , grad = 1.0)\n",
      "Loss at Epoch 627 is : netwok_nn.tensor(66.93515087389173 , grad = 1.0)\n",
      "Loss at Epoch 628 is : netwok_nn.tensor(66.79051249295972 , grad = 1.0)\n",
      "Loss at Epoch 629 is : netwok_nn.tensor(66.64606092451324 , grad = 1.0)\n",
      "Loss at Epoch 630 is : netwok_nn.tensor(66.501796082551 , grad = 1.0)\n",
      "Loss at Epoch 631 is : netwok_nn.tensor(66.35771788099397 , grad = 1.0)\n",
      "Loss at Epoch 632 is : netwok_nn.tensor(66.21382623368582 , grad = 1.0)\n",
      "Loss at Epoch 633 is : netwok_nn.tensor(66.07012105439375 , grad = 1.0)\n",
      "Loss at Epoch 634 is : netwok_nn.tensor(65.92660225680922 , grad = 1.0)\n",
      "Loss at Epoch 635 is : netwok_nn.tensor(65.78326975454854 , grad = 1.0)\n",
      "Loss at Epoch 636 is : netwok_nn.tensor(65.64012346115369 , grad = 1.0)\n",
      "Loss at Epoch 637 is : netwok_nn.tensor(65.4971632900929 , grad = 1.0)\n",
      "Loss at Epoch 638 is : netwok_nn.tensor(65.35438915476135 , grad = 1.0)\n",
      "Loss at Epoch 639 is : netwok_nn.tensor(65.21180096848201 , grad = 1.0)\n",
      "Loss at Epoch 640 is : netwok_nn.tensor(65.069398644506 , grad = 1.0)\n",
      "Loss at Epoch 641 is : netwok_nn.tensor(64.92718209601345 , grad = 1.0)\n",
      "Loss at Epoch 642 is : netwok_nn.tensor(64.78515123611425 , grad = 1.0)\n",
      "Loss at Epoch 643 is : netwok_nn.tensor(64.64330597784848 , grad = 1.0)\n",
      "Loss at Epoch 644 is : netwok_nn.tensor(64.50164623418719 , grad = 1.0)\n",
      "Loss at Epoch 645 is : netwok_nn.tensor(64.36017191803302 , grad = 1.0)\n",
      "Loss at Epoch 646 is : netwok_nn.tensor(64.21888294222082 , grad = 1.0)\n",
      "Loss at Epoch 647 is : netwok_nn.tensor(64.0777792195183 , grad = 1.0)\n",
      "Loss at Epoch 648 is : netwok_nn.tensor(63.93686066262669 , grad = 1.0)\n",
      "Loss at Epoch 649 is : netwok_nn.tensor(63.796127184181245 , grad = 1.0)\n",
      "Loss at Epoch 650 is : netwok_nn.tensor(63.65557869675199 , grad = 1.0)\n",
      "Loss at Epoch 651 is : netwok_nn.tensor(63.51521511284429 , grad = 1.0)\n",
      "Loss at Epoch 652 is : netwok_nn.tensor(63.37503634489938 , grad = 1.0)\n",
      "Loss at Epoch 653 is : netwok_nn.tensor(63.23504230529512 , grad = 1.0)\n",
      "Loss at Epoch 654 is : netwok_nn.tensor(63.095232906346425 , grad = 1.0)\n",
      "Loss at Epoch 655 is : netwok_nn.tensor(62.95560806030599 , grad = 1.0)\n",
      "Loss at Epoch 656 is : netwok_nn.tensor(62.816167679364796 , grad = 1.0)\n",
      "Loss at Epoch 657 is : netwok_nn.tensor(62.67691167565275 , grad = 1.0)\n",
      "Loss at Epoch 658 is : netwok_nn.tensor(62.53783996123912 , grad = 1.0)\n",
      "Loss at Epoch 659 is : netwok_nn.tensor(62.39895244813339 , grad = 1.0)\n",
      "Loss at Epoch 660 is : netwok_nn.tensor(62.260249048285495 , grad = 1.0)\n",
      "Loss at Epoch 661 is : netwok_nn.tensor(62.12172967358664 , grad = 1.0)\n",
      "Loss at Epoch 662 is : netwok_nn.tensor(61.983394235869724 , grad = 1.0)\n",
      "Loss at Epoch 663 is : netwok_nn.tensor(61.84524264690994 , grad = 1.0)\n",
      "Loss at Epoch 664 is : netwok_nn.tensor(61.7072748184253 , grad = 1.0)\n",
      "Loss at Epoch 665 is : netwok_nn.tensor(61.56949066207719 , grad = 1.0)\n",
      "Loss at Epoch 666 is : netwok_nn.tensor(61.43189008947097 , grad = 1.0)\n",
      "Loss at Epoch 667 is : netwok_nn.tensor(61.29447301215642 , grad = 1.0)\n",
      "Loss at Epoch 668 is : netwok_nn.tensor(61.15723934162826 , grad = 1.0)\n",
      "Loss at Epoch 669 is : netwok_nn.tensor(61.02018898932682 , grad = 1.0)\n",
      "Loss at Epoch 670 is : netwok_nn.tensor(60.88332186663838 , grad = 1.0)\n",
      "Loss at Epoch 671 is : netwok_nn.tensor(60.74663788489581 , grad = 1.0)\n",
      "Loss at Epoch 672 is : netwok_nn.tensor(60.61013695537911 , grad = 1.0)\n",
      "Loss at Epoch 673 is : netwok_nn.tensor(60.47381898931577 , grad = 1.0)\n",
      "Loss at Epoch 674 is : netwok_nn.tensor(60.3376838978814 , grad = 1.0)\n",
      "Loss at Epoch 675 is : netwok_nn.tensor(60.201731592200204 , grad = 1.0)\n",
      "Loss at Epoch 676 is : netwok_nn.tensor(60.06596198334549 , grad = 1.0)\n",
      "Loss at Epoch 677 is : netwok_nn.tensor(59.930374982340126 , grad = 1.0)\n",
      "Loss at Epoch 678 is : netwok_nn.tensor(59.79497050015708 , grad = 1.0)\n",
      "Loss at Epoch 679 is : netwok_nn.tensor(59.65974844771982 , grad = 1.0)\n",
      "Loss at Epoch 680 is : netwok_nn.tensor(59.52470873590292 , grad = 1.0)\n",
      "Loss at Epoch 681 is : netwok_nn.tensor(59.38985127553246 , grad = 1.0)\n",
      "Loss at Epoch 682 is : netwok_nn.tensor(59.25517597738648 , grad = 1.0)\n",
      "Loss at Epoch 683 is : netwok_nn.tensor(59.12068275219554 , grad = 1.0)\n",
      "Loss at Epoch 684 is : netwok_nn.tensor(58.98637151064307 , grad = 1.0)\n",
      "Loss at Epoch 685 is : netwok_nn.tensor(58.852242163365915 , grad = 1.0)\n",
      "Loss at Epoch 686 is : netwok_nn.tensor(58.718294620954836 , grad = 1.0)\n",
      "Loss at Epoch 687 is : netwok_nn.tensor(58.584528793954824 , grad = 1.0)\n",
      "Loss at Epoch 688 is : netwok_nn.tensor(58.450944592865625 , grad = 1.0)\n",
      "Loss at Epoch 689 is : netwok_nn.tensor(58.31754192814228 , grad = 1.0)\n",
      "Loss at Epoch 690 is : netwok_nn.tensor(58.18432071019542 , grad = 1.0)\n",
      "Loss at Epoch 691 is : netwok_nn.tensor(58.051280849391794 , grad = 1.0)\n",
      "Loss at Epoch 692 is : netwok_nn.tensor(57.91842225605469 , grad = 1.0)\n",
      "Loss at Epoch 693 is : netwok_nn.tensor(57.785744840464346 , grad = 1.0)\n",
      "Loss at Epoch 694 is : netwok_nn.tensor(57.65324851285845 , grad = 1.0)\n",
      "Loss at Epoch 695 is : netwok_nn.tensor(57.52093318343238 , grad = 1.0)\n",
      "Loss at Epoch 696 is : netwok_nn.tensor(57.388798762339974 , grad = 1.0)\n",
      "Loss at Epoch 697 is : netwok_nn.tensor(57.256845159693576 , grad = 1.0)\n",
      "Loss at Epoch 698 is : netwok_nn.tensor(57.12507228556472 , grad = 1.0)\n",
      "Loss at Epoch 699 is : netwok_nn.tensor(56.993480049984356 , grad = 1.0)\n",
      "Loss at Epoch 700 is : netwok_nn.tensor(56.86206836294341 , grad = 1.0)\n",
      "Loss at Epoch 701 is : netwok_nn.tensor(56.73083713439312 , grad = 1.0)\n",
      "Loss at Epoch 702 is : netwok_nn.tensor(56.59978627424542 , grad = 1.0)\n",
      "Loss at Epoch 703 is : netwok_nn.tensor(56.468915692373365 , grad = 1.0)\n",
      "Loss at Epoch 704 is : netwok_nn.tensor(56.338225298611626 , grad = 1.0)\n",
      "Loss at Epoch 705 is : netwok_nn.tensor(56.20771500275668 , grad = 1.0)\n",
      "Loss at Epoch 706 is : netwok_nn.tensor(56.077384714567344 , grad = 1.0)\n",
      "Loss at Epoch 707 is : netwok_nn.tensor(55.94723434376516 , grad = 1.0)\n",
      "Loss at Epoch 708 is : netwok_nn.tensor(55.81726380003476 , grad = 1.0)\n",
      "Loss at Epoch 709 is : netwok_nn.tensor(55.6874729930242 , grad = 1.0)\n",
      "Loss at Epoch 710 is : netwok_nn.tensor(55.55786183234539 , grad = 1.0)\n",
      "Loss at Epoch 711 is : netwok_nn.tensor(55.428430227574474 , grad = 1.0)\n",
      "Loss at Epoch 712 is : netwok_nn.tensor(55.29917808825218 , grad = 1.0)\n",
      "Loss at Epoch 713 is : netwok_nn.tensor(55.170105323884194 , grad = 1.0)\n",
      "Loss at Epoch 714 is : netwok_nn.tensor(55.04121184394154 , grad = 1.0)\n",
      "Loss at Epoch 715 is : netwok_nn.tensor(54.912497557860945 , grad = 1.0)\n",
      "Loss at Epoch 716 is : netwok_nn.tensor(54.783962375045164 , grad = 1.0)\n",
      "Loss at Epoch 717 is : netwok_nn.tensor(54.6556062048634 , grad = 1.0)\n",
      "Loss at Epoch 718 is : netwok_nn.tensor(54.52742895665159 , grad = 1.0)\n",
      "Loss at Epoch 719 is : netwok_nn.tensor(54.39943053971281 , grad = 1.0)\n",
      "Loss at Epoch 720 is : netwok_nn.tensor(54.27161086331759 , grad = 1.0)\n",
      "Loss at Epoch 721 is : netwok_nn.tensor(54.143969836704336 , grad = 1.0)\n",
      "Loss at Epoch 722 is : netwok_nn.tensor(54.016507369079555 , grad = 1.0)\n",
      "Loss at Epoch 723 is : netwok_nn.tensor(53.88922336961828 , grad = 1.0)\n",
      "Loss at Epoch 724 is : netwok_nn.tensor(53.76211774746438 , grad = 1.0)\n",
      "Loss at Epoch 725 is : netwok_nn.tensor(53.635190411730925 , grad = 1.0)\n",
      "Loss at Epoch 726 is : netwok_nn.tensor(53.508441271500466 , grad = 1.0)\n",
      "Loss at Epoch 727 is : netwok_nn.tensor(53.38187023582548 , grad = 1.0)\n",
      "Loss at Epoch 728 is : netwok_nn.tensor(53.25547721372852 , grad = 1.0)\n",
      "Loss at Epoch 729 is : netwok_nn.tensor(53.129262114202646 , grad = 1.0)\n",
      "Loss at Epoch 730 is : netwok_nn.tensor(53.00322484621179 , grad = 1.0)\n",
      "Loss at Epoch 731 is : netwok_nn.tensor(52.87736531869105 , grad = 1.0)\n",
      "Loss at Epoch 732 is : netwok_nn.tensor(52.751683440546884 , grad = 1.0)\n",
      "Loss at Epoch 733 is : netwok_nn.tensor(52.62617912065762 , grad = 1.0)\n",
      "Loss at Epoch 734 is : netwok_nn.tensor(52.500852267873626 , grad = 1.0)\n",
      "Loss at Epoch 735 is : netwok_nn.tensor(52.37570279101767 , grad = 1.0)\n",
      "Loss at Epoch 736 is : netwok_nn.tensor(52.25073059888528 , grad = 1.0)\n",
      "Loss at Epoch 737 is : netwok_nn.tensor(52.12593560024493 , grad = 1.0)\n",
      "Loss at Epoch 738 is : netwok_nn.tensor(52.00131770383845 , grad = 1.0)\n",
      "Loss at Epoch 739 is : netwok_nn.tensor(51.87687681838127 , grad = 1.0)\n",
      "Loss at Epoch 740 is : netwok_nn.tensor(51.75261285256276 , grad = 1.0)\n",
      "Loss at Epoch 741 is : netwok_nn.tensor(51.62852571504649 , grad = 1.0)\n",
      "Loss at Epoch 742 is : netwok_nn.tensor(51.50461531447054 , grad = 1.0)\n",
      "Loss at Epoch 743 is : netwok_nn.tensor(51.380881559447765 , grad = 1.0)\n",
      "Loss at Epoch 744 is : netwok_nn.tensor(51.25732435856614 , grad = 1.0)\n",
      "Loss at Epoch 745 is : netwok_nn.tensor(51.13394362038898 , grad = 1.0)\n",
      "Loss at Epoch 746 is : netwok_nn.tensor(51.01073925345531 , grad = 1.0)\n",
      "Loss at Epoch 747 is : netwok_nn.tensor(50.88771116628004 , grad = 1.0)\n",
      "Loss at Epoch 748 is : netwok_nn.tensor(50.764859267354325 , grad = 1.0)\n",
      "Loss at Epoch 749 is : netwok_nn.tensor(50.64218346514583 , grad = 1.0)\n",
      "Loss at Epoch 750 is : netwok_nn.tensor(50.51968366809898 , grad = 1.0)\n",
      "Loss at Epoch 751 is : netwok_nn.tensor(50.397359784635235 , grad = 1.0)\n",
      "Loss at Epoch 752 is : netwok_nn.tensor(50.27521172315342 , grad = 1.0)\n",
      "Loss at Epoch 753 is : netwok_nn.tensor(50.15323939202989 , grad = 1.0)\n",
      "Loss at Epoch 754 is : netwok_nn.tensor(50.03144269961889 , grad = 1.0)\n",
      "Loss at Epoch 755 is : netwok_nn.tensor(49.9098215542528 , grad = 1.0)\n",
      "Loss at Epoch 756 is : netwok_nn.tensor(49.788375864242326 , grad = 1.0)\n",
      "Loss at Epoch 757 is : netwok_nn.tensor(49.667105537876886 , grad = 1.0)\n",
      "Loss at Epoch 758 is : netwok_nn.tensor(49.54601048342475 , grad = 1.0)\n",
      "Loss at Epoch 759 is : netwok_nn.tensor(49.42509060913338 , grad = 1.0)\n",
      "Loss at Epoch 760 is : netwok_nn.tensor(49.30434582322963 , grad = 1.0)\n",
      "Loss at Epoch 761 is : netwok_nn.tensor(49.18377603392004 , grad = 1.0)\n",
      "Loss at Epoch 762 is : netwok_nn.tensor(49.063381149391034 , grad = 1.0)\n",
      "Loss at Epoch 763 is : netwok_nn.tensor(48.943161077809215 , grad = 1.0)\n",
      "Loss at Epoch 764 is : netwok_nn.tensor(48.823115727321635 , grad = 1.0)\n",
      "Loss at Epoch 765 is : netwok_nn.tensor(48.70324500605599 , grad = 1.0)\n",
      "Loss at Epoch 766 is : netwok_nn.tensor(48.583548822120804 , grad = 1.0)\n",
      "Loss at Epoch 767 is : netwok_nn.tensor(48.46402708360584 , grad = 1.0)\n",
      "Loss at Epoch 768 is : netwok_nn.tensor(48.344679698582155 , grad = 1.0)\n",
      "Loss at Epoch 769 is : netwok_nn.tensor(48.2255065751025 , grad = 1.0)\n",
      "Loss at Epoch 770 is : netwok_nn.tensor(48.106507621201416 , grad = 1.0)\n",
      "Loss at Epoch 771 is : netwok_nn.tensor(47.987682744895594 , grad = 1.0)\n",
      "Loss at Epoch 772 is : netwok_nn.tensor(47.86903185418395 , grad = 1.0)\n",
      "Loss at Epoch 773 is : netwok_nn.tensor(47.750554857047995 , grad = 1.0)\n",
      "Loss at Epoch 774 is : netwok_nn.tensor(47.632251661452045 , grad = 1.0)\n",
      "Loss at Epoch 775 is : netwok_nn.tensor(47.51412217534337 , grad = 1.0)\n",
      "Loss at Epoch 776 is : netwok_nn.tensor(47.39616630665243 , grad = 1.0)\n",
      "Loss at Epoch 777 is : netwok_nn.tensor(47.27838396329324 , grad = 1.0)\n",
      "Loss at Epoch 778 is : netwok_nn.tensor(47.16077505316336 , grad = 1.0)\n",
      "Loss at Epoch 779 is : netwok_nn.tensor(47.043339484144326 , grad = 1.0)\n",
      "Loss at Epoch 780 is : netwok_nn.tensor(46.92607716410171 , grad = 1.0)\n",
      "Loss at Epoch 781 is : netwok_nn.tensor(46.808988000885456 , grad = 1.0)\n",
      "Loss at Epoch 782 is : netwok_nn.tensor(46.692071902329964 , grad = 1.0)\n",
      "Loss at Epoch 783 is : netwok_nn.tensor(46.57532877625445 , grad = 1.0)\n",
      "Loss at Epoch 784 is : netwok_nn.tensor(46.45875853046306 , grad = 1.0)\n",
      "Loss at Epoch 785 is : netwok_nn.tensor(46.34236107274507 , grad = 1.0)\n",
      "Loss at Epoch 786 is : netwok_nn.tensor(46.226136310875155 , grad = 1.0)\n",
      "Loss at Epoch 787 is : netwok_nn.tensor(46.110084152613574 , grad = 1.0)\n",
      "Loss at Epoch 788 is : netwok_nn.tensor(45.994204505706286 , grad = 1.0)\n",
      "Loss at Epoch 789 is : netwok_nn.tensor(45.878497277885316 , grad = 1.0)\n",
      "Loss at Epoch 790 is : netwok_nn.tensor(45.76296237686884 , grad = 1.0)\n",
      "Loss at Epoch 791 is : netwok_nn.tensor(45.64759971036138 , grad = 1.0)\n",
      "Loss at Epoch 792 is : netwok_nn.tensor(45.53240918605408 , grad = 1.0)\n",
      "Loss at Epoch 793 is : netwok_nn.tensor(45.417390711624805 , grad = 1.0)\n",
      "Loss at Epoch 794 is : netwok_nn.tensor(45.3025441947384 , grad = 1.0)\n",
      "Loss at Epoch 795 is : netwok_nn.tensor(45.18786954304688 , grad = 1.0)\n",
      "Loss at Epoch 796 is : netwok_nn.tensor(45.07336666418958 , grad = 1.0)\n",
      "Loss at Epoch 797 is : netwok_nn.tensor(44.95903546579339 , grad = 1.0)\n",
      "Loss at Epoch 798 is : netwok_nn.tensor(44.844875855472935 , grad = 1.0)\n",
      "Loss at Epoch 799 is : netwok_nn.tensor(44.73088774083071 , grad = 1.0)\n",
      "Loss at Epoch 800 is : netwok_nn.tensor(44.61707102945732 , grad = 1.0)\n",
      "Loss at Epoch 801 is : netwok_nn.tensor(44.503425628931645 , grad = 1.0)\n",
      "Loss at Epoch 802 is : netwok_nn.tensor(44.38995144682103 , grad = 1.0)\n",
      "Loss at Epoch 803 is : netwok_nn.tensor(44.276648390681494 , grad = 1.0)\n",
      "Loss at Epoch 804 is : netwok_nn.tensor(44.16351636805777 , grad = 1.0)\n",
      "Loss at Epoch 805 is : netwok_nn.tensor(44.05055528648371 , grad = 1.0)\n",
      "Loss at Epoch 806 is : netwok_nn.tensor(43.937765053482224 , grad = 1.0)\n",
      "Loss at Epoch 807 is : netwok_nn.tensor(43.82514557656565 , grad = 1.0)\n",
      "Loss at Epoch 808 is : netwok_nn.tensor(43.71269676323581 , grad = 1.0)\n",
      "Loss at Epoch 809 is : netwok_nn.tensor(43.600418520984206 , grad = 1.0)\n",
      "Loss at Epoch 810 is : netwok_nn.tensor(43.48831075729222 , grad = 1.0)\n",
      "Loss at Epoch 811 is : netwok_nn.tensor(43.37637337963124 , grad = 1.0)\n",
      "Loss at Epoch 812 is : netwok_nn.tensor(43.26460629546288 , grad = 1.0)\n",
      "Loss at Epoch 813 is : netwok_nn.tensor(43.15300941223911 , grad = 1.0)\n",
      "Loss at Epoch 814 is : netwok_nn.tensor(43.04158263740238 , grad = 1.0)\n",
      "Loss at Epoch 815 is : netwok_nn.tensor(42.930325878385894 , grad = 1.0)\n",
      "Loss at Epoch 816 is : netwok_nn.tensor(42.819239042613646 , grad = 1.0)\n",
      "Loss at Epoch 817 is : netwok_nn.tensor(42.70832203750072 , grad = 1.0)\n",
      "Loss at Epoch 818 is : netwok_nn.tensor(42.597574770453285 , grad = 1.0)\n",
      "Loss at Epoch 819 is : netwok_nn.tensor(42.486997148868916 , grad = 1.0)\n",
      "Loss at Epoch 820 is : netwok_nn.tensor(42.3765890801366 , grad = 1.0)\n",
      "Loss at Epoch 821 is : netwok_nn.tensor(42.26635047163706 , grad = 1.0)\n",
      "Loss at Epoch 822 is : netwok_nn.tensor(42.156281230742735 , grad = 1.0)\n",
      "Loss at Epoch 823 is : netwok_nn.tensor(42.046381264818066 , grad = 1.0)\n",
      "Loss at Epoch 824 is : netwok_nn.tensor(41.93665048121953 , grad = 1.0)\n",
      "Loss at Epoch 825 is : netwok_nn.tensor(41.82708878729593 , grad = 1.0)\n",
      "Loss at Epoch 826 is : netwok_nn.tensor(41.717696090388415 , grad = 1.0)\n",
      "Loss at Epoch 827 is : netwok_nn.tensor(41.60847229783072 , grad = 1.0)\n",
      "Loss at Epoch 828 is : netwok_nn.tensor(41.49941731694924 , grad = 1.0)\n",
      "Loss at Epoch 829 is : netwok_nn.tensor(41.39053105506326 , grad = 1.0)\n",
      "Loss at Epoch 830 is : netwok_nn.tensor(41.281813419485005 , grad = 1.0)\n",
      "Loss at Epoch 831 is : netwok_nn.tensor(41.173264317519845 , grad = 1.0)\n",
      "Loss at Epoch 832 is : netwok_nn.tensor(41.06488365646641 , grad = 1.0)\n",
      "Loss at Epoch 833 is : netwok_nn.tensor(40.956671343616755 , grad = 1.0)\n",
      "Loss at Epoch 834 is : netwok_nn.tensor(40.84862728625648 , grad = 1.0)\n",
      "Loss at Epoch 835 is : netwok_nn.tensor(40.74075139166489 , grad = 1.0)\n",
      "Loss at Epoch 836 is : netwok_nn.tensor(40.63304356711507 , grad = 1.0)\n",
      "Loss at Epoch 837 is : netwok_nn.tensor(40.525503719874116 , grad = 1.0)\n",
      "Loss at Epoch 838 is : netwok_nn.tensor(40.4181317572032 , grad = 1.0)\n",
      "Loss at Epoch 839 is : netwok_nn.tensor(40.310927586357735 , grad = 1.0)\n",
      "Loss at Epoch 840 is : netwok_nn.tensor(40.20389111458747 , grad = 1.0)\n",
      "Loss at Epoch 841 is : netwok_nn.tensor(40.09702224913668 , grad = 1.0)\n",
      "Loss at Epoch 842 is : netwok_nn.tensor(39.990320897244246 , grad = 1.0)\n",
      "Loss at Epoch 843 is : netwok_nn.tensor(39.88378696614382 , grad = 1.0)\n",
      "Loss at Epoch 844 is : netwok_nn.tensor(39.77742036306393 , grad = 1.0)\n",
      "Loss at Epoch 845 is : netwok_nn.tensor(39.67122099522811 , grad = 1.0)\n",
      "Loss at Epoch 846 is : netwok_nn.tensor(39.56518876985501 , grad = 1.0)\n",
      "Loss at Epoch 847 is : netwok_nn.tensor(39.45932359415859 , grad = 1.0)\n",
      "Loss at Epoch 848 is : netwok_nn.tensor(39.35362537534816 , grad = 1.0)\n",
      "Loss at Epoch 849 is : netwok_nn.tensor(39.24809402062854 , grad = 1.0)\n",
      "Loss at Epoch 850 is : netwok_nn.tensor(39.14272943720019 , grad = 1.0)\n",
      "Loss at Epoch 851 is : netwok_nn.tensor(39.03753153225932 , grad = 1.0)\n",
      "Loss at Epoch 852 is : netwok_nn.tensor(38.93250021299801 , grad = 1.0)\n",
      "Loss at Epoch 853 is : netwok_nn.tensor(38.827635386604285 , grad = 1.0)\n",
      "Loss at Epoch 854 is : netwok_nn.tensor(38.72293696026237 , grad = 1.0)\n",
      "Loss at Epoch 855 is : netwok_nn.tensor(38.61840484115265 , grad = 1.0)\n",
      "Loss at Epoch 856 is : netwok_nn.tensor(38.51403893645184 , grad = 1.0)\n",
      "Loss at Epoch 857 is : netwok_nn.tensor(38.40983915333314 , grad = 1.0)\n",
      "Loss at Epoch 858 is : netwok_nn.tensor(38.30580539896631 , grad = 1.0)\n",
      "Loss at Epoch 859 is : netwok_nn.tensor(38.201937580517786 , grad = 1.0)\n",
      "Loss at Epoch 860 is : netwok_nn.tensor(38.098235605150784 , grad = 1.0)\n",
      "Loss at Epoch 861 is : netwok_nn.tensor(37.99469938002544 , grad = 1.0)\n",
      "Loss at Epoch 862 is : netwok_nn.tensor(37.891328812298894 , grad = 1.0)\n",
      "Loss at Epoch 863 is : netwok_nn.tensor(37.78812380912543 , grad = 1.0)\n",
      "Loss at Epoch 864 is : netwok_nn.tensor(37.68508427765653 , grad = 1.0)\n",
      "Loss at Epoch 865 is : netwok_nn.tensor(37.582210125041016 , grad = 1.0)\n",
      "Loss at Epoch 866 is : netwok_nn.tensor(37.479501258425174 , grad = 1.0)\n",
      "Loss at Epoch 867 is : netwok_nn.tensor(37.37695758495281 , grad = 1.0)\n",
      "Loss at Epoch 868 is : netwok_nn.tensor(37.274579011765425 , grad = 1.0)\n",
      "Loss at Epoch 869 is : netwok_nn.tensor(37.17236544600222 , grad = 1.0)\n",
      "Loss at Epoch 870 is : netwok_nn.tensor(37.070316794800284 , grad = 1.0)\n",
      "Loss at Epoch 871 is : netwok_nn.tensor(36.96843296529464 , grad = 1.0)\n",
      "Loss at Epoch 872 is : netwok_nn.tensor(36.86671386461842 , grad = 1.0)\n",
      "Loss at Epoch 873 is : netwok_nn.tensor(36.7651593999029 , grad = 1.0)\n",
      "Loss at Epoch 874 is : netwok_nn.tensor(36.66376947827755 , grad = 1.0)\n",
      "Loss at Epoch 875 is : netwok_nn.tensor(36.56254400687027 , grad = 1.0)\n",
      "Loss at Epoch 876 is : netwok_nn.tensor(36.46148289280738 , grad = 1.0)\n",
      "Loss at Epoch 877 is : netwok_nn.tensor(36.36058604321376 , grad = 1.0)\n",
      "Loss at Epoch 878 is : netwok_nn.tensor(36.25985336521293 , grad = 1.0)\n",
      "Loss at Epoch 879 is : netwok_nn.tensor(36.159284765927126 , grad = 1.0)\n",
      "Loss at Epoch 880 is : netwok_nn.tensor(36.05888015247744 , grad = 1.0)\n",
      "Loss at Epoch 881 is : netwok_nn.tensor(35.95863943198392 , grad = 1.0)\n",
      "Loss at Epoch 882 is : netwok_nn.tensor(35.85856251156556 , grad = 1.0)\n",
      "Loss at Epoch 883 is : netwok_nn.tensor(35.75864929834051 , grad = 1.0)\n",
      "Loss at Epoch 884 is : netwok_nn.tensor(35.658899699426094 , grad = 1.0)\n",
      "Loss at Epoch 885 is : netwok_nn.tensor(35.559313621938934 , grad = 1.0)\n",
      "Loss at Epoch 886 is : netwok_nn.tensor(35.459890972995055 , grad = 1.0)\n",
      "Loss at Epoch 887 is : netwok_nn.tensor(35.3606316597099 , grad = 1.0)\n",
      "Loss at Epoch 888 is : netwok_nn.tensor(35.26153558919848 , grad = 1.0)\n",
      "Loss at Epoch 889 is : netwok_nn.tensor(35.162602668575445 , grad = 1.0)\n",
      "Loss at Epoch 890 is : netwok_nn.tensor(35.06383280495516 , grad = 1.0)\n",
      "Loss at Epoch 891 is : netwok_nn.tensor(34.96522590545182 , grad = 1.0)\n",
      "Loss at Epoch 892 is : netwok_nn.tensor(34.86678187717948 , grad = 1.0)\n",
      "Loss at Epoch 893 is : netwok_nn.tensor(34.76850062725219 , grad = 1.0)\n",
      "Loss at Epoch 894 is : netwok_nn.tensor(34.670382062784036 , grad = 1.0)\n",
      "Loss at Epoch 895 is : netwok_nn.tensor(34.572426090889266 , grad = 1.0)\n",
      "Loss at Epoch 896 is : netwok_nn.tensor(34.47463261868233 , grad = 1.0)\n",
      "Loss at Epoch 897 is : netwok_nn.tensor(34.37700155327801 , grad = 1.0)\n",
      "Loss at Epoch 898 is : netwok_nn.tensor(34.27953280179141 , grad = 1.0)\n",
      "Loss at Epoch 899 is : netwok_nn.tensor(34.1822262713381 , grad = 1.0)\n",
      "Loss at Epoch 900 is : netwok_nn.tensor(34.08508186903424 , grad = 1.0)\n",
      "Loss at Epoch 901 is : netwok_nn.tensor(33.98809950199652 , grad = 1.0)\n",
      "Loss at Epoch 902 is : netwok_nn.tensor(33.8912790773424 , grad = 1.0)\n",
      "Loss at Epoch 903 is : netwok_nn.tensor(33.79462050219007 , grad = 1.0)\n",
      "Loss at Epoch 904 is : netwok_nn.tensor(33.698123683658494 , grad = 1.0)\n",
      "Loss at Epoch 905 is : netwok_nn.tensor(33.60178852886766 , grad = 1.0)\n",
      "Loss at Epoch 906 is : netwok_nn.tensor(33.505614944938486 , grad = 1.0)\n",
      "Loss at Epoch 907 is : netwok_nn.tensor(33.40960283899291 , grad = 1.0)\n",
      "Loss at Epoch 908 is : netwok_nn.tensor(33.31375211815406 , grad = 1.0)\n",
      "Loss at Epoch 909 is : netwok_nn.tensor(33.218062689546265 , grad = 1.0)\n",
      "Loss at Epoch 910 is : netwok_nn.tensor(33.12253446029509 , grad = 1.0)\n",
      "Loss at Epoch 911 is : netwok_nn.tensor(33.02716733752746 , grad = 1.0)\n",
      "Loss at Epoch 912 is : netwok_nn.tensor(32.931961228371705 , grad = 1.0)\n",
      "Loss at Epoch 913 is : netwok_nn.tensor(32.83691603995767 , grad = 1.0)\n",
      "Loss at Epoch 914 is : netwok_nn.tensor(32.742031679416684 , grad = 1.0)\n",
      "Loss at Epoch 915 is : netwok_nn.tensor(32.64730805388177 , grad = 1.0)\n",
      "Loss at Epoch 916 is : netwok_nn.tensor(32.55274507048755 , grad = 1.0)\n",
      "Loss at Epoch 917 is : netwok_nn.tensor(32.45834263637048 , grad = 1.0)\n",
      "Loss at Epoch 918 is : netwok_nn.tensor(32.36410065866877 , grad = 1.0)\n",
      "Loss at Epoch 919 is : netwok_nn.tensor(32.27001904452253 , grad = 1.0)\n",
      "Loss at Epoch 920 is : netwok_nn.tensor(32.17609770107378 , grad = 1.0)\n",
      "Loss at Epoch 921 is : netwok_nn.tensor(32.082336535466645 , grad = 1.0)\n",
      "Loss at Epoch 922 is : netwok_nn.tensor(31.988735454847184 , grad = 1.0)\n",
      "Loss at Epoch 923 is : netwok_nn.tensor(31.895294366363682 , grad = 1.0)\n",
      "Loss at Epoch 924 is : netwok_nn.tensor(31.802013177166582 , grad = 1.0)\n",
      "Loss at Epoch 925 is : netwok_nn.tensor(31.70889179440859 , grad = 1.0)\n",
      "Loss at Epoch 926 is : netwok_nn.tensor(31.615930125244716 , grad = 1.0)\n",
      "Loss at Epoch 927 is : netwok_nn.tensor(31.52312807683234 , grad = 1.0)\n",
      "Loss at Epoch 928 is : netwok_nn.tensor(31.430485556331305 , grad = 1.0)\n",
      "Loss at Epoch 929 is : netwok_nn.tensor(31.338002470903934 , grad = 1.0)\n",
      "Loss at Epoch 930 is : netwok_nn.tensor(31.245678727715102 , grad = 1.0)\n",
      "Loss at Epoch 931 is : netwok_nn.tensor(31.15351423393224 , grad = 1.0)\n",
      "Loss at Epoch 932 is : netwok_nn.tensor(31.061508896725503 , grad = 1.0)\n",
      "Loss at Epoch 933 is : netwok_nn.tensor(30.969662623267745 , grad = 1.0)\n",
      "Loss at Epoch 934 is : netwok_nn.tensor(30.877975320734627 , grad = 1.0)\n",
      "Loss at Epoch 935 is : netwok_nn.tensor(30.786446896304586 , grad = 1.0)\n",
      "Loss at Epoch 936 is : netwok_nn.tensor(30.69507725715898 , grad = 1.0)\n",
      "Loss at Epoch 937 is : netwok_nn.tensor(30.603866310482086 , grad = 1.0)\n",
      "Loss at Epoch 938 is : netwok_nn.tensor(30.512813963461177 , grad = 1.0)\n",
      "Loss at Epoch 939 is : netwok_nn.tensor(30.421920123286586 , grad = 1.0)\n",
      "Loss at Epoch 940 is : netwok_nn.tensor(30.331184697151738 , grad = 1.0)\n",
      "Loss at Epoch 941 is : netwok_nn.tensor(30.240607592253195 , grad = 1.0)\n",
      "Loss at Epoch 942 is : netwok_nn.tensor(30.150188715790726 , grad = 1.0)\n",
      "Loss at Epoch 943 is : netwok_nn.tensor(30.059927974967355 , grad = 1.0)\n",
      "Loss at Epoch 944 is : netwok_nn.tensor(29.969825276989376 , grad = 1.0)\n",
      "Loss at Epoch 945 is : netwok_nn.tensor(29.879880529066508 , grad = 1.0)\n",
      "Loss at Epoch 946 is : netwok_nn.tensor(29.790093638411772 , grad = 1.0)\n",
      "Loss at Epoch 947 is : netwok_nn.tensor(29.700464512241705 , grad = 1.0)\n",
      "Loss at Epoch 948 is : netwok_nn.tensor(29.61099305777634 , grad = 1.0)\n",
      "Loss at Epoch 949 is : netwok_nn.tensor(29.52167918223919 , grad = 1.0)\n",
      "Loss at Epoch 950 is : netwok_nn.tensor(29.43252279285743 , grad = 1.0)\n",
      "Loss at Epoch 951 is : netwok_nn.tensor(29.34352379686184 , grad = 1.0)\n",
      "Loss at Epoch 952 is : netwok_nn.tensor(29.25468210148689 , grad = 1.0)\n",
      "Loss at Epoch 953 is : netwok_nn.tensor(29.16599761397075 , grad = 1.0)\n",
      "Loss at Epoch 954 is : netwok_nn.tensor(29.077470241555364 , grad = 1.0)\n",
      "Loss at Epoch 955 is : netwok_nn.tensor(28.989099891486568 , grad = 1.0)\n",
      "Loss at Epoch 956 is : netwok_nn.tensor(28.900886471013976 , grad = 1.0)\n",
      "Loss at Epoch 957 is : netwok_nn.tensor(28.812829887391135 , grad = 1.0)\n",
      "Loss at Epoch 958 is : netwok_nn.tensor(28.72493004787553 , grad = 1.0)\n",
      "Loss at Epoch 959 is : netwok_nn.tensor(28.63718685972863 , grad = 1.0)\n",
      "Loss at Epoch 960 is : netwok_nn.tensor(28.54960023021595 , grad = 1.0)\n",
      "Loss at Epoch 961 is : netwok_nn.tensor(28.462170066607083 , grad = 1.0)\n",
      "Loss at Epoch 962 is : netwok_nn.tensor(28.37489627617574 , grad = 1.0)\n",
      "Loss at Epoch 963 is : netwok_nn.tensor(28.28777876619977 , grad = 1.0)\n",
      "Loss at Epoch 964 is : netwok_nn.tensor(28.2008174439612 , grad = 1.0)\n",
      "Loss at Epoch 965 is : netwok_nn.tensor(28.11401221674633 , grad = 1.0)\n",
      "Loss at Epoch 966 is : netwok_nn.tensor(28.027362991845724 , grad = 1.0)\n",
      "Loss at Epoch 967 is : netwok_nn.tensor(27.94086967655422 , grad = 1.0)\n",
      "Loss at Epoch 968 is : netwok_nn.tensor(27.854532178171052 , grad = 1.0)\n",
      "Loss at Epoch 969 is : netwok_nn.tensor(27.76835040399983 , grad = 1.0)\n",
      "Loss at Epoch 970 is : netwok_nn.tensor(27.68232426134859 , grad = 1.0)\n",
      "Loss at Epoch 971 is : netwok_nn.tensor(27.59645365752981 , grad = 1.0)\n",
      "Loss at Epoch 972 is : netwok_nn.tensor(27.510738499860505 , grad = 1.0)\n",
      "Loss at Epoch 973 is : netwok_nn.tensor(27.425178695662197 , grad = 1.0)\n",
      "Loss at Epoch 974 is : netwok_nn.tensor(27.339774152260993 , grad = 1.0)\n",
      "Loss at Epoch 975 is : netwok_nn.tensor(27.254524776987576 , grad = 1.0)\n",
      "Loss at Epoch 976 is : netwok_nn.tensor(27.16943047717734 , grad = 1.0)\n",
      "Loss at Epoch 977 is : netwok_nn.tensor(27.084491160170245 , grad = 1.0)\n",
      "Loss at Epoch 978 is : netwok_nn.tensor(26.999706733311072 , grad = 1.0)\n",
      "Loss at Epoch 979 is : netwok_nn.tensor(26.915077103949294 , grad = 1.0)\n",
      "Loss at Epoch 980 is : netwok_nn.tensor(26.830602179439126 , grad = 1.0)\n",
      "Loss at Epoch 981 is : netwok_nn.tensor(26.746281867139693 , grad = 1.0)\n",
      "Loss at Epoch 982 is : netwok_nn.tensor(26.662116074414875 , grad = 1.0)\n",
      "Loss at Epoch 983 is : netwok_nn.tensor(26.578104708633436 , grad = 1.0)\n",
      "Loss at Epoch 984 is : netwok_nn.tensor(26.49424767716905 , grad = 1.0)\n",
      "Loss at Epoch 985 is : netwok_nn.tensor(26.41054488740036 , grad = 1.0)\n",
      "Loss at Epoch 986 is : netwok_nn.tensor(26.326996246710973 , grad = 1.0)\n",
      "Loss at Epoch 987 is : netwok_nn.tensor(26.24360166248945 , grad = 1.0)\n",
      "Loss at Epoch 988 is : netwok_nn.tensor(26.160361042129395 , grad = 1.0)\n",
      "Loss at Epoch 989 is : netwok_nn.tensor(26.077274293029497 , grad = 1.0)\n",
      "Loss at Epoch 990 is : netwok_nn.tensor(25.994341322593506 , grad = 1.0)\n",
      "Loss at Epoch 991 is : netwok_nn.tensor(25.911562038230304 , grad = 1.0)\n",
      "Loss at Epoch 992 is : netwok_nn.tensor(25.828936347353903 , grad = 1.0)\n",
      "Loss at Epoch 993 is : netwok_nn.tensor(25.746464157383528 , grad = 1.0)\n",
      "Loss at Epoch 994 is : netwok_nn.tensor(25.664145375743548 , grad = 1.0)\n",
      "Loss at Epoch 995 is : netwok_nn.tensor(25.581979909863595 , grad = 1.0)\n",
      "Loss at Epoch 996 is : netwok_nn.tensor(25.49996766717853 , grad = 1.0)\n",
      "Loss at Epoch 997 is : netwok_nn.tensor(25.418108555128512 , grad = 1.0)\n",
      "Loss at Epoch 998 is : netwok_nn.tensor(25.33640248115902 , grad = 1.0)\n",
      "Loss at Epoch 999 is : netwok_nn.tensor(25.254849352720868 , grad = 1.0)\n",
      "Loss at Epoch 1000 is : netwok_nn.tensor(25.173449077270217 , grad = 1.0)\n",
      "Loss at Epoch 1001 is : netwok_nn.tensor(25.092201562268606 , grad = 1.0)\n",
      "Loss at Epoch 1002 is : netwok_nn.tensor(25.011106715183004 , grad = 1.0)\n",
      "Loss at Epoch 1003 is : netwok_nn.tensor(24.93016444348582 , grad = 1.0)\n",
      "Loss at Epoch 1004 is : netwok_nn.tensor(24.849374654654913 , grad = 1.0)\n",
      "Loss at Epoch 1005 is : netwok_nn.tensor(24.768737256173637 , grad = 1.0)\n",
      "Loss at Epoch 1006 is : netwok_nn.tensor(24.688252155530822 , grad = 1.0)\n",
      "Loss at Epoch 1007 is : netwok_nn.tensor(24.607919260220875 , grad = 1.0)\n",
      "Loss at Epoch 1008 is : netwok_nn.tensor(24.527738477743725 , grad = 1.0)\n",
      "Loss at Epoch 1009 is : netwok_nn.tensor(24.447709715604905 , grad = 1.0)\n",
      "Loss at Epoch 1010 is : netwok_nn.tensor(24.36783288131553 , grad = 1.0)\n",
      "Loss at Epoch 1011 is : netwok_nn.tensor(24.28810788239235 , grad = 1.0)\n",
      "Loss at Epoch 1012 is : netwok_nn.tensor(24.20853462635776 , grad = 1.0)\n",
      "Loss at Epoch 1013 is : netwok_nn.tensor(24.129113020739805 , grad = 1.0)\n",
      "Loss at Epoch 1014 is : netwok_nn.tensor(24.04984297307224 , grad = 1.0)\n",
      "Loss at Epoch 1015 is : netwok_nn.tensor(23.970724390894535 , grad = 1.0)\n",
      "Loss at Epoch 1016 is : netwok_nn.tensor(23.891757181751856 , grad = 1.0)\n",
      "Loss at Epoch 1017 is : netwok_nn.tensor(23.812941253195152 , grad = 1.0)\n",
      "Loss at Epoch 1018 is : netwok_nn.tensor(23.73427651278113 , grad = 1.0)\n",
      "Loss at Epoch 1019 is : netwok_nn.tensor(23.655762868072273 , grad = 1.0)\n",
      "Loss at Epoch 1020 is : netwok_nn.tensor(23.577400226636914 , grad = 1.0)\n",
      "Loss at Epoch 1021 is : netwok_nn.tensor(23.499188496049182 , grad = 1.0)\n",
      "Loss at Epoch 1022 is : netwok_nn.tensor(23.421127583889064 , grad = 1.0)\n",
      "Loss at Epoch 1023 is : netwok_nn.tensor(23.343217397742446 , grad = 1.0)\n",
      "Loss at Epoch 1024 is : netwok_nn.tensor(23.265457845201023 , grad = 1.0)\n",
      "Loss at Epoch 1025 is : netwok_nn.tensor(23.18784883386249 , grad = 1.0)\n",
      "Loss at Epoch 1026 is : netwok_nn.tensor(23.110390271330413 , grad = 1.0)\n",
      "Loss at Epoch 1027 is : netwok_nn.tensor(23.033082065214288 , grad = 1.0)\n",
      "Loss at Epoch 1028 is : netwok_nn.tensor(22.955924123129584 , grad = 1.0)\n",
      "Loss at Epoch 1029 is : netwok_nn.tensor(22.87891635269778 , grad = 1.0)\n",
      "Loss at Epoch 1030 is : netwok_nn.tensor(22.802058661546297 , grad = 1.0)\n",
      "Loss at Epoch 1031 is : netwok_nn.tensor(22.725350957308606 , grad = 1.0)\n",
      "Loss at Epoch 1032 is : netwok_nn.tensor(22.64879314762418 , grad = 1.0)\n",
      "Loss at Epoch 1033 is : netwok_nn.tensor(22.572385140138536 , grad = 1.0)\n",
      "Loss at Epoch 1034 is : netwok_nn.tensor(22.496126842503248 , grad = 1.0)\n",
      "Loss at Epoch 1035 is : netwok_nn.tensor(22.420018162375968 , grad = 1.0)\n",
      "Loss at Epoch 1036 is : netwok_nn.tensor(22.344059007420455 , grad = 1.0)\n",
      "Loss at Epoch 1037 is : netwok_nn.tensor(22.26824928530657 , grad = 1.0)\n",
      "Loss at Epoch 1038 is : netwok_nn.tensor(22.192588903710256 , grad = 1.0)\n",
      "Loss at Epoch 1039 is : netwok_nn.tensor(22.11707777031365 , grad = 1.0)\n",
      "Loss at Epoch 1040 is : netwok_nn.tensor(22.04171579280502 , grad = 1.0)\n",
      "Loss at Epoch 1041 is : netwok_nn.tensor(21.966502878878764 , grad = 1.0)\n",
      "Loss at Epoch 1042 is : netwok_nn.tensor(21.891438936235502 , grad = 1.0)\n",
      "Loss at Epoch 1043 is : netwok_nn.tensor(21.816523872582046 , grad = 1.0)\n",
      "Loss at Epoch 1044 is : netwok_nn.tensor(21.741757595631398 , grad = 1.0)\n",
      "Loss at Epoch 1045 is : netwok_nn.tensor(21.667140013102788 , grad = 1.0)\n",
      "Loss at Epoch 1046 is : netwok_nn.tensor(21.592671032721693 , grad = 1.0)\n",
      "Loss at Epoch 1047 is : netwok_nn.tensor(21.518350562219783 , grad = 1.0)\n",
      "Loss at Epoch 1048 is : netwok_nn.tensor(21.444178509335075 , grad = 1.0)\n",
      "Loss at Epoch 1049 is : netwok_nn.tensor(21.37015478181182 , grad = 1.0)\n",
      "Loss at Epoch 1050 is : netwok_nn.tensor(21.296279287400548 , grad = 1.0)\n",
      "Loss at Epoch 1051 is : netwok_nn.tensor(21.22255193385809 , grad = 1.0)\n",
      "Loss at Epoch 1052 is : netwok_nn.tensor(21.148972628947604 , grad = 1.0)\n",
      "Loss at Epoch 1053 is : netwok_nn.tensor(21.075541280438575 , grad = 1.0)\n",
      "Loss at Epoch 1054 is : netwok_nn.tensor(21.002257796106818 , grad = 1.0)\n",
      "Loss at Epoch 1055 is : netwok_nn.tensor(20.929122083734455 , grad = 1.0)\n",
      "Loss at Epoch 1056 is : netwok_nn.tensor(20.856134051110057 , grad = 1.0)\n",
      "Loss at Epoch 1057 is : netwok_nn.tensor(20.783293606028497 , grad = 1.0)\n",
      "Loss at Epoch 1058 is : netwok_nn.tensor(20.710600656291057 , grad = 1.0)\n",
      "Loss at Epoch 1059 is : netwok_nn.tensor(20.6380551097054 , grad = 1.0)\n",
      "Loss at Epoch 1060 is : netwok_nn.tensor(20.565656874085597 , grad = 1.0)\n",
      "Loss at Epoch 1061 is : netwok_nn.tensor(20.493405857252156 , grad = 1.0)\n",
      "Loss at Epoch 1062 is : netwok_nn.tensor(20.421301967031987 , grad = 1.0)\n",
      "Loss at Epoch 1063 is : netwok_nn.tensor(20.349345111258465 , grad = 1.0)\n",
      "Loss at Epoch 1064 is : netwok_nn.tensor(20.277535197771382 , grad = 1.0)\n",
      "Loss at Epoch 1065 is : netwok_nn.tensor(20.20587213441701 , grad = 1.0)\n",
      "Loss at Epoch 1066 is : netwok_nn.tensor(20.134355829048076 , grad = 1.0)\n",
      "Loss at Epoch 1067 is : netwok_nn.tensor(20.062986189523816 , grad = 1.0)\n",
      "Loss at Epoch 1068 is : netwok_nn.tensor(19.991763123709916 , grad = 1.0)\n",
      "Loss at Epoch 1069 is : netwok_nn.tensor(19.92068653947858 , grad = 1.0)\n",
      "Loss at Epoch 1070 is : netwok_nn.tensor(19.8497563447085 , grad = 1.0)\n",
      "Loss at Epoch 1071 is : netwok_nn.tensor(19.778972447284936 , grad = 1.0)\n",
      "Loss at Epoch 1072 is : netwok_nn.tensor(19.70833475509962 , grad = 1.0)\n",
      "Loss at Epoch 1073 is : netwok_nn.tensor(19.637843176050843 , grad = 1.0)\n",
      "Loss at Epoch 1074 is : netwok_nn.tensor(19.567497618043443 , grad = 1.0)\n",
      "Loss at Epoch 1075 is : netwok_nn.tensor(19.497297988988812 , grad = 1.0)\n",
      "Loss at Epoch 1076 is : netwok_nn.tensor(19.427244196804903 , grad = 1.0)\n",
      "Loss at Epoch 1077 is : netwok_nn.tensor(19.357336149416266 , grad = 1.0)\n",
      "Loss at Epoch 1078 is : netwok_nn.tensor(19.287573754753957 , grad = 1.0)\n",
      "Loss at Epoch 1079 is : netwok_nn.tensor(19.217956920755718 , grad = 1.0)\n",
      "Loss at Epoch 1080 is : netwok_nn.tensor(19.148485555365834 , grad = 1.0)\n",
      "Loss at Epoch 1081 is : netwok_nn.tensor(19.079159566535182 , grad = 1.0)\n",
      "Loss at Epoch 1082 is : netwok_nn.tensor(19.00997886222131 , grad = 1.0)\n",
      "Loss at Epoch 1083 is : netwok_nn.tensor(18.940943350388345 , grad = 1.0)\n",
      "Loss at Epoch 1084 is : netwok_nn.tensor(18.872052939007066 , grad = 1.0)\n",
      "Loss at Epoch 1085 is : netwok_nn.tensor(18.803307536054874 , grad = 1.0)\n",
      "Loss at Epoch 1086 is : netwok_nn.tensor(18.73470704951584 , grad = 1.0)\n",
      "Loss at Epoch 1087 is : netwok_nn.tensor(18.666251387380676 , grad = 1.0)\n",
      "Loss at Epoch 1088 is : netwok_nn.tensor(18.597940457646747 , grad = 1.0)\n",
      "Loss at Epoch 1089 is : netwok_nn.tensor(18.52977416831811 , grad = 1.0)\n",
      "Loss at Epoch 1090 is : netwok_nn.tensor(18.461752427405493 , grad = 1.0)\n",
      "Loss at Epoch 1091 is : netwok_nn.tensor(18.39387514292632 , grad = 1.0)\n",
      "Loss at Epoch 1092 is : netwok_nn.tensor(18.32614222290468 , grad = 1.0)\n",
      "Loss at Epoch 1093 is : netwok_nn.tensor(18.258553575371383 , grad = 1.0)\n",
      "Loss at Epoch 1094 is : netwok_nn.tensor(18.191109108363953 , grad = 1.0)\n",
      "Loss at Epoch 1095 is : netwok_nn.tensor(18.123808729926633 , grad = 1.0)\n",
      "Loss at Epoch 1096 is : netwok_nn.tensor(18.05665234811038 , grad = 1.0)\n",
      "Loss at Epoch 1097 is : netwok_nn.tensor(17.989639870972884 , grad = 1.0)\n",
      "Loss at Epoch 1098 is : netwok_nn.tensor(17.922771206578563 , grad = 1.0)\n",
      "Loss at Epoch 1099 is : netwok_nn.tensor(17.8560462629986 , grad = 1.0)\n",
      "Loss at Epoch 1100 is : netwok_nn.tensor(17.789464948310933 , grad = 1.0)\n",
      "Loss at Epoch 1101 is : netwok_nn.tensor(17.72302717060023 , grad = 1.0)\n",
      "Loss at Epoch 1102 is : netwok_nn.tensor(17.65673283795797 , grad = 1.0)\n",
      "Loss at Epoch 1103 is : netwok_nn.tensor(17.590581858482345 , grad = 1.0)\n",
      "Loss at Epoch 1104 is : netwok_nn.tensor(17.524574140278393 , grad = 1.0)\n",
      "Loss at Epoch 1105 is : netwok_nn.tensor(17.45870959145789 , grad = 1.0)\n",
      "Loss at Epoch 1106 is : netwok_nn.tensor(17.392988120139464 , grad = 1.0)\n",
      "Loss at Epoch 1107 is : netwok_nn.tensor(17.327409634448475 , grad = 1.0)\n",
      "Loss at Epoch 1108 is : netwok_nn.tensor(17.26197404251716 , grad = 1.0)\n",
      "Loss at Epoch 1109 is : netwok_nn.tensor(17.196681252484524 , grad = 1.0)\n",
      "Loss at Epoch 1110 is : netwok_nn.tensor(17.131531172496402 , grad = 1.0)\n",
      "Loss at Epoch 1111 is : netwok_nn.tensor(17.066523710705486 , grad = 1.0)\n",
      "Loss at Epoch 1112 is : netwok_nn.tensor(17.001658775271288 , grad = 1.0)\n",
      "Loss at Epoch 1113 is : netwok_nn.tensor(16.936936274360175 , grad = 1.0)\n",
      "Loss at Epoch 1114 is : netwok_nn.tensor(16.87235611614534 , grad = 1.0)\n",
      "Loss at Epoch 1115 is : netwok_nn.tensor(16.80791820880687 , grad = 1.0)\n",
      "Loss at Epoch 1116 is : netwok_nn.tensor(16.74362246053167 , grad = 1.0)\n",
      "Loss at Epoch 1117 is : netwok_nn.tensor(16.679468779513584 , grad = 1.0)\n",
      "Loss at Epoch 1118 is : netwok_nn.tensor(16.615457073953287 , grad = 1.0)\n",
      "Loss at Epoch 1119 is : netwok_nn.tensor(16.551587252058344 , grad = 1.0)\n",
      "Loss at Epoch 1120 is : netwok_nn.tensor(16.487859222043205 , grad = 1.0)\n",
      "Loss at Epoch 1121 is : netwok_nn.tensor(16.424272892129267 , grad = 1.0)\n",
      "Loss at Epoch 1122 is : netwok_nn.tensor(16.360828170544806 , grad = 1.0)\n",
      "Loss at Epoch 1123 is : netwok_nn.tensor(16.297524965525003 , grad = 1.0)\n",
      "Loss at Epoch 1124 is : netwok_nn.tensor(16.234363185311967 , grad = 1.0)\n",
      "Loss at Epoch 1125 is : netwok_nn.tensor(16.171342738154753 , grad = 1.0)\n",
      "Loss at Epoch 1126 is : netwok_nn.tensor(16.108463532309354 , grad = 1.0)\n",
      "Loss at Epoch 1127 is : netwok_nn.tensor(16.0457254760387 , grad = 1.0)\n",
      "Loss at Epoch 1128 is : netwok_nn.tensor(15.983128477612645 , grad = 1.0)\n",
      "Loss at Epoch 1129 is : netwok_nn.tensor(15.920672445308044 , grad = 1.0)\n",
      "Loss at Epoch 1130 is : netwok_nn.tensor(15.858357287408705 , grad = 1.0)\n",
      "Loss at Epoch 1131 is : netwok_nn.tensor(15.79618291220542 , grad = 1.0)\n",
      "Loss at Epoch 1132 is : netwok_nn.tensor(15.734149227995953 , grad = 1.0)\n",
      "Loss at Epoch 1133 is : netwok_nn.tensor(15.672256143085038 , grad = 1.0)\n",
      "Loss at Epoch 1134 is : netwok_nn.tensor(15.610503565784448 , grad = 1.0)\n",
      "Loss at Epoch 1135 is : netwok_nn.tensor(15.548891404412943 , grad = 1.0)\n",
      "Loss at Epoch 1136 is : netwok_nn.tensor(15.487419567296286 , grad = 1.0)\n",
      "Loss at Epoch 1137 is : netwok_nn.tensor(15.426087962767301 , grad = 1.0)\n",
      "Loss at Epoch 1138 is : netwok_nn.tensor(15.364896499165782 , grad = 1.0)\n",
      "Loss at Epoch 1139 is : netwok_nn.tensor(15.303845084838624 , grad = 1.0)\n",
      "Loss at Epoch 1140 is : netwok_nn.tensor(15.242933628139731 , grad = 1.0)\n",
      "Loss at Epoch 1141 is : netwok_nn.tensor(15.182162037430059 , grad = 1.0)\n",
      "Loss at Epoch 1142 is : netwok_nn.tensor(15.121530221077665 , grad = 1.0)\n",
      "Loss at Epoch 1143 is : netwok_nn.tensor(15.061038087457643 , grad = 1.0)\n",
      "Loss at Epoch 1144 is : netwok_nn.tensor(15.000685544952178 , grad = 1.0)\n",
      "Loss at Epoch 1145 is : netwok_nn.tensor(14.940472501950554 , grad = 1.0)\n",
      "Loss at Epoch 1146 is : netwok_nn.tensor(14.88039886684915 , grad = 1.0)\n",
      "Loss at Epoch 1147 is : netwok_nn.tensor(14.820464548051454 , grad = 1.0)\n",
      "Loss at Epoch 1148 is : netwok_nn.tensor(14.760669453968083 , grad = 1.0)\n",
      "Loss at Epoch 1149 is : netwok_nn.tensor(14.701013493016758 , grad = 1.0)\n",
      "Loss at Epoch 1150 is : netwok_nn.tensor(14.641496573622346 , grad = 1.0)\n",
      "Loss at Epoch 1151 is : netwok_nn.tensor(14.582118604216882 , grad = 1.0)\n",
      "Loss at Epoch 1152 is : netwok_nn.tensor(14.522879493239525 , grad = 1.0)\n",
      "Loss at Epoch 1153 is : netwok_nn.tensor(14.46377914913661 , grad = 1.0)\n",
      "Loss at Epoch 1154 is : netwok_nn.tensor(14.404817480361674 , grad = 1.0)\n",
      "Loss at Epoch 1155 is : netwok_nn.tensor(14.34599439537541 , grad = 1.0)\n",
      "Loss at Epoch 1156 is : netwok_nn.tensor(14.287309802645696 , grad = 1.0)\n",
      "Loss at Epoch 1157 is : netwok_nn.tensor(14.228763610647661 , grad = 1.0)\n",
      "Loss at Epoch 1158 is : netwok_nn.tensor(14.17035572786362 , grad = 1.0)\n",
      "Loss at Epoch 1159 is : netwok_nn.tensor(14.112086062783128 , grad = 1.0)\n",
      "Loss at Epoch 1160 is : netwok_nn.tensor(14.053954523902984 , grad = 1.0)\n",
      "Loss at Epoch 1161 is : netwok_nn.tensor(13.995961019727229 , grad = 1.0)\n",
      "Loss at Epoch 1162 is : netwok_nn.tensor(13.938105458767177 , grad = 1.0)\n",
      "Loss at Epoch 1163 is : netwok_nn.tensor(13.88038774954139 , grad = 1.0)\n",
      "Loss at Epoch 1164 is : netwok_nn.tensor(13.822807800575754 , grad = 1.0)\n",
      "Loss at Epoch 1165 is : netwok_nn.tensor(13.765365520403416 , grad = 1.0)\n",
      "Loss at Epoch 1166 is : netwok_nn.tensor(13.708060817564853 , grad = 1.0)\n",
      "Loss at Epoch 1167 is : netwok_nn.tensor(13.650893600607876 , grad = 1.0)\n",
      "Loss at Epoch 1168 is : netwok_nn.tensor(13.593863778087604 , grad = 1.0)\n",
      "Loss at Epoch 1169 is : netwok_nn.tensor(13.536971258566517 , grad = 1.0)\n",
      "Loss at Epoch 1170 is : netwok_nn.tensor(13.480215950614456 , grad = 1.0)\n",
      "Loss at Epoch 1171 is : netwok_nn.tensor(13.423597762808615 , grad = 1.0)\n",
      "Loss at Epoch 1172 is : netwok_nn.tensor(13.367116603733612 , grad = 1.0)\n",
      "Loss at Epoch 1173 is : netwok_nn.tensor(13.31077238198144 , grad = 1.0)\n",
      "Loss at Epoch 1174 is : netwok_nn.tensor(13.254565006151505 , grad = 1.0)\n",
      "Loss at Epoch 1175 is : netwok_nn.tensor(13.198494384850642 , grad = 1.0)\n",
      "Loss at Epoch 1176 is : netwok_nn.tensor(13.142560426693144 , grad = 1.0)\n",
      "Loss at Epoch 1177 is : netwok_nn.tensor(13.08676304030073 , grad = 1.0)\n",
      "Loss at Epoch 1178 is : netwok_nn.tensor(13.03110213430262 , grad = 1.0)\n",
      "Loss at Epoch 1179 is : netwok_nn.tensor(12.975577617335519 , grad = 1.0)\n",
      "Loss at Epoch 1180 is : netwok_nn.tensor(12.920189398043599 , grad = 1.0)\n",
      "Loss at Epoch 1181 is : netwok_nn.tensor(12.864937385078587 , grad = 1.0)\n",
      "Loss at Epoch 1182 is : netwok_nn.tensor(12.809821487099725 , grad = 1.0)\n",
      "Loss at Epoch 1183 is : netwok_nn.tensor(12.754841612773808 , grad = 1.0)\n",
      "Loss at Epoch 1184 is : netwok_nn.tensor(12.699997670775188 , grad = 1.0)\n",
      "Loss at Epoch 1185 is : netwok_nn.tensor(12.645289569785804 , grad = 1.0)\n",
      "Loss at Epoch 1186 is : netwok_nn.tensor(12.590717218495183 , grad = 1.0)\n",
      "Loss at Epoch 1187 is : netwok_nn.tensor(12.536280525600484 , grad = 1.0)\n",
      "Loss at Epoch 1188 is : netwok_nn.tensor(12.481979399806491 , grad = 1.0)\n",
      "Loss at Epoch 1189 is : netwok_nn.tensor(12.427813749825637 , grad = 1.0)\n",
      "Loss at Epoch 1190 is : netwok_nn.tensor(12.373783484378015 , grad = 1.0)\n",
      "Loss at Epoch 1191 is : netwok_nn.tensor(12.319888512191394 , grad = 1.0)\n",
      "Loss at Epoch 1192 is : netwok_nn.tensor(12.26612874200129 , grad = 1.0)\n",
      "Loss at Epoch 1193 is : netwok_nn.tensor(12.21250408255088 , grad = 1.0)\n",
      "Loss at Epoch 1194 is : netwok_nn.tensor(12.159014442591154 , grad = 1.0)\n",
      "Loss at Epoch 1195 is : netwok_nn.tensor(12.105659730880804 , grad = 1.0)\n",
      "Loss at Epoch 1196 is : netwok_nn.tensor(12.052439856186322 , grad = 1.0)\n",
      "Loss at Epoch 1197 is : netwok_nn.tensor(11.999354727282011 , grad = 1.0)\n",
      "Loss at Epoch 1198 is : netwok_nn.tensor(11.946404252949979 , grad = 1.0)\n",
      "Loss at Epoch 1199 is : netwok_nn.tensor(11.893588341980175 , grad = 1.0)\n",
      "Loss at Epoch 1200 is : netwok_nn.tensor(11.840906903170437 , grad = 1.0)\n",
      "Loss at Epoch 1201 is : netwok_nn.tensor(11.788359845326449 , grad = 1.0)\n",
      "Loss at Epoch 1202 is : netwok_nn.tensor(11.735947077261837 , grad = 1.0)\n",
      "Loss at Epoch 1203 is : netwok_nn.tensor(11.68366850779813 , grad = 1.0)\n",
      "Loss at Epoch 1204 is : netwok_nn.tensor(11.631524045764825 , grad = 1.0)\n",
      "Loss at Epoch 1205 is : netwok_nn.tensor(11.579513599999368 , grad = 1.0)\n",
      "Loss at Epoch 1206 is : netwok_nn.tensor(11.527637079347205 , grad = 1.0)\n",
      "Loss at Epoch 1207 is : netwok_nn.tensor(11.475894392661816 , grad = 1.0)\n",
      "Loss at Epoch 1208 is : netwok_nn.tensor(11.424285448804726 , grad = 1.0)\n",
      "Loss at Epoch 1209 is : netwok_nn.tensor(11.372810156645519 , grad = 1.0)\n",
      "Loss at Epoch 1210 is : netwok_nn.tensor(11.321468425061864 , grad = 1.0)\n",
      "Loss at Epoch 1211 is : netwok_nn.tensor(11.270260162939541 , grad = 1.0)\n",
      "Loss at Epoch 1212 is : netwok_nn.tensor(11.21918527917249 , grad = 1.0)\n",
      "Loss at Epoch 1213 is : netwok_nn.tensor(11.16824368266283 , grad = 1.0)\n",
      "Loss at Epoch 1214 is : netwok_nn.tensor(11.117435282320825 , grad = 1.0)\n",
      "Loss at Epoch 1215 is : netwok_nn.tensor(11.066759987065007 , grad = 1.0)\n",
      "Loss at Epoch 1216 is : netwok_nn.tensor(11.01621770582213 , grad = 1.0)\n",
      "Loss at Epoch 1217 is : netwok_nn.tensor(10.965808347527222 , grad = 1.0)\n",
      "Loss at Epoch 1218 is : netwok_nn.tensor(10.915531821123611 , grad = 1.0)\n",
      "Loss at Epoch 1219 is : netwok_nn.tensor(10.86538803556298 , grad = 1.0)\n",
      "Loss at Epoch 1220 is : netwok_nn.tensor(10.815376899805342 , grad = 1.0)\n",
      "Loss at Epoch 1221 is : netwok_nn.tensor(10.765498322819107 , grad = 1.0)\n",
      "Loss at Epoch 1222 is : netwok_nn.tensor(10.715752213581117 , grad = 1.0)\n",
      "Loss at Epoch 1223 is : netwok_nn.tensor(10.666138481076626 , grad = 1.0)\n",
      "Loss at Epoch 1224 is : netwok_nn.tensor(10.61665703429939 , grad = 1.0)\n",
      "Loss at Epoch 1225 is : netwok_nn.tensor(10.567307782251687 , grad = 1.0)\n",
      "Loss at Epoch 1226 is : netwok_nn.tensor(10.518090633944292 , grad = 1.0)\n",
      "Loss at Epoch 1227 is : netwok_nn.tensor(10.46900549839658 , grad = 1.0)\n",
      "Loss at Epoch 1228 is : netwok_nn.tensor(10.420052284636533 , grad = 1.0)\n",
      "Loss at Epoch 1229 is : netwok_nn.tensor(10.371230901700745 , grad = 1.0)\n",
      "Loss at Epoch 1230 is : netwok_nn.tensor(10.322541258634502 , grad = 1.0)\n",
      "Loss at Epoch 1231 is : netwok_nn.tensor(10.273983264491765 , grad = 1.0)\n",
      "Loss at Epoch 1232 is : netwok_nn.tensor(10.225556828335252 , grad = 1.0)\n",
      "Loss at Epoch 1233 is : netwok_nn.tensor(10.177261859236449 , grad = 1.0)\n",
      "Loss at Epoch 1234 is : netwok_nn.tensor(10.129098266275632 , grad = 1.0)\n",
      "Loss at Epoch 1235 is : netwok_nn.tensor(10.081065958541945 , grad = 1.0)\n",
      "Loss at Epoch 1236 is : netwok_nn.tensor(10.03316484513339 , grad = 1.0)\n",
      "Loss at Epoch 1237 is : netwok_nn.tensor(9.985394835156875 , grad = 1.0)\n",
      "Loss at Epoch 1238 is : netwok_nn.tensor(9.937755837728286 , grad = 1.0)\n",
      "Loss at Epoch 1239 is : netwok_nn.tensor(9.890247761972464 , grad = 1.0)\n",
      "Loss at Epoch 1240 is : netwok_nn.tensor(9.84287051702329 , grad = 1.0)\n",
      "Loss at Epoch 1241 is : netwok_nn.tensor(9.795624012023724 , grad = 1.0)\n",
      "Loss at Epoch 1242 is : netwok_nn.tensor(9.748508156125801 , grad = 1.0)\n",
      "Loss at Epoch 1243 is : netwok_nn.tensor(9.701522858490735 , grad = 1.0)\n",
      "Loss at Epoch 1244 is : netwok_nn.tensor(9.654668028288894 , grad = 1.0)\n",
      "Loss at Epoch 1245 is : netwok_nn.tensor(9.607943574699878 , grad = 1.0)\n",
      "Loss at Epoch 1246 is : netwok_nn.tensor(9.561349406912552 , grad = 1.0)\n",
      "Loss at Epoch 1247 is : netwok_nn.tensor(9.5148854341251 , grad = 1.0)\n",
      "Loss at Epoch 1248 is : netwok_nn.tensor(9.468551565545045 , grad = 1.0)\n",
      "Loss at Epoch 1249 is : netwok_nn.tensor(9.422347710389296 , grad = 1.0)\n",
      "Loss at Epoch 1250 is : netwok_nn.tensor(9.376273777884219 , grad = 1.0)\n",
      "Loss at Epoch 1251 is : netwok_nn.tensor(9.330329677265627 , grad = 1.0)\n",
      "Loss at Epoch 1252 is : netwok_nn.tensor(9.284515317778915 , grad = 1.0)\n",
      "Loss at Epoch 1253 is : netwok_nn.tensor(9.238830608678988 , grad = 1.0)\n",
      "Loss at Epoch 1254 is : netwok_nn.tensor(9.193275459230408 , grad = 1.0)\n",
      "Loss at Epoch 1255 is : netwok_nn.tensor(9.147849778707375 , grad = 1.0)\n",
      "Loss at Epoch 1256 is : netwok_nn.tensor(9.102553476393819 , grad = 1.0)\n",
      "Loss at Epoch 1257 is : netwok_nn.tensor(9.057386461583421 , grad = 1.0)\n",
      "Loss at Epoch 1258 is : netwok_nn.tensor(9.012348643579678 , grad = 1.0)\n",
      "Loss at Epoch 1259 is : netwok_nn.tensor(8.967439931695925 , grad = 1.0)\n",
      "Loss at Epoch 1260 is : netwok_nn.tensor(8.922660235255407 , grad = 1.0)\n",
      "Loss at Epoch 1261 is : netwok_nn.tensor(8.878009463591331 , grad = 1.0)\n",
      "Loss at Epoch 1262 is : netwok_nn.tensor(8.833487526046913 , grad = 1.0)\n",
      "Loss at Epoch 1263 is : netwok_nn.tensor(8.789094331975427 , grad = 1.0)\n",
      "Loss at Epoch 1264 is : netwok_nn.tensor(8.744829790740239 , grad = 1.0)\n",
      "Loss at Epoch 1265 is : netwok_nn.tensor(8.700693811714906 , grad = 1.0)\n",
      "Loss at Epoch 1266 is : netwok_nn.tensor(8.656686304283198 , grad = 1.0)\n",
      "Loss at Epoch 1267 is : netwok_nn.tensor(8.61280717783914 , grad = 1.0)\n",
      "Loss at Epoch 1268 is : netwok_nn.tensor(8.569056341787086 , grad = 1.0)\n",
      "Loss at Epoch 1269 is : netwok_nn.tensor(8.525433705541792 , grad = 1.0)\n",
      "Loss at Epoch 1270 is : netwok_nn.tensor(8.481939178528426 , grad = 1.0)\n",
      "Loss at Epoch 1271 is : netwok_nn.tensor(8.438572670182674 , grad = 1.0)\n",
      "Loss at Epoch 1272 is : netwok_nn.tensor(8.395334089950762 , grad = 1.0)\n",
      "Loss at Epoch 1273 is : netwok_nn.tensor(8.352223347289517 , grad = 1.0)\n",
      "Loss at Epoch 1274 is : netwok_nn.tensor(8.30924035166646 , grad = 1.0)\n",
      "Loss at Epoch 1275 is : netwok_nn.tensor(8.266385012559846 , grad = 1.0)\n",
      "Loss at Epoch 1276 is : netwok_nn.tensor(8.223657239458692 , grad = 1.0)\n",
      "Loss at Epoch 1277 is : netwok_nn.tensor(8.181056941862897 , grad = 1.0)\n",
      "Loss at Epoch 1278 is : netwok_nn.tensor(8.13858402928325 , grad = 1.0)\n",
      "Loss at Epoch 1279 is : netwok_nn.tensor(8.096238411241536 , grad = 1.0)\n",
      "Loss at Epoch 1280 is : netwok_nn.tensor(8.054019997270567 , grad = 1.0)\n",
      "Loss at Epoch 1281 is : netwok_nn.tensor(8.011928696914271 , grad = 1.0)\n",
      "Loss at Epoch 1282 is : netwok_nn.tensor(7.9699644197277495 , grad = 1.0)\n",
      "Loss at Epoch 1283 is : netwok_nn.tensor(7.928127075277324 , grad = 1.0)\n",
      "Loss at Epoch 1284 is : netwok_nn.tensor(7.886416573140622 , grad = 1.0)\n",
      "Loss at Epoch 1285 is : netwok_nn.tensor(7.844832822906657 , grad = 1.0)\n",
      "Loss at Epoch 1286 is : netwok_nn.tensor(7.803375734175863 , grad = 1.0)\n",
      "Loss at Epoch 1287 is : netwok_nn.tensor(7.762045216560182 , grad = 1.0)\n",
      "Loss at Epoch 1288 is : netwok_nn.tensor(7.7208411796831635 , grad = 1.0)\n",
      "Loss at Epoch 1289 is : netwok_nn.tensor(7.679763533179955 , grad = 1.0)\n",
      "Loss at Epoch 1290 is : netwok_nn.tensor(7.638812186697461 , grad = 1.0)\n",
      "Loss at Epoch 1291 is : netwok_nn.tensor(7.597987049894364 , grad = 1.0)\n",
      "Loss at Epoch 1292 is : netwok_nn.tensor(7.557288032441208 , grad = 1.0)\n",
      "Loss at Epoch 1293 is : netwok_nn.tensor(7.516715044020479 , grad = 1.0)\n",
      "Loss at Epoch 1294 is : netwok_nn.tensor(7.476267994326685 , grad = 1.0)\n",
      "Loss at Epoch 1295 is : netwok_nn.tensor(7.435946793066398 , grad = 1.0)\n",
      "Loss at Epoch 1296 is : netwok_nn.tensor(7.395751349958367 , grad = 1.0)\n",
      "Loss at Epoch 1297 is : netwok_nn.tensor(7.355681574733592 , grad = 1.0)\n",
      "Loss at Epoch 1298 is : netwok_nn.tensor(7.315737377135378 , grad = 1.0)\n",
      "Loss at Epoch 1299 is : netwok_nn.tensor(7.275918666919446 , grad = 1.0)\n",
      "Loss at Epoch 1300 is : netwok_nn.tensor(7.2362253538539765 , grad = 1.0)\n",
      "Loss at Epoch 1301 is : netwok_nn.tensor(7.196657347719704 , grad = 1.0)\n",
      "Loss at Epoch 1302 is : netwok_nn.tensor(7.1572145583100415 , grad = 1.0)\n",
      "Loss at Epoch 1303 is : netwok_nn.tensor(7.11789689543109 , grad = 1.0)\n",
      "Loss at Epoch 1304 is : netwok_nn.tensor(7.078704268901764 , grad = 1.0)\n",
      "Loss at Epoch 1305 is : netwok_nn.tensor(7.039636588553887 , grad = 1.0)\n",
      "Loss at Epoch 1306 is : netwok_nn.tensor(7.0006937642322375 , grad = 1.0)\n",
      "Loss at Epoch 1307 is : netwok_nn.tensor(6.961875705794653 , grad = 1.0)\n",
      "Loss at Epoch 1308 is : netwok_nn.tensor(6.923182323112129 , grad = 1.0)\n",
      "Loss at Epoch 1309 is : netwok_nn.tensor(6.884613526068917 , grad = 1.0)\n",
      "Loss at Epoch 1310 is : netwok_nn.tensor(6.846169224562551 , grad = 1.0)\n",
      "Loss at Epoch 1311 is : netwok_nn.tensor(6.807849328504033 , grad = 1.0)\n",
      "Loss at Epoch 1312 is : netwok_nn.tensor(6.769653747817836 , grad = 1.0)\n",
      "Loss at Epoch 1313 is : netwok_nn.tensor(6.731582392442033 , grad = 1.0)\n",
      "Loss at Epoch 1314 is : netwok_nn.tensor(6.693635172328403 , grad = 1.0)\n",
      "Loss at Epoch 1315 is : netwok_nn.tensor(6.65581199744249 , grad = 1.0)\n",
      "Loss at Epoch 1316 is : netwok_nn.tensor(6.61811277776373 , grad = 1.0)\n",
      "Loss at Epoch 1317 is : netwok_nn.tensor(6.580537423285545 , grad = 1.0)\n",
      "Loss at Epoch 1318 is : netwok_nn.tensor(6.543085844015395 , grad = 1.0)\n",
      "Loss at Epoch 1319 is : netwok_nn.tensor(6.505757949974955 , grad = 1.0)\n",
      "Loss at Epoch 1320 is : netwok_nn.tensor(6.468553651200116 , grad = 1.0)\n",
      "Loss at Epoch 1321 is : netwok_nn.tensor(6.431472857741175 , grad = 1.0)\n",
      "Loss at Epoch 1322 is : netwok_nn.tensor(6.3945154796628785 , grad = 1.0)\n",
      "Loss at Epoch 1323 is : netwok_nn.tensor(6.357681427044555 , grad = 1.0)\n",
      "Loss at Epoch 1324 is : netwok_nn.tensor(6.320970609980186 , grad = 1.0)\n",
      "Loss at Epoch 1325 is : netwok_nn.tensor(6.284382938578551 , grad = 1.0)\n",
      "Loss at Epoch 1326 is : netwok_nn.tensor(6.247918322963288 , grad = 1.0)\n",
      "Loss at Epoch 1327 is : netwok_nn.tensor(6.21157667327304 , grad = 1.0)\n",
      "Loss at Epoch 1328 is : netwok_nn.tensor(6.175357899661524 , grad = 1.0)\n",
      "Loss at Epoch 1329 is : netwok_nn.tensor(6.139261912297672 , grad = 1.0)\n",
      "Loss at Epoch 1330 is : netwok_nn.tensor(6.103288621365718 , grad = 1.0)\n",
      "Loss at Epoch 1331 is : netwok_nn.tensor(6.067437937065319 , grad = 1.0)\n",
      "Loss at Epoch 1332 is : netwok_nn.tensor(6.031709769611657 , grad = 1.0)\n",
      "Loss at Epoch 1333 is : netwok_nn.tensor(5.99610402923557 , grad = 1.0)\n",
      "Loss at Epoch 1334 is : netwok_nn.tensor(5.960620626183641 , grad = 1.0)\n",
      "Loss at Epoch 1335 is : netwok_nn.tensor(5.925259470718328 , grad = 1.0)\n",
      "Loss at Epoch 1336 is : netwok_nn.tensor(5.890020473118059 , grad = 1.0)\n",
      "Loss at Epoch 1337 is : netwok_nn.tensor(5.854903543677393 , grad = 1.0)\n",
      "Loss at Epoch 1338 is : netwok_nn.tensor(5.819908592707086 , grad = 1.0)\n",
      "Loss at Epoch 1339 is : netwok_nn.tensor(5.785035530534236 , grad = 1.0)\n",
      "Loss at Epoch 1340 is : netwok_nn.tensor(5.750284267502411 , grad = 1.0)\n",
      "Loss at Epoch 1341 is : netwok_nn.tensor(5.715654713971748 , grad = 1.0)\n",
      "Loss at Epoch 1342 is : netwok_nn.tensor(5.681146780319081 , grad = 1.0)\n",
      "Loss at Epoch 1343 is : netwok_nn.tensor(5.646760376938086 , grad = 1.0)\n",
      "Loss at Epoch 1344 is : netwok_nn.tensor(5.612495414239374 , grad = 1.0)\n",
      "Loss at Epoch 1345 is : netwok_nn.tensor(5.578351802650634 , grad = 1.0)\n",
      "Loss at Epoch 1346 is : netwok_nn.tensor(5.544329452616766 , grad = 1.0)\n",
      "Loss at Epoch 1347 is : netwok_nn.tensor(5.510428274599978 , grad = 1.0)\n",
      "Loss at Epoch 1348 is : netwok_nn.tensor(5.47664817907997 , grad = 1.0)\n",
      "Loss at Epoch 1349 is : netwok_nn.tensor(5.442989076554004 , grad = 1.0)\n",
      "Loss at Epoch 1350 is : netwok_nn.tensor(5.409450877537058 , grad = 1.0)\n",
      "Loss at Epoch 1351 is : netwok_nn.tensor(5.376033492561998 , grad = 1.0)\n",
      "Loss at Epoch 1352 is : netwok_nn.tensor(5.3427368321796385 , grad = 1.0)\n",
      "Loss at Epoch 1353 is : netwok_nn.tensor(5.3095608069589435 , grad = 1.0)\n",
      "Loss at Epoch 1354 is : netwok_nn.tensor(5.27650532748713 , grad = 1.0)\n",
      "Loss at Epoch 1355 is : netwok_nn.tensor(5.243570304369796 , grad = 1.0)\n",
      "Loss at Epoch 1356 is : netwok_nn.tensor(5.210755648231096 , grad = 1.0)\n",
      "Loss at Epoch 1357 is : netwok_nn.tensor(5.1780612697138455 , grad = 1.0)\n",
      "Loss at Epoch 1358 is : netwok_nn.tensor(5.145487079479677 , grad = 1.0)\n",
      "Loss at Epoch 1359 is : netwok_nn.tensor(5.11303298820919 , grad = 1.0)\n",
      "Loss at Epoch 1360 is : netwok_nn.tensor(5.080698906602088 , grad = 1.0)\n",
      "Loss at Epoch 1361 is : netwok_nn.tensor(5.048484745377309 , grad = 1.0)\n",
      "Loss at Epoch 1362 is : netwok_nn.tensor(5.016390415273195 , grad = 1.0)\n",
      "Loss at Epoch 1363 is : netwok_nn.tensor(4.984415827047619 , grad = 1.0)\n",
      "Loss at Epoch 1364 is : netwok_nn.tensor(4.9525608914781625 , grad = 1.0)\n",
      "Loss at Epoch 1365 is : netwok_nn.tensor(4.92082551936223 , grad = 1.0)\n",
      "Loss at Epoch 1366 is : netwok_nn.tensor(4.889209621517235 , grad = 1.0)\n",
      "Loss at Epoch 1367 is : netwok_nn.tensor(4.857713108780711 , grad = 1.0)\n",
      "Loss at Epoch 1368 is : netwok_nn.tensor(4.8263358920105235 , grad = 1.0)\n",
      "Loss at Epoch 1369 is : netwok_nn.tensor(4.79507788208495 , grad = 1.0)\n",
      "Loss at Epoch 1370 is : netwok_nn.tensor(4.763938989902913 , grad = 1.0)\n",
      "Loss at Epoch 1371 is : netwok_nn.tensor(4.7329191263840835 , grad = 1.0)\n",
      "Loss at Epoch 1372 is : netwok_nn.tensor(4.702018202469068 , grad = 1.0)\n",
      "Loss at Epoch 1373 is : netwok_nn.tensor(4.671236129119574 , grad = 1.0)\n",
      "Loss at Epoch 1374 is : netwok_nn.tensor(4.640572817318526 , grad = 1.0)\n",
      "Loss at Epoch 1375 is : netwok_nn.tensor(4.6100281780702925 , grad = 1.0)\n",
      "Loss at Epoch 1376 is : netwok_nn.tensor(4.5796021224008 , grad = 1.0)\n",
      "Loss at Epoch 1377 is : netwok_nn.tensor(4.549294561357724 , grad = 1.0)\n",
      "Loss at Epoch 1378 is : netwok_nn.tensor(4.519105406010663 , grad = 1.0)\n",
      "Loss at Epoch 1379 is : netwok_nn.tensor(4.4890345674512755 , grad = 1.0)\n",
      "Loss at Epoch 1380 is : netwok_nn.tensor(4.459081956793475 , grad = 1.0)\n",
      "Loss at Epoch 1381 is : netwok_nn.tensor(4.429247485173608 , grad = 1.0)\n",
      "Loss at Epoch 1382 is : netwok_nn.tensor(4.399531063750606 , grad = 1.0)\n",
      "Loss at Epoch 1383 is : netwok_nn.tensor(4.36993260370616 , grad = 1.0)\n",
      "Loss at Epoch 1384 is : netwok_nn.tensor(4.3404520162449165 , grad = 1.0)\n",
      "Loss at Epoch 1385 is : netwok_nn.tensor(4.311089212594645 , grad = 1.0)\n",
      "Loss at Epoch 1386 is : netwok_nn.tensor(4.281844104006394 , grad = 1.0)\n",
      "Loss at Epoch 1387 is : netwok_nn.tensor(4.252716601754711 , grad = 1.0)\n",
      "Loss at Epoch 1388 is : netwok_nn.tensor(4.22370661713779 , grad = 1.0)\n",
      "Loss at Epoch 1389 is : netwok_nn.tensor(4.194814061477673 , grad = 1.0)\n",
      "Loss at Epoch 1390 is : netwok_nn.tensor(4.166038846120416 , grad = 1.0)\n",
      "Loss at Epoch 1391 is : netwok_nn.tensor(4.1373808824363065 , grad = 1.0)\n",
      "Loss at Epoch 1392 is : netwok_nn.tensor(4.108840081820011 , grad = 1.0)\n",
      "Loss at Epoch 1393 is : netwok_nn.tensor(4.080416355690794 , grad = 1.0)\n",
      "Loss at Epoch 1394 is : netwok_nn.tensor(4.0521096154926886 , grad = 1.0)\n",
      "Loss at Epoch 1395 is : netwok_nn.tensor(4.023919772694706 , grad = 1.0)\n",
      "Loss at Epoch 1396 is : netwok_nn.tensor(3.9958467387910033 , grad = 1.0)\n",
      "Loss at Epoch 1397 is : netwok_nn.tensor(3.9678904253010927 , grad = 1.0)\n",
      "Loss at Epoch 1398 is : netwok_nn.tensor(3.9400507437700445 , grad = 1.0)\n",
      "Loss at Epoch 1399 is : netwok_nn.tensor(3.912327605768663 , grad = 1.0)\n",
      "Loss at Epoch 1400 is : netwok_nn.tensor(3.8847209228937083 , grad = 1.0)\n",
      "Loss at Epoch 1401 is : netwok_nn.tensor(3.8572306067680717 , grad = 1.0)\n",
      "Loss at Epoch 1402 is : netwok_nn.tensor(3.8298565690410022 , grad = 1.0)\n",
      "Loss at Epoch 1403 is : netwok_nn.tensor(3.802598721388291 , grad = 1.0)\n",
      "Loss at Epoch 1404 is : netwok_nn.tensor(3.7754569755124794 , grad = 1.0)\n",
      "Loss at Epoch 1405 is : netwok_nn.tensor(3.748431243143063 , grad = 1.0)\n",
      "Loss at Epoch 1406 is : netwok_nn.tensor(3.7215214360367166 , grad = 1.0)\n",
      "Loss at Epoch 1407 is : netwok_nn.tensor(3.6947274659774796 , grad = 1.0)\n",
      "Loss at Epoch 1408 is : netwok_nn.tensor(3.6680492447769764 , grad = 1.0)\n",
      "Loss at Epoch 1409 is : netwok_nn.tensor(3.6414866842746227 , grad = 1.0)\n",
      "Loss at Epoch 1410 is : netwok_nn.tensor(3.615039696337851 , grad = 1.0)\n",
      "Loss at Epoch 1411 is : netwok_nn.tensor(3.5887081928623106 , grad = 1.0)\n",
      "Loss at Epoch 1412 is : netwok_nn.tensor(3.562492085772099 , grad = 1.0)\n",
      "Loss at Epoch 1413 is : netwok_nn.tensor(3.5363912870199647 , grad = 1.0)\n",
      "Loss at Epoch 1414 is : netwok_nn.tensor(3.5104057085875295 , grad = 1.0)\n",
      "Loss at Epoch 1415 is : netwok_nn.tensor(3.4845352624855197 , grad = 1.0)\n",
      "Loss at Epoch 1416 is : netwok_nn.tensor(3.458779860753989 , grad = 1.0)\n",
      "Loss at Epoch 1417 is : netwok_nn.tensor(3.4331394154625117 , grad = 1.0)\n",
      "Loss at Epoch 1418 is : netwok_nn.tensor(3.4076138387104487 , grad = 1.0)\n",
      "Loss at Epoch 1419 is : netwok_nn.tensor(3.3822030426271534 , grad = 1.0)\n",
      "Loss at Epoch 1420 is : netwok_nn.tensor(3.3569069393722013 , grad = 1.0)\n",
      "Loss at Epoch 1421 is : netwok_nn.tensor(3.3317254411356227 , grad = 1.0)\n",
      "Loss at Epoch 1422 is : netwok_nn.tensor(3.3066584601381392 , grad = 1.0)\n",
      "Loss at Epoch 1423 is : netwok_nn.tensor(3.281705908631372 , grad = 1.0)\n",
      "Loss at Epoch 1424 is : netwok_nn.tensor(3.256867698898115 , grad = 1.0)\n",
      "Loss at Epoch 1425 is : netwok_nn.tensor(3.23214374325254 , grad = 1.0)\n",
      "Loss at Epoch 1426 is : netwok_nn.tensor(3.2075339540404513 , grad = 1.0)\n",
      "Loss at Epoch 1427 is : netwok_nn.tensor(3.183038243639509 , grad = 1.0)\n",
      "Loss at Epoch 1428 is : netwok_nn.tensor(3.1586565244594884 , grad = 1.0)\n",
      "Loss at Epoch 1429 is : netwok_nn.tensor(3.1343887089425215 , grad = 1.0)\n",
      "Loss at Epoch 1430 is : netwok_nn.tensor(3.1102347095633047 , grad = 1.0)\n",
      "Loss at Epoch 1431 is : netwok_nn.tensor(3.0861944388293967 , grad = 1.0)\n",
      "Loss at Epoch 1432 is : netwok_nn.tensor(3.0622678092814266 , grad = 1.0)\n",
      "Loss at Epoch 1433 is : netwok_nn.tensor(3.038454733493369 , grad = 1.0)\n",
      "Loss at Epoch 1434 is : netwok_nn.tensor(3.01475512407276 , grad = 1.0)\n",
      "Loss at Epoch 1435 is : netwok_nn.tensor(2.991168893660995 , grad = 1.0)\n",
      "Loss at Epoch 1436 is : netwok_nn.tensor(2.9676959549335384 , grad = 1.0)\n",
      "Loss at Epoch 1437 is : netwok_nn.tensor(2.9443362206002 , grad = 1.0)\n",
      "Loss at Epoch 1438 is : netwok_nn.tensor(2.9210896034053913 , grad = 1.0)\n",
      "Loss at Epoch 1439 is : netwok_nn.tensor(2.8979560161283793 , grad = 1.0)\n",
      "Loss at Epoch 1440 is : netwok_nn.tensor(2.8749353715835393 , grad = 1.0)\n",
      "Loss at Epoch 1441 is : netwok_nn.tensor(2.852027582620622 , grad = 1.0)\n",
      "Loss at Epoch 1442 is : netwok_nn.tensor(2.829232562125024 , grad = 1.0)\n",
      "Loss at Epoch 1443 is : netwok_nn.tensor(2.806550223018036 , grad = 1.0)\n",
      "Loss at Epoch 1444 is : netwok_nn.tensor(2.7839804782571127 , grad = 1.0)\n",
      "Loss at Epoch 1445 is : netwok_nn.tensor(2.7615232408361607 , grad = 1.0)\n",
      "Loss at Epoch 1446 is : netwok_nn.tensor(2.739178423785762 , grad = 1.0)\n",
      "Loss at Epoch 1447 is : netwok_nn.tensor(2.716945940173498 , grad = 1.0)\n",
      "Loss at Epoch 1448 is : netwok_nn.tensor(2.694825703104172 , grad = 1.0)\n",
      "Loss at Epoch 1449 is : netwok_nn.tensor(2.672817625720122 , grad = 1.0)\n",
      "Loss at Epoch 1450 is : netwok_nn.tensor(2.650921621201461 , grad = 1.0)\n",
      "Loss at Epoch 1451 is : netwok_nn.tensor(2.6291376027663893 , grad = 1.0)\n",
      "Loss at Epoch 1452 is : netwok_nn.tensor(2.6074654836714393 , grad = 1.0)\n",
      "Loss at Epoch 1453 is : netwok_nn.tensor(2.5859051772117745 , grad = 1.0)\n",
      "Loss at Epoch 1454 is : netwok_nn.tensor(2.5644565967214596 , grad = 1.0)\n",
      "Loss at Epoch 1455 is : netwok_nn.tensor(2.5431196555737516 , grad = 1.0)\n",
      "Loss at Epoch 1456 is : netwok_nn.tensor(2.52189426718138 , grad = 1.0)\n",
      "Loss at Epoch 1457 is : netwok_nn.tensor(2.500780344996835 , grad = 1.0)\n",
      "Loss at Epoch 1458 is : netwok_nn.tensor(2.479777802512648 , grad = 1.0)\n",
      "Loss at Epoch 1459 is : netwok_nn.tensor(2.458886553261681 , grad = 1.0)\n",
      "Loss at Epoch 1460 is : netwok_nn.tensor(2.4381065108174216 , grad = 1.0)\n",
      "Loss at Epoch 1461 is : netwok_nn.tensor(2.4174375887942774 , grad = 1.0)\n",
      "Loss at Epoch 1462 is : netwok_nn.tensor(2.3968797008478537 , grad = 1.0)\n",
      "Loss at Epoch 1463 is : netwok_nn.tensor(2.376432760675274 , grad = 1.0)\n",
      "Loss at Epoch 1464 is : netwok_nn.tensor(2.356096682015441 , grad = 1.0)\n",
      "Loss at Epoch 1465 is : netwok_nn.tensor(2.3358713786493617 , grad = 1.0)\n",
      "Loss at Epoch 1466 is : netwok_nn.tensor(2.315756764400447 , grad = 1.0)\n",
      "Loss at Epoch 1467 is : netwok_nn.tensor(2.2957527531347885 , grad = 1.0)\n",
      "Loss at Epoch 1468 is : netwok_nn.tensor(2.2758592587614803 , grad = 1.0)\n",
      "Loss at Epoch 1469 is : netwok_nn.tensor(2.256076195232917 , grad = 1.0)\n",
      "Loss at Epoch 1470 is : netwok_nn.tensor(2.2364034765451017 , grad = 1.0)\n",
      "Loss at Epoch 1471 is : netwok_nn.tensor(2.2168410167379484 , grad = 1.0)\n",
      "Loss at Epoch 1472 is : netwok_nn.tensor(2.1973887298955903 , grad = 1.0)\n",
      "Loss at Epoch 1473 is : netwok_nn.tensor(2.178046530146684 , grad = 1.0)\n",
      "Loss at Epoch 1474 is : netwok_nn.tensor(2.158814331664735 , grad = 1.0)\n",
      "Loss at Epoch 1475 is : netwok_nn.tensor(2.139692048668398 , grad = 1.0)\n",
      "Loss at Epoch 1476 is : netwok_nn.tensor(2.1206795954217945 , grad = 1.0)\n",
      "Loss at Epoch 1477 is : netwok_nn.tensor(2.1017768862348145 , grad = 1.0)\n",
      "Loss at Epoch 1478 is : netwok_nn.tensor(2.082983835463457 , grad = 1.0)\n",
      "Loss at Epoch 1479 is : netwok_nn.tensor(2.0643003575101435 , grad = 1.0)\n",
      "Loss at Epoch 1480 is : netwok_nn.tensor(2.0457263668240087 , grad = 1.0)\n",
      "Loss at Epoch 1481 is : netwok_nn.tensor(2.0272617779012583 , grad = 1.0)\n",
      "Loss at Epoch 1482 is : netwok_nn.tensor(2.0089065052854593 , grad = 1.0)\n",
      "Loss at Epoch 1483 is : netwok_nn.tensor(1.9906604635678977 , grad = 1.0)\n",
      "Loss at Epoch 1484 is : netwok_nn.tensor(1.9725235673878736 , grad = 1.0)\n",
      "Loss at Epoch 1485 is : netwok_nn.tensor(1.954495731433036 , grad = 1.0)\n",
      "Loss at Epoch 1486 is : netwok_nn.tensor(1.9365768704397204 , grad = 1.0)\n",
      "Loss at Epoch 1487 is : netwok_nn.tensor(1.9187668991932616 , grad = 1.0)\n",
      "Loss at Epoch 1488 is : netwok_nn.tensor(1.9010657325283367 , grad = 1.0)\n",
      "Loss at Epoch 1489 is : netwok_nn.tensor(1.8834732853292888 , grad = 1.0)\n",
      "Loss at Epoch 1490 is : netwok_nn.tensor(1.8659894725304675 , grad = 1.0)\n",
      "Loss at Epoch 1491 is : netwok_nn.tensor(1.8486142091165558 , grad = 1.0)\n",
      "Loss at Epoch 1492 is : netwok_nn.tensor(1.831347410122905 , grad = 1.0)\n",
      "Loss at Epoch 1493 is : netwok_nn.tensor(1.8141889906358748 , grad = 1.0)\n",
      "Loss at Epoch 1494 is : netwok_nn.tensor(1.7971388657931715 , grad = 1.0)\n",
      "Loss at Epoch 1495 is : netwok_nn.tensor(1.780196950784192 , grad = 1.0)\n",
      "Loss at Epoch 1496 is : netwok_nn.tensor(1.7633631608503504 , grad = 1.0)\n",
      "Loss at Epoch 1497 is : netwok_nn.tensor(1.746637411285429 , grad = 1.0)\n",
      "Loss at Epoch 1498 is : netwok_nn.tensor(1.73001961743593 , grad = 1.0)\n",
      "Loss at Epoch 1499 is : netwok_nn.tensor(1.7135096947013972 , grad = 1.0)\n",
      "Loss at Epoch 1500 is : netwok_nn.tensor(1.697107558534777 , grad = 1.0)\n",
      "Loss at Epoch 1501 is : netwok_nn.tensor(1.680813124442765 , grad = 1.0)\n",
      "Loss at Epoch 1502 is : netwok_nn.tensor(1.6646263079861479 , grad = 1.0)\n",
      "Loss at Epoch 1503 is : netwok_nn.tensor(1.6485470247801484 , grad = 1.0)\n",
      "Loss at Epoch 1504 is : netwok_nn.tensor(1.632575190494793 , grad = 1.0)\n",
      "Loss at Epoch 1505 is : netwok_nn.tensor(1.6167107208552463 , grad = 1.0)\n",
      "Loss at Epoch 1506 is : netwok_nn.tensor(1.600953531642166 , grad = 1.0)\n",
      "Loss at Epoch 1507 is : netwok_nn.tensor(1.5853035386920653 , grad = 1.0)\n",
      "Loss at Epoch 1508 is : netwok_nn.tensor(1.5697606578976473 , grad = 1.0)\n",
      "Loss at Epoch 1509 is : netwok_nn.tensor(1.554324805208187 , grad = 1.0)\n",
      "Loss at Epoch 1510 is : netwok_nn.tensor(1.5389958966298625 , grad = 1.0)\n",
      "Loss at Epoch 1511 is : netwok_nn.tensor(1.5237738482261278 , grad = 1.0)\n",
      "Loss at Epoch 1512 is : netwok_nn.tensor(1.5086585761180777 , grad = 1.0)\n",
      "Loss at Epoch 1513 is : netwok_nn.tensor(1.493649996484782 , grad = 1.0)\n",
      "Loss at Epoch 1514 is : netwok_nn.tensor(1.47874802556367 , grad = 1.0)\n",
      "Loss at Epoch 1515 is : netwok_nn.tensor(1.4639525796508799 , grad = 1.0)\n",
      "Loss at Epoch 1516 is : netwok_nn.tensor(1.4492635751016232 , grad = 1.0)\n",
      "Loss at Epoch 1517 is : netwok_nn.tensor(1.4346809283305533 , grad = 1.0)\n",
      "Loss at Epoch 1518 is : netwok_nn.tensor(1.4202045558121212 , grad = 1.0)\n",
      "Loss at Epoch 1519 is : netwok_nn.tensor(1.405834374080946 , grad = 1.0)\n",
      "Loss at Epoch 1520 is : netwok_nn.tensor(1.3915702997321864 , grad = 1.0)\n",
      "Loss at Epoch 1521 is : netwok_nn.tensor(1.3774122494218852 , grad = 1.0)\n",
      "Loss at Epoch 1522 is : netwok_nn.tensor(1.3633601398673707 , grad = 1.0)\n",
      "Loss at Epoch 1523 is : netwok_nn.tensor(1.3494138878475943 , grad = 1.0)\n",
      "Loss at Epoch 1524 is : netwok_nn.tensor(1.3355734102035148 , grad = 1.0)\n",
      "Loss at Epoch 1525 is : netwok_nn.tensor(1.3218386238384705 , grad = 1.0)\n",
      "Loss at Epoch 1526 is : netwok_nn.tensor(1.308209445718541 , grad = 1.0)\n",
      "Loss at Epoch 1527 is : netwok_nn.tensor(1.29468579287293 , grad = 1.0)\n",
      "Loss at Epoch 1528 is : netwok_nn.tensor(1.2812675823943251 , grad = 1.0)\n",
      "Loss at Epoch 1529 is : netwok_nn.tensor(1.2679547314392723 , grad = 1.0)\n",
      "Loss at Epoch 1530 is : netwok_nn.tensor(1.2547471572285653 , grad = 1.0)\n",
      "Loss at Epoch 1531 is : netwok_nn.tensor(1.2416447770475991 , grad = 1.0)\n",
      "Loss at Epoch 1532 is : netwok_nn.tensor(1.2286475082467572 , grad = 1.0)\n",
      "Loss at Epoch 1533 is : netwok_nn.tensor(1.2157552682417803 , grad = 1.0)\n",
      "Loss at Epoch 1534 is : netwok_nn.tensor(1.2029679745141515 , grad = 1.0)\n",
      "Loss at Epoch 1535 is : netwok_nn.tensor(1.1902855446114602 , grad = 1.0)\n",
      "Loss at Epoch 1536 is : netwok_nn.tensor(1.1777078961477934 , grad = 1.0)\n",
      "Loss at Epoch 1537 is : netwok_nn.tensor(1.1652349468041017 , grad = 1.0)\n",
      "Loss at Epoch 1538 is : netwok_nn.tensor(1.1528666143285766 , grad = 1.0)\n",
      "Loss at Epoch 1539 is : netwok_nn.tensor(1.1406028165370365 , grad = 1.0)\n",
      "Loss at Epoch 1540 is : netwok_nn.tensor(1.1284434713133058 , grad = 1.0)\n",
      "Loss at Epoch 1541 is : netwok_nn.tensor(1.1163884966095923 , grad = 1.0)\n",
      "Loss at Epoch 1542 is : netwok_nn.tensor(1.1044378104468557 , grad = 1.0)\n",
      "Loss at Epoch 1543 is : netwok_nn.tensor(1.0925913309152104 , grad = 1.0)\n",
      "Loss at Epoch 1544 is : netwok_nn.tensor(1.0808489761742792 , grad = 1.0)\n",
      "Loss at Epoch 1545 is : netwok_nn.tensor(1.0692106644535988 , grad = 1.0)\n",
      "Loss at Epoch 1546 is : netwok_nn.tensor(1.0576763140529815 , grad = 1.0)\n",
      "Loss at Epoch 1547 is : netwok_nn.tensor(1.0462458433429076 , grad = 1.0)\n",
      "Loss at Epoch 1548 is : netwok_nn.tensor(1.0349191707649026 , grad = 1.0)\n",
      "Loss at Epoch 1549 is : netwok_nn.tensor(1.0236962148319178 , grad = 1.0)\n",
      "Loss at Epoch 1550 is : netwok_nn.tensor(1.012576894128712 , grad = 1.0)\n",
      "Loss at Epoch 1551 is : netwok_nn.tensor(1.0015611273122318 , grad = 1.0)\n",
      "Loss at Epoch 1552 is : netwok_nn.tensor(0.9906488331120049 , grad = 1.0)\n",
      "Loss at Epoch 1553 is : netwok_nn.tensor(0.9798399303305001 , grad = 1.0)\n",
      "Loss at Epoch 1554 is : netwok_nn.tensor(0.9691343378435298 , grad = 1.0)\n",
      "Loss at Epoch 1555 is : netwok_nn.tensor(0.9585319746006158 , grad = 1.0)\n",
      "Loss at Epoch 1556 is : netwok_nn.tensor(0.94803275962539 , grad = 1.0)\n",
      "Loss at Epoch 1557 is : netwok_nn.tensor(0.9376366120159537 , grad = 1.0)\n",
      "Loss at Epoch 1558 is : netwok_nn.tensor(0.9273434509452718 , grad = 1.0)\n",
      "Loss at Epoch 1559 is : netwok_nn.tensor(0.9171531956615598 , grad = 1.0)\n",
      "Loss at Epoch 1560 is : netwok_nn.tensor(0.9070657654886506 , grad = 1.0)\n",
      "Loss at Epoch 1561 is : netwok_nn.tensor(0.8970810798263816 , grad = 1.0)\n",
      "Loss at Epoch 1562 is : netwok_nn.tensor(0.8871990581509789 , grad = 1.0)\n",
      "Loss at Epoch 1563 is : netwok_nn.tensor(0.8774196200154358 , grad = 1.0)\n",
      "Loss at Epoch 1564 is : netwok_nn.tensor(0.8677426850498887 , grad = 1.0)\n",
      "Loss at Epoch 1565 is : netwok_nn.tensor(0.8581681729619993 , grad = 1.0)\n",
      "Loss at Epoch 1566 is : netwok_nn.tensor(0.8486960035373454 , grad = 1.0)\n",
      "Loss at Epoch 1567 is : netwok_nn.tensor(0.8393260966397739 , grad = 1.0)\n",
      "Loss at Epoch 1568 is : netwok_nn.tensor(0.8300583722118057 , grad = 1.0)\n",
      "Loss at Epoch 1569 is : netwok_nn.tensor(0.8208927502750012 , grad = 1.0)\n",
      "Loss at Epoch 1570 is : netwok_nn.tensor(0.8118291509303371 , grad = 1.0)\n",
      "Loss at Epoch 1571 is : netwok_nn.tensor(0.8028674943585871 , grad = 1.0)\n",
      "Loss at Epoch 1572 is : netwok_nn.tensor(0.7940077008206989 , grad = 1.0)\n",
      "Loss at Epoch 1573 is : netwok_nn.tensor(0.785249690658162 , grad = 1.0)\n",
      "Loss at Epoch 1574 is : netwok_nn.tensor(0.7765933842933945 , grad = 1.0)\n",
      "Loss at Epoch 1575 is : netwok_nn.tensor(0.7680387022301067 , grad = 1.0)\n",
      "Loss at Epoch 1576 is : netwok_nn.tensor(0.7595855650536832 , grad = 1.0)\n",
      "Loss at Epoch 1577 is : netwok_nn.tensor(0.751233893431545 , grad = 1.0)\n",
      "Loss at Epoch 1578 is : netwok_nn.tensor(0.7429836081135381 , grad = 1.0)\n",
      "Loss at Epoch 1579 is : netwok_nn.tensor(0.7348346299322848 , grad = 1.0)\n",
      "Loss at Epoch 1580 is : netwok_nn.tensor(0.7267868798035702 , grad = 1.0)\n",
      "Loss at Epoch 1581 is : netwok_nn.tensor(0.7188402787267026 , grad = 1.0)\n",
      "Loss at Epoch 1582 is : netwok_nn.tensor(0.710994747784878 , grad = 1.0)\n",
      "Loss at Epoch 1583 is : netwok_nn.tensor(0.703250208145564 , grad = 1.0)\n",
      "Loss at Epoch 1584 is : netwok_nn.tensor(0.695606581060843 , grad = 1.0)\n",
      "Loss at Epoch 1585 is : netwok_nn.tensor(0.688063787867796 , grad = 1.0)\n",
      "Loss at Epoch 1586 is : netwok_nn.tensor(0.6806217499888554 , grad = 1.0)\n",
      "Loss at Epoch 1587 is : netwok_nn.tensor(0.6732803889321685 , grad = 1.0)\n",
      "Loss at Epoch 1588 is : netwok_nn.tensor(0.6660396262919666 , grad = 1.0)\n",
      "Loss at Epoch 1589 is : netwok_nn.tensor(0.658899383748918 , grad = 1.0)\n",
      "Loss at Epoch 1590 is : netwok_nn.tensor(0.6518595830704877 , grad = 1.0)\n",
      "Loss at Epoch 1591 is : netwok_nn.tensor(0.6449201461112922 , grad = 1.0)\n",
      "Loss at Epoch 1592 is : netwok_nn.tensor(0.6380809948134626 , grad = 1.0)\n",
      "Loss at Epoch 1593 is : netwok_nn.tensor(0.6313420512069893 , grad = 1.0)\n",
      "Loss at Epoch 1594 is : netwok_nn.tensor(0.6247032374100812 , grad = 1.0)\n",
      "Loss at Epoch 1595 is : netwok_nn.tensor(0.6181644756295209 , grad = 1.0)\n",
      "Loss at Epoch 1596 is : netwok_nn.tensor(0.6117256881610025 , grad = 1.0)\n",
      "Loss at Epoch 1597 is : netwok_nn.tensor(0.6053867973894875 , grad = 1.0)\n",
      "Loss at Epoch 1598 is : netwok_nn.tensor(0.5991477257895502 , grad = 1.0)\n",
      "Loss at Epoch 1599 is : netwok_nn.tensor(0.5930083959257206 , grad = 1.0)\n",
      "Loss at Epoch 1600 is : netwok_nn.tensor(0.5869687304528302 , grad = 1.0)\n",
      "Loss at Epoch 1601 is : netwok_nn.tensor(0.5810286521163492 , grad = 1.0)\n",
      "Loss at Epoch 1602 is : netwok_nn.tensor(0.5751880837527272 , grad = 1.0)\n",
      "Loss at Epoch 1603 is : netwok_nn.tensor(0.5694469482897266 , grad = 1.0)\n",
      "Loss at Epoch 1604 is : netwok_nn.tensor(0.5638051687467684 , grad = 1.0)\n",
      "Loss at Epoch 1605 is : netwok_nn.tensor(0.5582626682352514 , grad = 1.0)\n",
      "Loss at Epoch 1606 is : netwok_nn.tensor(0.5528193699588904 , grad = 1.0)\n",
      "Loss at Epoch 1607 is : netwok_nn.tensor(0.5474751972140456 , grad = 1.0)\n",
      "Loss at Epoch 1608 is : netwok_nn.tensor(0.542230073390051 , grad = 1.0)\n",
      "Loss at Epoch 1609 is : netwok_nn.tensor(0.5370839219695293 , grad = 1.0)\n",
      "Loss at Epoch 1610 is : netwok_nn.tensor(0.5320366665287252 , grad = 1.0)\n",
      "Loss at Epoch 1611 is : netwok_nn.tensor(0.5270882307378185 , grad = 1.0)\n",
      "Loss at Epoch 1612 is : netwok_nn.tensor(0.522238538361244 , grad = 1.0)\n",
      "Loss at Epoch 1613 is : netwok_nn.tensor(0.5174875132580055 , grad = 1.0)\n",
      "Loss at Epoch 1614 is : netwok_nn.tensor(0.5128350793819874 , grad = 1.0)\n",
      "Loss at Epoch 1615 is : netwok_nn.tensor(0.5082811607822694 , grad = 1.0)\n",
      "Loss at Epoch 1616 is : netwok_nn.tensor(0.5038256816034259 , grad = 1.0)\n",
      "Loss at Epoch 1617 is : netwok_nn.tensor(0.4994685660858415 , grad = 1.0)\n",
      "Loss at Epoch 1618 is : netwok_nn.tensor(0.4952097385660011 , grad = 1.0)\n",
      "Loss at Epoch 1619 is : netwok_nn.tensor(0.49104912347680113 , grad = 1.0)\n",
      "Loss at Epoch 1620 is : netwok_nn.tensor(0.4869866453478331 , grad = 1.0)\n",
      "Loss at Epoch 1621 is : netwok_nn.tensor(0.4830222288056939 , grad = 1.0)\n",
      "Loss at Epoch 1622 is : netwok_nn.tensor(0.47915579857425866 , grad = 1.0)\n",
      "Loss at Epoch 1623 is : netwok_nn.tensor(0.4753872794749822 , grad = 1.0)\n",
      "Loss at Epoch 1624 is : netwok_nn.tensor(0.4717165964271784 , grad = 1.0)\n",
      "Loss at Epoch 1625 is : netwok_nn.tensor(0.46814367444830296 , grad = 1.0)\n",
      "Loss at Epoch 1626 is : netwok_nn.tensor(0.46466843865423324 , grad = 1.0)\n",
      "Loss at Epoch 1627 is : netwok_nn.tensor(0.4612908142595403 , grad = 1.0)\n",
      "Loss at Epoch 1628 is : netwok_nn.tensor(0.45801072657776737 , grad = 1.0)\n",
      "Loss at Epoch 1629 is : netwok_nn.tensor(0.45482810102169496 , grad = 1.0)\n",
      "Loss at Epoch 1630 is : netwok_nn.tensor(0.45174286310360595 , grad = 1.0)\n",
      "Loss at Epoch 1631 is : netwok_nn.tensor(0.4487549384355536 , grad = 1.0)\n",
      "Loss at Epoch 1632 is : netwok_nn.tensor(0.44586425272961167 , grad = 1.0)\n",
      "Loss at Epoch 1633 is : netwok_nn.tensor(0.4430707317981416 , grad = 1.0)\n",
      "Loss at Epoch 1634 is : netwok_nn.tensor(0.4403743015540355 , grad = 1.0)\n",
      "Loss at Epoch 1635 is : netwok_nn.tensor(0.4377748880109673 , grad = 1.0)\n",
      "Loss at Epoch 1636 is : netwok_nn.tensor(0.4352724172836424 , grad = 1.0)\n",
      "Loss at Epoch 1637 is : netwok_nn.tensor(0.43286681558803247 , grad = 1.0)\n",
      "Loss at Epoch 1638 is : netwok_nn.tensor(0.4305580092416158 , grad = 1.0)\n",
      "Loss at Epoch 1639 is : netwok_nn.tensor(0.4283459246636104 , grad = 1.0)\n",
      "Loss at Epoch 1640 is : netwok_nn.tensor(0.4262304883752092 , grad = 1.0)\n",
      "Loss at Epoch 1641 is : netwok_nn.tensor(0.4242116269997978 , grad = 1.0)\n",
      "Loss at Epoch 1642 is : netwok_nn.tensor(0.4222892672631793 , grad = 1.0)\n",
      "Loss at Epoch 1643 is : netwok_nn.tensor(0.4204633359938002 , grad = 1.0)\n",
      "Loss at Epoch 1644 is : netwok_nn.tensor(0.41873376012295177 , grad = 1.0)\n",
      "Loss at Epoch 1645 is : netwok_nn.tensor(0.417100466684991 , grad = 1.0)\n",
      "Loss at Epoch 1646 is : netwok_nn.tensor(0.4155633828175398 , grad = 1.0)\n",
      "Loss at Epoch 1647 is : netwok_nn.tensor(0.4141224357616898 , grad = 1.0)\n",
      "Loss at Epoch 1648 is : netwok_nn.tensor(0.41277755286220147 , grad = 1.0)\n",
      "Loss at Epoch 1649 is : netwok_nn.tensor(0.4115286615676915 , grad = 1.0)\n",
      "Loss at Epoch 1650 is : netwok_nn.tensor(0.4103756894308267 , grad = 1.0)\n",
      "Loss at Epoch 1651 is : netwok_nn.tensor(0.4093185641085065 , grad = 1.0)\n",
      "Loss at Epoch 1652 is : netwok_nn.tensor(0.40835721336204467 , grad = 1.0)\n",
      "Loss at Epoch 1653 is : netwok_nn.tensor(0.40749156505733775 , grad = 1.0)\n",
      "Loss at Epoch 1654 is : netwok_nn.tensor(0.40672154716504844 , grad = 1.0)\n",
      "Loss at Epoch 1655 is : netwok_nn.tensor(0.4060470877607609 , grad = 1.0)\n",
      "Loss at Epoch 1656 is : netwok_nn.tensor(0.40546811502514546 , grad = 1.0)\n",
      "Loss at Epoch 1657 is : netwok_nn.tensor(0.4049845572441167 , grad = 1.0)\n",
      "Loss at Epoch 1658 is : netwok_nn.tensor(0.40459634280898493 , grad = 1.0)\n",
      "Loss at Epoch 1659 is : netwok_nn.tensor(0.4043034002166004 , grad = 1.0)\n",
      "Loss at Epoch 1660 is : netwok_nn.tensor(0.4041056580695037 , grad = 1.0)\n",
      "Loss at Epoch 1661 is : netwok_nn.tensor(0.4040030450760519 , grad = 1.0)\n",
      "Loss at Epoch 1662 is : netwok_nn.tensor(0.4039954900505593 , grad = 1.0)\n",
      "Loss at Epoch 1663 is : netwok_nn.tensor(0.40408292191342243 , grad = 1.0)\n",
      "Loss at Epoch 1664 is : netwok_nn.tensor(0.40426526969123805 , grad = 1.0)\n",
      "Loss at Epoch 1665 is : netwok_nn.tensor(0.40454246251693177 , grad = 1.0)\n",
      "Loss at Epoch 1666 is : netwok_nn.tensor(0.4049144296298536 , grad = 1.0)\n",
      "Loss at Epoch 1667 is : netwok_nn.tensor(0.4053811003758962 , grad = 1.0)\n",
      "Loss at Epoch 1668 is : netwok_nn.tensor(0.40594240420759564 , grad = 1.0)\n",
      "Loss at Epoch 1669 is : netwok_nn.tensor(0.40659827068422244 , grad = 1.0)\n",
      "Loss at Epoch 1670 is : netwok_nn.tensor(0.40734862947187556 , grad = 1.0)\n",
      "Loss at Epoch 1671 is : netwok_nn.tensor(0.40819341034356454 , grad = 1.0)\n",
      "Loss at Epoch 1672 is : netwok_nn.tensor(0.40913254317929515 , grad = 1.0)\n",
      "Loss at Epoch 1673 is : netwok_nn.tensor(0.41016595796613475 , grad = 1.0)\n",
      "Loss at Epoch 1674 is : netwok_nn.tensor(0.41129358479828965 , grad = 1.0)\n",
      "Loss at Epoch 1675 is : netwok_nn.tensor(0.41251535387716187 , grad = 1.0)\n",
      "Loss at Epoch 1676 is : netwok_nn.tensor(0.4138311955114128 , grad = 1.0)\n",
      "Loss at Epoch 1677 is : netwok_nn.tensor(0.41524104011700297 , grad = 1.0)\n",
      "Loss at Epoch 1678 is : netwok_nn.tensor(0.4167448182172517 , grad = 1.0)\n",
      "Loss at Epoch 1679 is : netwok_nn.tensor(0.4183424604428698 , grad = 1.0)\n",
      "Loss at Epoch 1680 is : netwok_nn.tensor(0.42003389753199266 , grad = 1.0)\n",
      "Loss at Epoch 1681 is : netwok_nn.tensor(0.4218190603302099 , grad = 1.0)\n",
      "Loss at Epoch 1682 is : netwok_nn.tensor(0.4236978797905911 , grad = 1.0)\n",
      "Loss at Epoch 1683 is : netwok_nn.tensor(0.4256702869736948 , grad = 1.0)\n",
      "Loss at Epoch 1684 is : netwok_nn.tensor(0.42773621304758747 , grad = 1.0)\n",
      "Loss at Epoch 1685 is : netwok_nn.tensor(0.4298955892878378 , grad = 1.0)\n",
      "Loss at Epoch 1686 is : netwok_nn.tensor(0.43214834707752187 , grad = 1.0)\n",
      "Loss at Epoch 1687 is : netwok_nn.tensor(0.4344944179072132 , grad = 1.0)\n",
      "Loss at Epoch 1688 is : netwok_nn.tensor(0.43693373337496866 , grad = 1.0)\n",
      "Loss at Epoch 1689 is : netwok_nn.tensor(0.4394662251863024 , grad = 1.0)\n",
      "Loss at Epoch 1690 is : netwok_nn.tensor(0.4420918251541705 , grad = 1.0)\n",
      "Loss at Epoch 1691 is : netwok_nn.tensor(0.44481046519892176 , grad = 1.0)\n",
      "Loss at Epoch 1692 is : netwok_nn.tensor(0.4476220773482741 , grad = 1.0)\n",
      "Loss at Epoch 1693 is : netwok_nn.tensor(0.4505265937372565 , grad = 1.0)\n",
      "Loss at Epoch 1694 is : netwok_nn.tensor(0.45352394660816153 , grad = 1.0)\n",
      "Loss at Epoch 1695 is : netwok_nn.tensor(0.4566140683104885 , grad = 1.0)\n",
      "Loss at Epoch 1696 is : netwok_nn.tensor(0.4597968913008726 , grad = 1.0)\n",
      "Loss at Epoch 1697 is : netwok_nn.tensor(0.46307234814301196 , grad = 1.0)\n",
      "Loss at Epoch 1698 is : netwok_nn.tensor(0.46644037150759843 , grad = 1.0)\n",
      "Loss at Epoch 1699 is : netwok_nn.tensor(0.46990089417222086 , grad = 1.0)\n",
      "Loss at Epoch 1700 is : netwok_nn.tensor(0.4734538490212806 , grad = 1.0)\n",
      "Loss at Epoch 1701 is : netwok_nn.tensor(0.47709916904588817 , grad = 1.0)\n",
      "Loss at Epoch 1702 is : netwok_nn.tensor(0.4808367873437587 , grad = 1.0)\n",
      "Loss at Epoch 1703 is : netwok_nn.tensor(0.4846666371191018 , grad = 1.0)\n",
      "Loss at Epoch 1704 is : netwok_nn.tensor(0.4885886516825042 , grad = 1.0)\n",
      "Loss at Epoch 1705 is : netwok_nn.tensor(0.4926027644507924 , grad = 1.0)\n",
      "Loss at Epoch 1706 is : netwok_nn.tensor(0.4967089089469136 , grad = 1.0)\n",
      "Loss at Epoch 1707 is : netwok_nn.tensor(0.500907018799789 , grad = 1.0)\n",
      "Loss at Epoch 1708 is : netwok_nn.tensor(0.5051970277441692 , grad = 1.0)\n",
      "Loss at Epoch 1709 is : netwok_nn.tensor(0.5095788696204794 , grad = 1.0)\n",
      "Loss at Epoch 1710 is : netwok_nn.tensor(0.5140524783746556 , grad = 1.0)\n",
      "Loss at Epoch 1711 is : netwok_nn.tensor(0.5186177880579846 , grad = 1.0)\n",
      "Loss at Epoch 1712 is : netwok_nn.tensor(0.5232747328269263 , grad = 1.0)\n",
      "Loss at Epoch 1713 is : netwok_nn.tensor(0.5280232469429249 , grad = 1.0)\n",
      "Loss at Epoch 1714 is : netwok_nn.tensor(0.5328632647722304 , grad = 1.0)\n",
      "Loss at Epoch 1715 is : netwok_nn.tensor(0.5377947207856967 , grad = 1.0)\n",
      "Loss at Epoch 1716 is : netwok_nn.tensor(0.5428175495585801 , grad = 1.0)\n",
      "Loss at Epoch 1717 is : netwok_nn.tensor(0.547931685770333 , grad = 1.0)\n",
      "Loss at Epoch 1718 is : netwok_nn.tensor(0.5531370642043733 , grad = 1.0)\n",
      "Loss at Epoch 1719 is : netwok_nn.tensor(0.558433619747876 , grad = 1.0)\n",
      "Loss at Epoch 1720 is : netwok_nn.tensor(0.563821287391533 , grad = 1.0)\n",
      "Loss at Epoch 1721 is : netwok_nn.tensor(0.5693000022293149 , grad = 1.0)\n",
      "Loss at Epoch 1722 is : netwok_nn.tensor(0.5748696994582226 , grad = 1.0)\n",
      "Loss at Epoch 1723 is : netwok_nn.tensor(0.5805303143780371 , grad = 1.0)\n",
      "Loss at Epoch 1724 is : netwok_nn.tensor(0.586281782391059 , grad = 1.0)\n",
      "Loss at Epoch 1725 is : netwok_nn.tensor(0.592124039001838 , grad = 1.0)\n",
      "Loss at Epoch 1726 is : netwok_nn.tensor(0.5980570198168972 , grad = 1.0)\n",
      "Loss at Epoch 1727 is : netwok_nn.tensor(0.6040806605444508 , grad = 1.0)\n",
      "Loss at Epoch 1728 is : netwok_nn.tensor(0.6101948969941131 , grad = 1.0)\n",
      "Loss at Epoch 1729 is : netwok_nn.tensor(0.6163996650766068 , grad = 1.0)\n",
      "Loss at Epoch 1730 is : netwok_nn.tensor(0.6226949008034474 , grad = 1.0)\n",
      "Loss at Epoch 1731 is : netwok_nn.tensor(0.6290805402866384 , grad = 1.0)\n",
      "Loss at Epoch 1732 is : netwok_nn.tensor(0.6355565197383494 , grad = 1.0)\n",
      "Loss at Epoch 1733 is : netwok_nn.tensor(0.64212277547059 , grad = 1.0)\n",
      "Loss at Epoch 1734 is : netwok_nn.tensor(0.6487792438948772 , grad = 1.0)\n",
      "Loss at Epoch 1735 is : netwok_nn.tensor(0.655525861521884 , grad = 1.0)\n",
      "Loss at Epoch 1736 is : netwok_nn.tensor(0.6623625649611019 , grad = 1.0)\n",
      "Loss at Epoch 1737 is : netwok_nn.tensor(0.669289290920478 , grad = 1.0)\n",
      "Loss at Epoch 1738 is : netwok_nn.tensor(0.6763059762060497 , grad = 1.0)\n",
      "Loss at Epoch 1739 is : netwok_nn.tensor(0.6834125577215784 , grad = 1.0)\n",
      "Loss at Epoch 1740 is : netwok_nn.tensor(0.690608972468166 , grad = 1.0)\n",
      "Loss at Epoch 1741 is : netwok_nn.tensor(0.6978951575438692 , grad = 1.0)\n",
      "Loss at Epoch 1742 is : netwok_nn.tensor(0.7052710501433048 , grad = 1.0)\n",
      "Loss at Epoch 1743 is : netwok_nn.tensor(0.7127365875572536 , grad = 1.0)\n",
      "Loss at Epoch 1744 is : netwok_nn.tensor(0.720291707172244 , grad = 1.0)\n",
      "Loss at Epoch 1745 is : netwok_nn.tensor(0.7279363464701422 , grad = 1.0)\n",
      "Loss at Epoch 1746 is : netwok_nn.tensor(0.7356704430277228 , grad = 1.0)\n",
      "Loss at Epoch 1747 is : netwok_nn.tensor(0.743493934516248 , grad = 1.0)\n",
      "Loss at Epoch 1748 is : netwok_nn.tensor(0.7514067587010128 , grad = 1.0)\n",
      "Loss at Epoch 1749 is : netwok_nn.tensor(0.7594088534409178 , grad = 1.0)\n",
      "Loss at Epoch 1750 is : netwok_nn.tensor(0.7675001566880068 , grad = 1.0)\n",
      "Loss at Epoch 1751 is : netwok_nn.tensor(0.7756806064869994 , grad = 1.0)\n",
      "Loss at Epoch 1752 is : netwok_nn.tensor(0.7839501409748426 , grad = 1.0)\n",
      "Loss at Epoch 1753 is : netwok_nn.tensor(0.7923086983802103 , grad = 1.0)\n",
      "Loss at Epoch 1754 is : netwok_nn.tensor(0.800756217023046 , grad = 1.0)\n",
      "Loss at Epoch 1755 is : netwok_nn.tensor(0.8092926353140588 , grad = 1.0)\n",
      "Loss at Epoch 1756 is : netwok_nn.tensor(0.8179178917542262 , grad = 1.0)\n",
      "Loss at Epoch 1757 is : netwok_nn.tensor(0.8266319249342976 , grad = 1.0)\n",
      "Loss at Epoch 1758 is : netwok_nn.tensor(0.835434673534273 , grad = 1.0)\n",
      "Loss at Epoch 1759 is : netwok_nn.tensor(0.8443260763228936 , grad = 1.0)\n",
      "Loss at Epoch 1760 is : netwok_nn.tensor(0.853306072157113 , grad = 1.0)\n",
      "Loss at Epoch 1761 is : netwok_nn.tensor(0.8623745999815564 , grad = 1.0)\n",
      "Loss at Epoch 1762 is : netwok_nn.tensor(0.8715315988279977 , grad = 1.0)\n",
      "Loss at Epoch 1763 is : netwok_nn.tensor(0.880777007814786 , grad = 1.0)\n",
      "Loss at Epoch 1764 is : netwok_nn.tensor(0.890110766146323 , grad = 1.0)\n",
      "Loss at Epoch 1765 is : netwok_nn.tensor(0.8995328131124712 , grad = 1.0)\n",
      "Loss at Epoch 1766 is : netwok_nn.tensor(0.9090430880880059 , grad = 1.0)\n",
      "Loss at Epoch 1767 is : netwok_nn.tensor(0.9186415305320343 , grad = 1.0)\n",
      "Loss at Epoch 1768 is : netwok_nn.tensor(0.9283280799874017 , grad = 1.0)\n",
      "Loss at Epoch 1769 is : netwok_nn.tensor(0.9381026760801185 , grad = 1.0)\n",
      "Loss at Epoch 1770 is : netwok_nn.tensor(0.9479652585187551 , grad = 1.0)\n",
      "Loss at Epoch 1771 is : netwok_nn.tensor(0.9579157670938367 , grad = 1.0)\n",
      "Loss at Epoch 1772 is : netwok_nn.tensor(0.967954141677241 , grad = 1.0)\n",
      "Loss at Epoch 1773 is : netwok_nn.tensor(0.9780803222215695 , grad = 1.0)\n",
      "Loss at Epoch 1774 is : netwok_nn.tensor(0.9882942487595316 , grad = 1.0)\n",
      "Loss at Epoch 1775 is : netwok_nn.tensor(0.9985958614033094 , grad = 1.0)\n",
      "Loss at Epoch 1776 is : netwok_nn.tensor(1.0089851003439296 , grad = 1.0)\n",
      "Loss at Epoch 1777 is : netwok_nn.tensor(1.0194619058506071 , grad = 1.0)\n",
      "Loss at Epoch 1778 is : netwok_nn.tensor(1.0300262182701014 , grad = 1.0)\n",
      "Loss at Epoch 1779 is : netwok_nn.tensor(1.040677978026053 , grad = 1.0)\n",
      "Loss at Epoch 1780 is : netwok_nn.tensor(1.0514171256183367 , grad = 1.0)\n",
      "Loss at Epoch 1781 is : netwok_nn.tensor(1.0622436016223582 , grad = 1.0)\n",
      "Loss at Epoch 1782 is : netwok_nn.tensor(1.0731573466884148 , grad = 1.0)\n",
      "Loss at Epoch 1783 is : netwok_nn.tensor(1.084158301540986 , grad = 1.0)\n",
      "Loss at Epoch 1784 is : netwok_nn.tensor(1.0952464069780579 , grad = 1.0)\n",
      "Loss at Epoch 1785 is : netwok_nn.tensor(1.1064216038704098 , grad = 1.0)\n",
      "Loss at Epoch 1786 is : netwok_nn.tensor(1.1176838331609387 , grad = 1.0)\n",
      "Loss at Epoch 1787 is : netwok_nn.tensor(1.129033035863927 , grad = 1.0)\n",
      "Loss at Epoch 1788 is : netwok_nn.tensor(1.1404691530643387 , grad = 1.0)\n",
      "Loss at Epoch 1789 is : netwok_nn.tensor(1.1519921259170935 , grad = 1.0)\n",
      "Loss at Epoch 1790 is : netwok_nn.tensor(1.1636018956463494 , grad = 1.0)\n",
      "Loss at Epoch 1791 is : netwok_nn.tensor(1.1752984035447576 , grad = 1.0)\n",
      "Loss at Epoch 1792 is : netwok_nn.tensor(1.1870815909727284 , grad = 1.0)\n",
      "Loss at Epoch 1793 is : netwok_nn.tensor(1.1989513993576941 , grad = 1.0)\n",
      "Loss at Epoch 1794 is : netwok_nn.tensor(1.2109077701933468 , grad = 1.0)\n",
      "Loss at Epoch 1795 is : netwok_nn.tensor(1.2229506450388898 , grad = 1.0)\n",
      "Loss at Epoch 1796 is : netwok_nn.tensor(1.2350799655182683 , grad = 1.0)\n",
      "Loss at Epoch 1797 is : netwok_nn.tensor(1.2472956733194145 , grad = 1.0)\n",
      "Loss at Epoch 1798 is : netwok_nn.tensor(1.2595977101934508 , grad = 1.0)\n",
      "Loss at Epoch 1799 is : netwok_nn.tensor(1.2719860179539444 , grad = 1.0)\n",
      "Loss at Epoch 1800 is : netwok_nn.tensor(1.2844605384760939 , grad = 1.0)\n",
      "Loss at Epoch 1801 is : netwok_nn.tensor(1.297021213695952 , grad = 1.0)\n",
      "Loss at Epoch 1802 is : netwok_nn.tensor(1.3096679856096234 , grad = 1.0)\n",
      "Loss at Epoch 1803 is : netwok_nn.tensor(1.3224007962724784 , grad = 1.0)\n",
      "Loss at Epoch 1804 is : netwok_nn.tensor(1.3352195877983375 , grad = 1.0)\n",
      "Loss at Epoch 1805 is : netwok_nn.tensor(1.3481243023586507 , grad = 1.0)\n",
      "Loss at Epoch 1806 is : netwok_nn.tensor(1.3611148821817083 , grad = 1.0)\n",
      "Loss at Epoch 1807 is : netwok_nn.tensor(1.3741912695517902 , grad = 1.0)\n",
      "Loss at Epoch 1808 is : netwok_nn.tensor(1.387353406808362 , grad = 1.0)\n",
      "Loss at Epoch 1809 is : netwok_nn.tensor(1.4006012363452374 , grad = 1.0)\n",
      "Loss at Epoch 1810 is : netwok_nn.tensor(1.4139347006097411 , grad = 1.0)\n",
      "Loss at Epoch 1811 is : netwok_nn.tensor(1.4273537421018696 , grad = 1.0)\n",
      "Loss at Epoch 1812 is : netwok_nn.tensor(1.4408583033734426 , grad = 1.0)\n",
      "Loss at Epoch 1813 is : netwok_nn.tensor(1.4544483270272643 , grad = 1.0)\n",
      "Loss at Epoch 1814 is : netwok_nn.tensor(1.4681237557162539 , grad = 1.0)\n",
      "Loss at Epoch 1815 is : netwok_nn.tensor(1.481884532142604 , grad = 1.0)\n",
      "Loss at Epoch 1816 is : netwok_nn.tensor(1.4957305990569045 , grad = 1.0)\n",
      "Loss at Epoch 1817 is : netwok_nn.tensor(1.5096618992572859 , grad = 1.0)\n",
      "Loss at Epoch 1818 is : netwok_nn.tensor(1.5236783755885448 , grad = 1.0)\n",
      "Loss at Epoch 1819 is : netwok_nn.tensor(1.5377799709412647 , grad = 1.0)\n",
      "Loss at Epoch 1820 is : netwok_nn.tensor(1.5519666282509343 , grad = 1.0)\n",
      "Loss at Epoch 1821 is : netwok_nn.tensor(1.5662382904970784 , grad = 1.0)\n",
      "Loss at Epoch 1822 is : netwok_nn.tensor(1.5805949007023525 , grad = 1.0)\n",
      "Loss at Epoch 1823 is : netwok_nn.tensor(1.5950364019316725 , grad = 1.0)\n",
      "Loss at Epoch 1824 is : netwok_nn.tensor(1.6095627372913084 , grad = 1.0)\n",
      "Loss at Epoch 1825 is : netwok_nn.tensor(1.6241738499279748 , grad = 1.0)\n",
      "Loss at Epoch 1826 is : netwok_nn.tensor(1.6388696830279534 , grad = 1.0)\n",
      "Loss at Epoch 1827 is : netwok_nn.tensor(1.6536501798161773 , grad = 1.0)\n",
      "Loss at Epoch 1828 is : netwok_nn.tensor(1.6685152835553094 , grad = 1.0)\n",
      "Loss at Epoch 1829 is : netwok_nn.tensor(1.683464937544844 , grad = 1.0)\n",
      "Loss at Epoch 1830 is : netwok_nn.tensor(1.698499085120202 , grad = 1.0)\n",
      "Loss at Epoch 1831 is : netwok_nn.tensor(1.7136176696517906 , grad = 1.0)\n",
      "Loss at Epoch 1832 is : netwok_nn.tensor(1.7288206345440946 , grad = 1.0)\n",
      "Loss at Epoch 1833 is : netwok_nn.tensor(1.744107923234746 , grad = 1.0)\n",
      "Loss at Epoch 1834 is : netwok_nn.tensor(1.7594794791936101 , grad = 1.0)\n",
      "Loss at Epoch 1835 is : netwok_nn.tensor(1.7749352459218355 , grad = 1.0)\n",
      "Loss at Epoch 1836 is : netwok_nn.tensor(1.7904751669509429 , grad = 1.0)\n",
      "Loss at Epoch 1837 is : netwok_nn.tensor(1.8060991858418682 , grad = 1.0)\n",
      "Loss at Epoch 1838 is : netwok_nn.tensor(1.8218072461840442 , grad = 1.0)\n",
      "Loss at Epoch 1839 is : netwok_nn.tensor(1.8375992915944515 , grad = 1.0)\n",
      "Loss at Epoch 1840 is : netwok_nn.tensor(1.8534752657166826 , grad = 1.0)\n",
      "Loss at Epoch 1841 is : netwok_nn.tensor(1.8694351122199797 , grad = 1.0)\n",
      "Loss at Epoch 1842 is : netwok_nn.tensor(1.885478774798315 , grad = 1.0)\n",
      "Loss at Epoch 1843 is : netwok_nn.tensor(1.9016061971694187 , grad = 1.0)\n",
      "Loss at Epoch 1844 is : netwok_nn.tensor(1.9178173230738351 , grad = 1.0)\n",
      "Loss at Epoch 1845 is : netwok_nn.tensor(1.9341120962739842 , grad = 1.0)\n",
      "Loss at Epoch 1846 is : netwok_nn.tensor(1.9504904605531808 , grad = 1.0)\n",
      "Loss at Epoch 1847 is : netwok_nn.tensor(1.9669523597147076 , grad = 1.0)\n",
      "Loss at Epoch 1848 is : netwok_nn.tensor(1.9834977375808245 , grad = 1.0)\n",
      "Loss at Epoch 1849 is : netwok_nn.tensor(2.000126537991849 , grad = 1.0)\n",
      "Loss at Epoch 1850 is : netwok_nn.tensor(2.016838704805153 , grad = 1.0)\n",
      "Loss at Epoch 1851 is : netwok_nn.tensor(2.033634181894241 , grad = 1.0)\n",
      "Loss at Epoch 1852 is : netwok_nn.tensor(2.050512913147758 , grad = 1.0)\n",
      "Loss at Epoch 1853 is : netwok_nn.tensor(2.0674748424685343 , grad = 1.0)\n",
      "Loss at Epoch 1854 is : netwok_nn.tensor(2.0845199137726285 , grad = 1.0)\n",
      "Loss at Epoch 1855 is : netwok_nn.tensor(2.1016480709883494 , grad = 1.0)\n",
      "Loss at Epoch 1856 is : netwok_nn.tensor(2.1188592580552923 , grad = 1.0)\n",
      "Loss at Epoch 1857 is : netwok_nn.tensor(2.136153418923368 , grad = 1.0)\n",
      "Loss at Epoch 1858 is : netwok_nn.tensor(2.1535304975518503 , grad = 1.0)\n",
      "Loss at Epoch 1859 is : netwok_nn.tensor(2.170990437908384 , grad = 1.0)\n",
      "Loss at Epoch 1860 is : netwok_nn.tensor(2.1885331839680333 , grad = 1.0)\n",
      "Loss at Epoch 1861 is : netwok_nn.tensor(2.206158679712304 , grad = 1.0)\n",
      "Loss at Epoch 1862 is : netwok_nn.tensor(2.2238668691281633 , grad = 1.0)\n",
      "Loss at Epoch 1863 is : netwok_nn.tensor(2.2416576962070867 , grad = 1.0)\n",
      "Loss at Epoch 1864 is : netwok_nn.tensor(2.259531104944079 , grad = 1.0)\n",
      "Loss at Epoch 1865 is : netwok_nn.tensor(2.2774870393367044 , grad = 1.0)\n",
      "Loss at Epoch 1866 is : netwok_nn.tensor(2.2955254433841157 , grad = 1.0)\n",
      "Loss at Epoch 1867 is : netwok_nn.tensor(2.3136462610860806 , grad = 1.0)\n",
      "Loss at Epoch 1868 is : netwok_nn.tensor(2.3318494364420217 , grad = 1.0)\n",
      "Loss at Epoch 1869 is : netwok_nn.tensor(2.3501349134500287 , grad = 1.0)\n",
      "Loss at Epoch 1870 is : netwok_nn.tensor(2.3685026361059043 , grad = 1.0)\n",
      "Loss at Epoch 1871 is : netwok_nn.tensor(2.3869525484021987 , grad = 1.0)\n",
      "Loss at Epoch 1872 is : netwok_nn.tensor(2.405484594327213 , grad = 1.0)\n",
      "Loss at Epoch 1873 is : netwok_nn.tensor(2.424098717864061 , grad = 1.0)\n",
      "Loss at Epoch 1874 is : netwok_nn.tensor(2.4427948629896843 , grad = 1.0)\n",
      "Loss at Epoch 1875 is : netwok_nn.tensor(2.4615729736739134 , grad = 1.0)\n",
      "Loss at Epoch 1876 is : netwok_nn.tensor(2.48043299387846 , grad = 1.0)\n",
      "Loss at Epoch 1877 is : netwok_nn.tensor(2.499374867555986 , grad = 1.0)\n",
      "Loss at Epoch 1878 is : netwok_nn.tensor(2.518398538649133 , grad = 1.0)\n",
      "Loss at Epoch 1879 is : netwok_nn.tensor(2.5375039510895534 , grad = 1.0)\n",
      "Loss at Epoch 1880 is : netwok_nn.tensor(2.5566910487969516 , grad = 1.0)\n",
      "Loss at Epoch 1881 is : netwok_nn.tensor(2.5759597756781347 , grad = 1.0)\n",
      "Loss at Epoch 1882 is : netwok_nn.tensor(2.5953100756260308 , grad = 1.0)\n",
      "Loss at Epoch 1883 is : netwok_nn.tensor(2.6147418925187718 , grad = 1.0)\n",
      "Loss at Epoch 1884 is : netwok_nn.tensor(2.634255170218702 , grad = 1.0)\n",
      "Loss at Epoch 1885 is : netwok_nn.tensor(2.653849852571444 , grad = 1.0)\n",
      "Loss at Epoch 1886 is : netwok_nn.tensor(2.6735258834049427 , grad = 1.0)\n",
      "Loss at Epoch 1887 is : netwok_nn.tensor(2.693283206528526 , grad = 1.0)\n",
      "Loss at Epoch 1888 is : netwok_nn.tensor(2.713121765731951 , grad = 1.0)\n",
      "Loss at Epoch 1889 is : netwok_nn.tensor(2.7330415047844463 , grad = 1.0)\n",
      "Loss at Epoch 1890 is : netwok_nn.tensor(2.7530423674337805 , grad = 1.0)\n",
      "Loss at Epoch 1891 is : netwok_nn.tensor(2.773124297405344 , grad = 1.0)\n",
      "Loss at Epoch 1892 is : netwok_nn.tensor(2.7932872384011698 , grad = 1.0)\n",
      "Loss at Epoch 1893 is : netwok_nn.tensor(2.8135311340990206 , grad = 1.0)\n",
      "Loss at Epoch 1894 is : netwok_nn.tensor(2.833855928151465 , grad = 1.0)\n",
      "Loss at Epoch 1895 is : netwok_nn.tensor(2.8542615641849305 , grad = 1.0)\n",
      "Loss at Epoch 1896 is : netwok_nn.tensor(2.8747479857987663 , grad = 1.0)\n",
      "Loss at Epoch 1897 is : netwok_nn.tensor(2.895315136564355 , grad = 1.0)\n",
      "Loss at Epoch 1898 is : netwok_nn.tensor(2.9159629600241526 , grad = 1.0)\n",
      "Loss at Epoch 1899 is : netwok_nn.tensor(2.9366913996907904 , grad = 1.0)\n",
      "Loss at Epoch 1900 is : netwok_nn.tensor(2.9575003990461477 , grad = 1.0)\n",
      "Loss at Epoch 1901 is : netwok_nn.tensor(2.9783899015404565 , grad = 1.0)\n",
      "Loss at Epoch 1902 is : netwok_nn.tensor(2.9993598505913552 , grad = 1.0)\n",
      "Loss at Epoch 1903 is : netwok_nn.tensor(3.020410189583023 , grad = 1.0)\n",
      "Loss at Epoch 1904 is : netwok_nn.tensor(3.0415408618652533 , grad = 1.0)\n",
      "Loss at Epoch 1905 is : netwok_nn.tensor(3.0627518107525527 , grad = 1.0)\n",
      "Loss at Epoch 1906 is : netwok_nn.tensor(3.084042979523249 , grad = 1.0)\n",
      "Loss at Epoch 1907 is : netwok_nn.tensor(3.1054143114185977 , grad = 1.0)\n",
      "Loss at Epoch 1908 is : netwok_nn.tensor(3.126865749641904 , grad = 1.0)\n",
      "Loss at Epoch 1909 is : netwok_nn.tensor(3.1483972373576217 , grad = 1.0)\n",
      "Loss at Epoch 1910 is : netwok_nn.tensor(3.1700087176904486 , grad = 1.0)\n",
      "Loss at Epoch 1911 is : netwok_nn.tensor(3.1917001337245 , grad = 1.0)\n",
      "Loss at Epoch 1912 is : netwok_nn.tensor(3.213471428502396 , grad = 1.0)\n",
      "Loss at Epoch 1913 is : netwok_nn.tensor(3.235322545024401 , grad = 1.0)\n",
      "Loss at Epoch 1914 is : netwok_nn.tensor(3.2572534262475523 , grad = 1.0)\n",
      "Loss at Epoch 1915 is : netwok_nn.tensor(3.279264015084803 , grad = 1.0)\n",
      "Loss at Epoch 1916 is : netwok_nn.tensor(3.3013542544041696 , grad = 1.0)\n",
      "Loss at Epoch 1917 is : netwok_nn.tensor(3.3235240870278533 , grad = 1.0)\n",
      "Loss at Epoch 1918 is : netwok_nn.tensor(3.3457734557314183 , grad = 1.0)\n",
      "Loss at Epoch 1919 is : netwok_nn.tensor(3.3681023032429205 , grad = 1.0)\n",
      "Loss at Epoch 1920 is : netwok_nn.tensor(3.390510572242085 , grad = 1.0)\n",
      "Loss at Epoch 1921 is : netwok_nn.tensor(3.412998205359452 , grad = 1.0)\n",
      "Loss at Epoch 1922 is : netwok_nn.tensor(3.435565145175555 , grad = 1.0)\n",
      "Loss at Epoch 1923 is : netwok_nn.tensor(3.458211334220094 , grad = 1.0)\n",
      "Loss at Epoch 1924 is : netwok_nn.tensor(3.480936714971104 , grad = 1.0)\n",
      "Loss at Epoch 1925 is : netwok_nn.tensor(3.5037412298541346 , grad = 1.0)\n",
      "Loss at Epoch 1926 is : netwok_nn.tensor(3.526624821241447 , grad = 1.0)\n",
      "Loss at Epoch 1927 is : netwok_nn.tensor(3.5495874314511893 , grad = 1.0)\n",
      "Loss at Epoch 1928 is : netwok_nn.tensor(3.5726290027466048 , grad = 1.0)\n",
      "Loss at Epoch 1929 is : netwok_nn.tensor(3.595749477335222 , grad = 1.0)\n",
      "Loss at Epoch 1930 is : netwok_nn.tensor(3.618948797368054 , grad = 1.0)\n",
      "Loss at Epoch 1931 is : netwok_nn.tensor(3.64222690493884 , grad = 1.0)\n",
      "Loss at Epoch 1932 is : netwok_nn.tensor(3.6655837420832076 , grad = 1.0)\n",
      "Loss at Epoch 1933 is : netwok_nn.tensor(3.6890192507779513 , grad = 1.0)\n",
      "Loss at Epoch 1934 is : netwok_nn.tensor(3.712533372940215 , grad = 1.0)\n",
      "Loss at Epoch 1935 is : netwok_nn.tensor(3.736126050426722 , grad = 1.0)\n",
      "Loss at Epoch 1936 is : netwok_nn.tensor(3.759797225033044 , grad = 1.0)\n",
      "Loss at Epoch 1937 is : netwok_nn.tensor(3.7835468384928226 , grad = 1.0)\n",
      "Loss at Epoch 1938 is : netwok_nn.tensor(3.8073748324769885 , grad = 1.0)\n",
      "Loss at Epoch 1939 is : netwok_nn.tensor(3.8312811485930585 , grad = 1.0)\n",
      "Loss at Epoch 1940 is : netwok_nn.tensor(3.8552657283843685 , grad = 1.0)\n",
      "Loss at Epoch 1941 is : netwok_nn.tensor(3.879328513329335 , grad = 1.0)\n",
      "Loss at Epoch 1942 is : netwok_nn.tensor(3.903469444840725 , grad = 1.0)\n",
      "Loss at Epoch 1943 is : netwok_nn.tensor(3.9276884642649263 , grad = 1.0)\n",
      "Loss at Epoch 1944 is : netwok_nn.tensor(3.9519855128812424 , grad = 1.0)\n",
      "Loss at Epoch 1945 is : netwok_nn.tensor(3.976360531901146 , grad = 1.0)\n",
      "Loss at Epoch 1946 is : netwok_nn.tensor(4.0008134624675895 , grad = 1.0)\n",
      "Loss at Epoch 1947 is : netwok_nn.tensor(4.025344245654306 , grad = 1.0)\n",
      "Loss at Epoch 1948 is : netwok_nn.tensor(4.049952822465096 , grad = 1.0)\n",
      "Loss at Epoch 1949 is : netwok_nn.tensor(4.074639133833125 , grad = 1.0)\n",
      "Loss at Epoch 1950 is : netwok_nn.tensor(4.09940312062028 , grad = 1.0)\n",
      "Loss at Epoch 1951 is : netwok_nn.tensor(4.124244723616423 , grad = 1.0)\n",
      "Loss at Epoch 1952 is : netwok_nn.tensor(4.14916388353877 , grad = 1.0)\n",
      "Loss at Epoch 1953 is : netwok_nn.tensor(4.174160541031195 , grad = 1.0)\n",
      "Loss at Epoch 1954 is : netwok_nn.tensor(4.199234636663561 , grad = 1.0)\n",
      "Loss at Epoch 1955 is : netwok_nn.tensor(4.224386110931086 , grad = 1.0)\n",
      "Loss at Epoch 1956 is : netwok_nn.tensor(4.249614904253669 , grad = 1.0)\n",
      "Loss at Epoch 1957 is : netwok_nn.tensor(4.27492095697525 , grad = 1.0)\n",
      "Loss at Epoch 1958 is : netwok_nn.tensor(4.300304209363169 , grad = 1.0)\n",
      "Loss at Epoch 1959 is : netwok_nn.tensor(4.325764601607528 , grad = 1.0)\n",
      "Loss at Epoch 1960 is : netwok_nn.tensor(4.351302073820565 , grad = 1.0)\n",
      "Loss at Epoch 1961 is : netwok_nn.tensor(4.376916566036048 , grad = 1.0)\n",
      "Loss at Epoch 1962 is : netwok_nn.tensor(4.402608018208614 , grad = 1.0)\n",
      "Loss at Epoch 1963 is : netwok_nn.tensor(4.428376370213215 , grad = 1.0)\n",
      "Loss at Epoch 1964 is : netwok_nn.tensor(4.454221561844478 , grad = 1.0)\n",
      "Loss at Epoch 1965 is : netwok_nn.tensor(4.480143532816093 , grad = 1.0)\n",
      "Loss at Epoch 1966 is : netwok_nn.tensor(4.506142222760269 , grad = 1.0)\n",
      "Loss at Epoch 1967 is : netwok_nn.tensor(4.532217571227105 , grad = 1.0)\n",
      "Loss at Epoch 1968 is : netwok_nn.tensor(4.558369517684046 , grad = 1.0)\n",
      "Loss at Epoch 1969 is : netwok_nn.tensor(4.584598001515266 , grad = 1.0)\n",
      "Loss at Epoch 1970 is : netwok_nn.tensor(4.610902962021138 , grad = 1.0)\n",
      "Loss at Epoch 1971 is : netwok_nn.tensor(4.637284338417661 , grad = 1.0)\n",
      "Loss at Epoch 1972 is : netwok_nn.tensor(4.66374206983589 , grad = 1.0)\n",
      "Loss at Epoch 1973 is : netwok_nn.tensor(4.690276095321405 , grad = 1.0)\n",
      "Loss at Epoch 1974 is : netwok_nn.tensor(4.71688635383376 , grad = 1.0)\n",
      "Loss at Epoch 1975 is : netwok_nn.tensor(4.7435727842459565 , grad = 1.0)\n",
      "Loss at Epoch 1976 is : netwok_nn.tensor(4.770335325343915 , grad = 1.0)\n",
      "Loss at Epoch 1977 is : netwok_nn.tensor(4.7971739158259155 , grad = 1.0)\n",
      "Loss at Epoch 1978 is : netwok_nn.tensor(4.824088494302134 , grad = 1.0)\n",
      "Loss at Epoch 1979 is : netwok_nn.tensor(4.851078999294076 , grad = 1.0)\n",
      "Loss at Epoch 1980 is : netwok_nn.tensor(4.87814536923411 , grad = 1.0)\n",
      "Loss at Epoch 1981 is : netwok_nn.tensor(4.9052875424649836 , grad = 1.0)\n",
      "Loss at Epoch 1982 is : netwok_nn.tensor(4.9325054572392535 , grad = 1.0)\n",
      "Loss at Epoch 1983 is : netwok_nn.tensor(4.959799051718895 , grad = 1.0)\n",
      "Loss at Epoch 1984 is : netwok_nn.tensor(4.987168263974748 , grad = 1.0)\n",
      "Loss at Epoch 1985 is : netwok_nn.tensor(5.014613031986086 , grad = 1.0)\n",
      "Loss at Epoch 1986 is : netwok_nn.tensor(5.042133293640141 , grad = 1.0)\n",
      "Loss at Epoch 1987 is : netwok_nn.tensor(5.069728986731618 , grad = 1.0)\n",
      "Loss at Epoch 1988 is : netwok_nn.tensor(5.0974000489622515 , grad = 1.0)\n",
      "Loss at Epoch 1989 is : netwok_nn.tensor(5.125146417940381 , grad = 1.0)\n",
      "Loss at Epoch 1990 is : netwok_nn.tensor(5.1529680311804835 , grad = 1.0)\n",
      "Loss at Epoch 1991 is : netwok_nn.tensor(5.180864826102744 , grad = 1.0)\n",
      "Loss at Epoch 1992 is : netwok_nn.tensor(5.208836740032608 , grad = 1.0)\n",
      "Loss at Epoch 1993 is : netwok_nn.tensor(5.236883710200399 , grad = 1.0)\n",
      "Loss at Epoch 1994 is : netwok_nn.tensor(5.2650056737408555 , grad = 1.0)\n",
      "Loss at Epoch 1995 is : netwok_nn.tensor(5.293202567692739 , grad = 1.0)\n",
      "Loss at Epoch 1996 is : netwok_nn.tensor(5.321474328998453 , grad = 1.0)\n",
      "Loss at Epoch 1997 is : netwok_nn.tensor(5.349820894503584 , grad = 1.0)\n",
      "Loss at Epoch 1998 is : netwok_nn.tensor(5.3782422009565725 , grad = 1.0)\n",
      "Loss at Epoch 1999 is : netwok_nn.tensor(5.406738185008287 , grad = 1.0)\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(in_features=1)\n",
    "optimiser = AdamOptimizer(lr=0.001)\n",
    "for epoch in range(2000):\n",
    "    out = model(x)\n",
    "    loss = mse(predictions=out, targets=y)\n",
    "    loss.backprop()\n",
    "    print(f\"Loss at Epoch {epoch} is : {loss}\")\n",
    "    optimiser.step(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
